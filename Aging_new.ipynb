{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56e359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from sklearn.metrics import confusion_matrix , classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(1234)\n",
    "import os\n",
    "import random\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d2489e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23517e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(1234)\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3988908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11  \\\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3   \n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0   \n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5   \n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0   \n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b71d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "661b9555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d1861e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7be3ec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c93a6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data['X11']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe70d146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.3\n",
       "1    10.0\n",
       "2    17.5\n",
       "3    31.0\n",
       "4    34.0\n",
       "Name: X11, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3922b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "17\n",
      "8\n",
      "18\n",
      "17\n",
      "9\n",
      "14\n",
      "55\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#We check the number of unique values in each column\n",
    "a=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "for i in a:\n",
    "    print(len(X[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f12e9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "132cbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this code reduces the  above outliers seen. This is done by chaning the values in the box plot based on inter quantile range \n",
    "# for i in X.columns:\n",
    "#     q1=X[i].quantile(0.25)\n",
    "#     q3=X[i].quantile(0.75)\n",
    "#     iqr=q3-q1\n",
    "#     ub=q3 + 1.5*iqr\n",
    "#     lb=q1 - 1.5*iqr\n",
    "#     uc=X[i].quantile(0.99)\n",
    "#     lc=X[i].quantile(0.01)\n",
    "#     for ind1 in X[i].index:\n",
    "#         if X.loc[ind1, i] >ub:            \n",
    "#             X.loc[ind1, i] =uc\n",
    "#         if X.loc[ind1, i] < lb:\n",
    "#             X.loc[ind1, i] =lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9bf0c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b37ea23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d4730fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2eb72511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28a42ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4ab42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d132751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6186e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867b055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665f6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f72a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd44cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b52554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4e2d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea59a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e063114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_RF_Acc :  0.8073577453485754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, Y)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "RF_accuracies = cross_val_score(estimator = rf, X = X, y = Y, cv = kf,scoring=\"r2\")\n",
    "print(\"Mean_RF_Acc : \", RF_accuracies.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b377171",
   "metadata": {},
   "source": [
    "# So i just tried a neural network below, it is similar to the neural network given in the machine learning mastery, not really sure what it means but have to work on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c73fe990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "# from tf.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1bb4ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=0.01, momentum=0.9)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93cd3d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 46.376, Test: 63.081\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT Modify\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform'))\n",
    "reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mse', \n",
    "                optimizer='SGD')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=100, verbose=0)\n",
    "\n",
    "train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score : %.2f\" % r2_score(Y_test,y_preds)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ffcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ae36c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X= scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71246a5e",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd251ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99149569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d086ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df = pd.DataFrame(data = X_pca)\n",
    "PCA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(PCA_df, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9778f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn import linear_model, tree, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a5fff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 8.9863 - mae: 8.9863\n",
      "[8.98630428314209, 8.98630428314209]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT Modify\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(8, input_dim=8, activation='relu',kernel_initializer='he_uniform'))\n",
    "reg_model.add(Dense(4, activation='relu'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam', \n",
    "                metrics=['mae'])\n",
    "\n",
    "\n",
    "his = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=100, verbose=0)\n",
    "\n",
    "print(reg_model.evaluate(X_test, Y_test))\n",
    "\n",
    "y_preds = reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f9c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319589ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4459f5a1",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fef6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "encoded = Dense(8, activation='relu')(input_layer)\n",
    "decoded = Dense(X.shape[1], activation='softmax')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "X1, X2, Y1, Y2 = train_test_split(X, X, test_size=0.3, random_state=101)\n",
    "\n",
    "autoencoder.fit(X1, Y1,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose = 30,\n",
    "                validation_data=(X2, Y2))\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_ae = encoder.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32eb3638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1a2998d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "batch_size = 32\n",
    "input_dim = X_train[0].shape[0] #num of predictor variables \n",
    "learning_rate = 1e-4\n",
    "input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "#Input Layer\n",
    "encoder = Dense (100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "#Encoder’s first dense layer\n",
    "encoder = Dense (50, activation=\"relu\",\n",
    "activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "#Encoder’s second dense layer\n",
    "encoder = Dense (25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Code layer\n",
    "encoder = Dense (8, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s first dense layer\n",
    "decoder = Dense(25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s second dense layer\n",
    "decoder = Dense(50, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Decoder’s Third dense layer\n",
    "decoder = Dense(100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Output Layer\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\", activity_regularizer=regularizers.l1(learning_rate))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3283b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 1ms/step - loss: 0.1504 - accuracy: 0.1429\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.1371\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.1371\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.1371\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.1371\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.1371\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.1371\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.1371\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.1371\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.1543\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.2514\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.2343\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.2743\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.2914\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.3029\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.4000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.4629\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.4343\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.5029\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.5714\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.5829\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.5600\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.5829\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.5886\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.5600\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.5371\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.4857\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.4971\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.4971\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.4971\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.5543\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.5657\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.5486\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.5657\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 871us/step - loss: 0.0249 - accuracy: 0.5829\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.5771\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.5943\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.0238 - accuracy: 0.5714\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0234 - accuracy: 0.5886\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.5943\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.6057\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.6286\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.6286\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.6114\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0215 - accuracy: 0.6286\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.6229\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.6343\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.6057\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.6229\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.5943\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.6686\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.6514\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.6514\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.6571\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.6743\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.6571\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.6457\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.6914\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.0172 - accuracy: 0.6343\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.6857\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.6971\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.6686\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.7029\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.7143\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 357us/step - loss: 0.0155 - accuracy: 0.6800\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.6914\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.6800\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.6971\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.7086\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.7200\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.7257\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.7314\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.7200\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.7314\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.7029\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.7314\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.7143\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.7486\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 846us/step - loss: 0.0121 - accuracy: 0.7200\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.7543\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.7143\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.7200\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.7200\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.7543\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.7429\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.7371\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.7429\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.6971\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.7371\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 988us/step - loss: 0.0103 - accuracy: 0.7371\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.7371\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.6971\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.7143\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.7200\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.7086\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 817us/step - loss: 0.0096 - accuracy: 0.7200\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.7314\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.7086\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.7371\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 962us/step - loss: 0.0091 - accuracy: 0.7371\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.7486\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.7371\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.7314\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.7314\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.7429\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 960us/step - loss: 0.0086 - accuracy: 0.7314\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0085 - accuracy: 0.7600\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 0.7429\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.7371\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.7543\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.7600\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.7600\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.7600\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.7657\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.7600\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.7600\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 0.7657\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.7714\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.7486\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 926us/step - loss: 0.0075 - accuracy: 0.7543\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.7657\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.7657\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.7771\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.7714\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 982us/step - loss: 0.0072 - accuracy: 0.7771\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 0.7771\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.7829\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.7771\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 0.7829\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.7771\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.7943\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.7943\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.7886\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.7886\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.7943\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.7943\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.7886\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 851us/step - loss: 0.0066 - accuracy: 0.7943\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.7943\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.7943\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.7886\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.7943\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.7943\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.7829\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 421us/step - loss: 0.0065 - accuracy: 0.7771\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 772us/step - loss: 0.0064 - accuracy: 0.7943\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.7886\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.7943\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.7886\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.7943\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 749us/step - loss: 0.0061 - accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.7943\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.7943\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 959us/step - loss: 0.0060 - accuracy: 0.7943\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0060 - accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 990us/step - loss: 0.0059 - accuracy: 0.7943\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0058 - accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.8000\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 173us/step - loss: 0.0057 - accuracy: 0.8000\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 219us/step - loss: 0.0056 - accuracy: 0.7943\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.7943\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 995us/step - loss: 0.0055 - accuracy: 0.7943\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.8000\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 416us/step - loss: 0.0054 - accuracy: 0.7943\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.7943\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 952us/step - loss: 0.0054 - accuracy: 0.7943\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.8000\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 991us/step - loss: 0.0053 - accuracy: 0.7943\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.7943\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.8057\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 969us/step - loss: 0.0053 - accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.7943\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 702us/step - loss: 0.0052 - accuracy: 0.8057\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0052 - accuracy: 0.7943\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.8000\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0052 - accuracy: 0.7943\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 674us/step - loss: 0.0052 - accuracy: 0.7943\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.7714\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.8057\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.8057\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.0050 - accuracy: 0.8114\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 448us/step - loss: 0.0050 - accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 938us/step - loss: 0.0050 - accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.8057\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.7943\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.7943\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.7943\n"
     ]
    }
   ],
   "source": [
    "autoencoder_1 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_1.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_1 = autoencoder_1.fit(X_train, X_train,epochs=200,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d711de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2_input = autoencoder_1.predict(X_train)\n",
    "autoencoder_2_input = np.concatenate((autoencoder_2_input , X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "287b49a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9029\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.8943\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.8857\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.8943\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.8914\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.8829\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.8857\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.8857\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.8829\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 858us/step - loss: 0.0038 - accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.8914\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.8886\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.8857\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9057\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 978us/step - loss: 0.0036 - accuracy: 0.8914\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.8943\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.8886\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.8914\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.8857\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.8771\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 880us/step - loss: 0.0033 - accuracy: 0.8829\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.8886\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.8971\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.8914\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.8829\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.8886\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.8829\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.8886\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.8914\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.8714\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.8971\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.8886\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.8857\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.8857\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 849us/step - loss: 0.0029 - accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.8943\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.8829\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.8886\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.8914\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.8800\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.8943\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.8886\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9029\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.8800\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.8914\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9029\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.8886\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.0027 - accuracy: 0.8857\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 909us/step - loss: 0.0027 - accuracy: 0.8886\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 909us/step - loss: 0.0027 - accuracy: 0.8771\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 936us/step - loss: 0.0028 - accuracy: 0.8686\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 954us/step - loss: 0.0030 - accuracy: 0.8657\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.8771\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.8800\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.8971\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.8857\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.8771\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.8857\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8714\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.8829\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8714\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.8800\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8743\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8743\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8886\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8771\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8829\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8743\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8829\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 842us/step - loss: 0.0023 - accuracy: 0.8629\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 463us/step - loss: 0.0023 - accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 661us/step - loss: 0.0023 - accuracy: 0.8771\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0023 - accuracy: 0.8771\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 482us/step - loss: 0.0023 - accuracy: 0.8943\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 513us/step - loss: 0.0023 - accuracy: 0.8971\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 712us/step - loss: 0.0023 - accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 707us/step - loss: 0.0023 - accuracy: 0.8857\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 609us/step - loss: 0.0023 - accuracy: 0.8829\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.0022 - accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.0022 - accuracy: 0.8800\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 619us/step - loss: 0.0022 - accuracy: 0.8857\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 663us/step - loss: 0.0022 - accuracy: 0.8686\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 346us/step - loss: 0.0022 - accuracy: 0.8914\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 392us/step - loss: 0.0022 - accuracy: 0.8886\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 610us/step - loss: 0.0022 - accuracy: 0.8714\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 689us/step - loss: 0.0022 - accuracy: 0.8857\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 647us/step - loss: 0.0022 - accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_2.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7732afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)\n",
    "autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01b16229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 1ms/step - loss: 0.0022 - accuracy: 0.9171\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9271\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9257\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9114\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9157\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9157\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9257\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9200\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9271\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9314\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9214\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9114\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9257\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9186\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9300\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9300\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9286\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9257\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9286\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9214\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9286\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9157\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9214\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9243\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.8814\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.8829\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.9029\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9071\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9114\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9171\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9114\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9229\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.9171\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9171\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9157\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9214\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9200\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9200\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9186\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9171\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9200\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9286\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9200\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9229\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9200\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9171\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.9157\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "autoencoder_3 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_3.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4755554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = Model(input_layer, encoder)\n",
    "X_ae1 = encoded.predict(X)\n",
    "X_ae1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f9fcd6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101947</td>\n",
       "      <td>0.021714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068422</td>\n",
       "      <td>0.080959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101932</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068404</td>\n",
       "      <td>0.080887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101907</td>\n",
       "      <td>0.021917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.080025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101613</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3         4    5         6    7\n",
       "0  0.068433  0.081002  0.0  0.101947  0.021714  0.0  0.002771  0.0\n",
       "1  0.068422  0.080959  0.0  0.101932  0.021790  0.0  0.002816  0.0\n",
       "2  0.068404  0.080887  0.0  0.101907  0.021917  0.0  0.002891  0.0\n",
       "3  0.068332  0.080600  0.0  0.101809  0.022426  0.0  0.003191  0.0\n",
       "4  0.068188  0.080025  0.0  0.101613  0.023443  0.0  0.003792  0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AEC_df = pd.DataFrame(data = X_ae1)\n",
    "AEC_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03053f2",
   "metadata": {},
   "source": [
    "# Independent component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "035555cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=8)\n",
    "X_ica = ica.fit_transform(X)\n",
    "X_ica = pd.DataFrame(data = X_ica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0da5e94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016637</td>\n",
       "      <td>-0.032390</td>\n",
       "      <td>-0.120925</td>\n",
       "      <td>-0.073528</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>0.031620</td>\n",
       "      <td>0.035413</td>\n",
       "      <td>0.015851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.016648</td>\n",
       "      <td>-0.032399</td>\n",
       "      <td>-0.120950</td>\n",
       "      <td>-0.073510</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016666</td>\n",
       "      <td>-0.032414</td>\n",
       "      <td>-0.120992</td>\n",
       "      <td>-0.073480</td>\n",
       "      <td>0.032203</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.015832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.016739</td>\n",
       "      <td>-0.032473</td>\n",
       "      <td>-0.121160</td>\n",
       "      <td>-0.073360</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>0.015786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016885</td>\n",
       "      <td>-0.032591</td>\n",
       "      <td>-0.121495</td>\n",
       "      <td>-0.073121</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.029534</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>0.015693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.016637 -0.032390 -0.120925 -0.073528  0.032233  0.031620  0.035413   \n",
       "1 -0.016648 -0.032399 -0.120950 -0.073510  0.032222  0.031528  0.035400   \n",
       "2 -0.016666 -0.032414 -0.120992 -0.073480  0.032203  0.031374  0.035378   \n",
       "3 -0.016739 -0.032473 -0.121160 -0.073360  0.032129  0.030761  0.035292   \n",
       "4 -0.016885 -0.032591 -0.121495 -0.073121  0.031981  0.029534  0.035118   \n",
       "\n",
       "          7  \n",
       "0  0.015851  \n",
       "1  0.015844  \n",
       "2  0.015832  \n",
       "3  0.015786  \n",
       "4  0.015693  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279dc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
