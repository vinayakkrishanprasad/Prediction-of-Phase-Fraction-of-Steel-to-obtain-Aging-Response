{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cb833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from sklearn.metrics import confusion_matrix , classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(1234)\n",
    "import os\n",
    "import random\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef72364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a468839",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a030d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11  \\\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3   \n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0   \n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5   \n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0   \n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4977254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8d132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd8a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33103b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f399522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data['X11']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ea07b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.3\n",
       "1    10.0\n",
       "2    17.5\n",
       "3    31.0\n",
       "4    34.0\n",
       "Name: X11, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9fbbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "17\n",
      "8\n",
      "18\n",
      "17\n",
      "9\n",
      "14\n",
      "55\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#We check the number of unique values in each column\n",
    "a=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "for i in a:\n",
    "    print(len(X[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e7ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c177d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this code reduces the  above outliers seen. This is done by chaning the values in the box plot based on inter quantile range \n",
    "# for i in X.columns:\n",
    "#     q1=X[i].quantile(0.25)\n",
    "#     q3=X[i].quantile(0.75)\n",
    "#     iqr=q3-q1\n",
    "#     ub=q3 + 1.5*iqr\n",
    "#     lb=q1 - 1.5*iqr\n",
    "#     uc=X[i].quantile(0.99)\n",
    "#     lc=X[i].quantile(0.01)\n",
    "#     for ind1 in X[i].index:\n",
    "#         if X.loc[ind1, i] >ub:            \n",
    "#             X.loc[ind1, i] =uc\n",
    "#         if X.loc[ind1, i] < lb:\n",
    "#             X.loc[ind1, i] =lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb85fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f03ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bdd997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9de59713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c3b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "520d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c30fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f2dea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_RF_Acc :  0.8073577453485754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, Y)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "RF_accuracies = cross_val_score(estimator = rf, X = X, y = Y, cv = kf,scoring=\"r2\")\n",
    "print(\"Mean_RF_Acc : \", RF_accuracies.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510874b",
   "metadata": {},
   "source": [
    "# So i just tried a neural network below, it is similar to the neural network given in the machine learning mastery, not really sure what it means but have to work on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3856118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a4a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c822c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e42b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8232db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dbb5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf887b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9623fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "6/6 [==============================] - 1s 56ms/step - loss: 10.6328 - val_loss: 13.2850\n",
      "Epoch 2/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5754 - val_loss: 13.2348\n",
      "Epoch 3/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.5191 - val_loss: 13.1779\n",
      "Epoch 4/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.4526 - val_loss: 13.1132\n",
      "Epoch 5/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.3776 - val_loss: 13.0399\n",
      "Epoch 6/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.2939 - val_loss: 12.9565\n",
      "Epoch 7/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.2006 - val_loss: 12.8595\n",
      "Epoch 8/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0910 - val_loss: 12.7511\n",
      "Epoch 9/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.9773 - val_loss: 12.6233\n",
      "Epoch 10/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.8441 - val_loss: 12.4789\n",
      "Epoch 11/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.6987 - val_loss: 12.3188\n",
      "Epoch 12/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5420 - val_loss: 12.1457\n",
      "Epoch 13/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.3620 - val_loss: 11.9513\n",
      "Epoch 14/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1860 - val_loss: 11.7305\n",
      "Epoch 15/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9822 - val_loss: 11.4955\n",
      "Epoch 16/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7712 - val_loss: 11.2386\n",
      "Epoch 17/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5517 - val_loss: 10.9846\n",
      "Epoch 18/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3271 - val_loss: 10.7177\n",
      "Epoch 19/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.0952 - val_loss: 10.4572\n",
      "Epoch 20/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8775 - val_loss: 10.2062\n",
      "Epoch 21/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6592 - val_loss: 9.9667\n",
      "Epoch 22/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4746 - val_loss: 9.7191\n",
      "Epoch 23/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2718 - val_loss: 9.5180\n",
      "Epoch 24/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.0878 - val_loss: 9.3135\n",
      "Epoch 25/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8939 - val_loss: 9.1105\n",
      "Epoch 26/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6924 - val_loss: 8.9084\n",
      "Epoch 27/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5152 - val_loss: 8.7099\n",
      "Epoch 28/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3178 - val_loss: 8.5162\n",
      "Epoch 29/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.1422 - val_loss: 8.3215\n",
      "Epoch 30/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.9454 - val_loss: 8.1321\n",
      "Epoch 31/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7509 - val_loss: 7.9509\n",
      "Epoch 32/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5614 - val_loss: 7.7685\n",
      "Epoch 33/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3854 - val_loss: 7.6059\n",
      "Epoch 34/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2016 - val_loss: 7.4390\n",
      "Epoch 35/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.0300 - val_loss: 7.2857\n",
      "Epoch 36/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.8667 - val_loss: 7.1369\n",
      "Epoch 37/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.7184 - val_loss: 6.9854\n",
      "Epoch 38/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.5718 - val_loss: 6.8291\n",
      "Epoch 39/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.4622 - val_loss: 6.7014\n",
      "Epoch 40/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3531 - val_loss: 6.5773\n",
      "Epoch 41/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.2797 - val_loss: 6.4880\n",
      "Epoch 42/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.2127 - val_loss: 6.4283\n",
      "Epoch 43/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.1570 - val_loss: 6.3654\n",
      "Epoch 44/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.1025 - val_loss: 6.2818\n",
      "Epoch 45/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.0665 - val_loss: 6.2011\n",
      "Epoch 46/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.0275 - val_loss: 6.1647\n",
      "Epoch 47/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.9984 - val_loss: 6.1760\n",
      "Epoch 48/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.9612 - val_loss: 6.0895\n",
      "Epoch 49/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.9219 - val_loss: 6.0529\n",
      "Epoch 50/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8998 - val_loss: 6.0352\n",
      "Epoch 51/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8775 - val_loss: 5.9849\n",
      "Epoch 52/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.8489 - val_loss: 5.9676\n",
      "Epoch 53/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.8308 - val_loss: 5.9706\n",
      "Epoch 54/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.8093 - val_loss: 5.9346\n",
      "Epoch 55/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.7964 - val_loss: 5.9127\n",
      "Epoch 56/1300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7957 - val_loss: 5.8762\n",
      "Epoch 57/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7773 - val_loss: 5.8721\n",
      "Epoch 58/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.7517 - val_loss: 5.9071\n",
      "Epoch 59/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.7467 - val_loss: 5.9007\n",
      "Epoch 60/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.7331 - val_loss: 5.8644\n",
      "Epoch 61/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.7218 - val_loss: 5.8298\n",
      "Epoch 62/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.7056 - val_loss: 5.8216\n",
      "Epoch 63/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.7115 - val_loss: 5.8328\n",
      "Epoch 64/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.6899 - val_loss: 5.7983\n",
      "Epoch 65/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.6836 - val_loss: 5.8281\n",
      "Epoch 66/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6675 - val_loss: 5.8081\n",
      "Epoch 67/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6550 - val_loss: 5.7713\n",
      "Epoch 68/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6478 - val_loss: 5.7795\n",
      "Epoch 69/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.6399 - val_loss: 5.7515\n",
      "Epoch 70/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6362 - val_loss: 5.7601\n",
      "Epoch 71/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6221 - val_loss: 5.7492\n",
      "Epoch 72/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.6108 - val_loss: 5.7269\n",
      "Epoch 73/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6111 - val_loss: 5.7235\n",
      "Epoch 74/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5960 - val_loss: 5.7362\n",
      "Epoch 75/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5852 - val_loss: 5.7192\n",
      "Epoch 76/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5956 - val_loss: 5.7008\n",
      "Epoch 77/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5877 - val_loss: 5.7319\n",
      "Epoch 78/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5697 - val_loss: 5.7135\n",
      "Epoch 79/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5733 - val_loss: 5.6839\n",
      "Epoch 80/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5674 - val_loss: 5.7152\n",
      "Epoch 81/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5576 - val_loss: 5.6887\n",
      "Epoch 82/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5496 - val_loss: 5.6635\n",
      "Epoch 83/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5392 - val_loss: 5.6800\n",
      "Epoch 84/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5419 - val_loss: 5.6441\n",
      "Epoch 85/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5252 - val_loss: 5.6574\n",
      "Epoch 86/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5193 - val_loss: 5.6674\n",
      "Epoch 87/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5182 - val_loss: 5.6466\n",
      "Epoch 88/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5074 - val_loss: 5.6265\n",
      "Epoch 89/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5100 - val_loss: 5.6434\n",
      "Epoch 90/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5058 - val_loss: 5.6151\n",
      "Epoch 91/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4937 - val_loss: 5.5886\n",
      "Epoch 92/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4948 - val_loss: 5.5985\n",
      "Epoch 93/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4905 - val_loss: 5.6309\n",
      "Epoch 94/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4846 - val_loss: 5.6180\n",
      "Epoch 95/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4837 - val_loss: 5.6282\n",
      "Epoch 96/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.4703 - val_loss: 5.6124\n",
      "Epoch 97/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4721 - val_loss: 5.5911\n",
      "Epoch 98/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4636 - val_loss: 5.6024\n",
      "Epoch 99/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4641 - val_loss: 5.6017\n",
      "Epoch 100/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4528 - val_loss: 5.5964\n",
      "Epoch 101/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4504 - val_loss: 5.5759\n",
      "Epoch 102/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4442 - val_loss: 5.5738\n",
      "Epoch 103/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4420 - val_loss: 5.5859\n",
      "Epoch 104/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4484 - val_loss: 5.5995\n",
      "Epoch 105/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4506 - val_loss: 5.5489\n",
      "Epoch 106/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4366 - val_loss: 5.6017\n",
      "Epoch 107/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4400 - val_loss: 5.5903\n",
      "Epoch 108/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4263 - val_loss: 5.5602\n",
      "Epoch 109/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4194 - val_loss: 5.5539\n",
      "Epoch 110/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4205 - val_loss: 5.5505\n",
      "Epoch 111/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4144 - val_loss: 5.5347\n",
      "Epoch 112/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4076 - val_loss: 5.5462\n",
      "Epoch 113/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4122 - val_loss: 5.5588\n",
      "Epoch 114/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4049 - val_loss: 5.5109\n",
      "Epoch 115/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4115 - val_loss: 5.5357\n",
      "Epoch 116/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4040 - val_loss: 5.5258\n",
      "Epoch 117/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3969 - val_loss: 5.5104\n",
      "Epoch 118/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3903 - val_loss: 5.5237\n",
      "Epoch 119/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3929 - val_loss: 5.5249\n",
      "Epoch 120/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3882 - val_loss: 5.5187\n",
      "Epoch 121/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3886 - val_loss: 5.5159\n",
      "Epoch 122/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3823 - val_loss: 5.5154\n",
      "Epoch 123/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3855 - val_loss: 5.5065\n",
      "Epoch 124/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.3770 - val_loss: 5.5188\n",
      "Epoch 125/1300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.3767 - val_loss: 5.4884\n",
      "Epoch 126/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3773 - val_loss: 5.5017\n",
      "Epoch 127/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3747 - val_loss: 5.5153\n",
      "Epoch 128/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3717 - val_loss: 5.4832\n",
      "Epoch 129/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3700 - val_loss: 5.5024\n",
      "Epoch 130/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3589 - val_loss: 5.5050\n",
      "Epoch 131/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3641 - val_loss: 5.4816\n",
      "Epoch 132/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3609 - val_loss: 5.4605\n",
      "Epoch 133/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3675 - val_loss: 5.4674\n",
      "Epoch 134/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3518 - val_loss: 5.4892\n",
      "Epoch 135/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3536 - val_loss: 5.4683\n",
      "Epoch 136/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3512 - val_loss: 5.4626\n",
      "Epoch 137/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3560 - val_loss: 5.4747\n",
      "Epoch 138/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3518 - val_loss: 5.4689\n",
      "Epoch 139/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.3508 - val_loss: 5.4470\n",
      "Epoch 140/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3455 - val_loss: 5.4771\n",
      "Epoch 141/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3487 - val_loss: 5.4880\n",
      "Epoch 142/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3483 - val_loss: 5.4528\n",
      "Epoch 143/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3408 - val_loss: 5.4734\n",
      "Epoch 144/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3458 - val_loss: 5.4571\n",
      "Epoch 145/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.3323 - val_loss: 5.4247\n",
      "Epoch 146/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3496 - val_loss: 5.4187\n",
      "Epoch 147/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3597 - val_loss: 5.4808\n",
      "Epoch 148/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3417 - val_loss: 5.4270\n",
      "Epoch 149/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3526 - val_loss: 5.4546\n",
      "Epoch 150/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3384 - val_loss: 5.4170\n",
      "Epoch 151/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3455 - val_loss: 5.4042\n",
      "Epoch 152/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3280 - val_loss: 5.4498\n",
      "Epoch 153/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3248 - val_loss: 5.4242\n",
      "Epoch 154/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3322 - val_loss: 5.4002\n",
      "Epoch 155/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3233 - val_loss: 5.4479\n",
      "Epoch 156/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3272 - val_loss: 5.4375\n",
      "Epoch 157/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.3219 - val_loss: 5.4240\n",
      "Epoch 158/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3174 - val_loss: 5.3970\n",
      "Epoch 159/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3177 - val_loss: 5.4015\n",
      "Epoch 160/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3155 - val_loss: 5.3989\n",
      "Epoch 161/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3117 - val_loss: 5.3789\n",
      "Epoch 162/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3175 - val_loss: 5.4156\n",
      "Epoch 163/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3143 - val_loss: 5.4156\n",
      "Epoch 164/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3101 - val_loss: 5.4129\n",
      "Epoch 165/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3085 - val_loss: 5.3872\n",
      "Epoch 166/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3064 - val_loss: 5.4090\n",
      "Epoch 167/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3183 - val_loss: 5.4326\n",
      "Epoch 168/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3053 - val_loss: 5.3907\n",
      "Epoch 169/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3132 - val_loss: 5.3583\n",
      "Epoch 170/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3031 - val_loss: 5.3914\n",
      "Epoch 171/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.3118 - val_loss: 5.4086\n",
      "Epoch 172/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3072 - val_loss: 5.3865\n",
      "Epoch 173/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3062 - val_loss: 5.3888\n",
      "Epoch 174/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3052 - val_loss: 5.3679\n",
      "Epoch 175/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2994 - val_loss: 5.3945\n",
      "Epoch 176/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3124 - val_loss: 5.4004\n",
      "Epoch 177/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2959 - val_loss: 5.3762\n",
      "Epoch 178/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2896 - val_loss: 5.3508\n",
      "Epoch 179/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2946 - val_loss: 5.3411\n",
      "Epoch 180/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2903 - val_loss: 5.3710\n",
      "Epoch 181/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2951 - val_loss: 5.3777\n",
      "Epoch 182/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2900 - val_loss: 5.3530\n",
      "Epoch 183/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2837 - val_loss: 5.3474\n",
      "Epoch 184/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2812 - val_loss: 5.3518\n",
      "Epoch 185/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2833 - val_loss: 5.3571\n",
      "Epoch 186/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2850 - val_loss: 5.3486\n",
      "Epoch 187/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2815 - val_loss: 5.3537\n",
      "Epoch 188/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2834 - val_loss: 5.3653\n",
      "Epoch 189/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2751 - val_loss: 5.3584\n",
      "Epoch 190/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2765 - val_loss: 5.3300\n",
      "Epoch 191/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2777 - val_loss: 5.3324\n",
      "Epoch 192/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2782 - val_loss: 5.3706\n",
      "Epoch 193/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2764 - val_loss: 5.3244\n",
      "Epoch 194/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2768 - val_loss: 5.3533\n",
      "Epoch 195/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2759 - val_loss: 5.3104\n",
      "Epoch 196/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2694 - val_loss: 5.3202\n",
      "Epoch 197/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2681 - val_loss: 5.3387\n",
      "Epoch 198/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.2782 - val_loss: 5.3073\n",
      "Epoch 199/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2634 - val_loss: 5.3129\n",
      "Epoch 200/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2662 - val_loss: 5.3011\n",
      "Epoch 201/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2674 - val_loss: 5.3354\n",
      "Epoch 202/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2617 - val_loss: 5.3152\n",
      "Epoch 203/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2641 - val_loss: 5.2984\n",
      "Epoch 204/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2648 - val_loss: 5.3069\n",
      "Epoch 205/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2531 - val_loss: 5.3149\n",
      "Epoch 206/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2573 - val_loss: 5.2882\n",
      "Epoch 207/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2606 - val_loss: 5.2889\n",
      "Epoch 208/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2486 - val_loss: 5.3133\n",
      "Epoch 209/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2497 - val_loss: 5.3033\n",
      "Epoch 210/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2490 - val_loss: 5.2961\n",
      "Epoch 211/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2560 - val_loss: 5.2949\n",
      "Epoch 212/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2469 - val_loss: 5.2878\n",
      "Epoch 213/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2452 - val_loss: 5.2798\n",
      "Epoch 214/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2484 - val_loss: 5.2461\n",
      "Epoch 215/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2426 - val_loss: 5.2837\n",
      "Epoch 216/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2418 - val_loss: 5.2673\n",
      "Epoch 217/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2350 - val_loss: 5.2566\n",
      "Epoch 218/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2357 - val_loss: 5.2620\n",
      "Epoch 219/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2385 - val_loss: 5.2723\n",
      "Epoch 220/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2386 - val_loss: 5.2889\n",
      "Epoch 221/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2541 - val_loss: 5.2814\n",
      "Epoch 222/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2389 - val_loss: 5.2257\n",
      "Epoch 223/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2453 - val_loss: 5.2805\n",
      "Epoch 224/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2480 - val_loss: 5.2828\n",
      "Epoch 225/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2430 - val_loss: 5.2596\n",
      "Epoch 226/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2368 - val_loss: 5.2875\n",
      "Epoch 227/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2347 - val_loss: 5.2348\n",
      "Epoch 228/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2255 - val_loss: 5.2675\n",
      "Epoch 229/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2276 - val_loss: 5.2449\n",
      "Epoch 230/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2270 - val_loss: 5.2333\n",
      "Epoch 231/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2316 - val_loss: 5.2354\n",
      "Epoch 232/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2250 - val_loss: 5.2230\n",
      "Epoch 233/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2332 - val_loss: 5.2666\n",
      "Epoch 234/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2211 - val_loss: 5.2205\n",
      "Epoch 235/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2224 - val_loss: 5.2534\n",
      "Epoch 236/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2165 - val_loss: 5.2179\n",
      "Epoch 237/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2126 - val_loss: 5.2401\n",
      "Epoch 238/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2122 - val_loss: 5.2431\n",
      "Epoch 239/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2164 - val_loss: 5.2357\n",
      "Epoch 240/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.2093 - val_loss: 5.2405\n",
      "Epoch 241/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2104 - val_loss: 5.2317\n",
      "Epoch 242/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2209 - val_loss: 5.2739\n",
      "Epoch 243/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2144 - val_loss: 5.2042\n",
      "Epoch 244/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2091 - val_loss: 5.2494\n",
      "Epoch 245/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2080 - val_loss: 5.2210\n",
      "Epoch 246/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.2043 - val_loss: 5.2164\n",
      "Epoch 247/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2057 - val_loss: 5.1967\n",
      "Epoch 248/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2004 - val_loss: 5.2006\n",
      "Epoch 249/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2216 - val_loss: 5.2555\n",
      "Epoch 250/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.2036 - val_loss: 5.1799\n",
      "Epoch 251/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2065 - val_loss: 5.2022\n",
      "Epoch 252/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1977 - val_loss: 5.1753\n",
      "Epoch 253/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.2006 - val_loss: 5.1885\n",
      "Epoch 254/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1927 - val_loss: 5.1755\n",
      "Epoch 255/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1901 - val_loss: 5.1814\n",
      "Epoch 256/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1939 - val_loss: 5.1782\n",
      "Epoch 257/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1829 - val_loss: 5.1865\n",
      "Epoch 258/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1889 - val_loss: 5.1905\n",
      "Epoch 259/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1951 - val_loss: 5.1768\n",
      "Epoch 260/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1855 - val_loss: 5.1662\n",
      "Epoch 261/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1877 - val_loss: 5.1698\n",
      "Epoch 262/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1775 - val_loss: 5.1683\n",
      "Epoch 263/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1862 - val_loss: 5.1743\n",
      "Epoch 264/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1898 - val_loss: 5.1779\n",
      "Epoch 265/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1727 - val_loss: 5.1657\n",
      "Epoch 266/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1872 - val_loss: 5.1478\n",
      "Epoch 267/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1825 - val_loss: 5.1767\n",
      "Epoch 268/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1797 - val_loss: 5.1536\n",
      "Epoch 269/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1670 - val_loss: 5.1743\n",
      "Epoch 270/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1762 - val_loss: 5.1547\n",
      "Epoch 271/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1696 - val_loss: 5.1604\n",
      "Epoch 272/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1738 - val_loss: 5.1550\n",
      "Epoch 273/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1843 - val_loss: 5.1383\n",
      "Epoch 274/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1607 - val_loss: 5.1455\n",
      "Epoch 275/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1838 - val_loss: 5.1059\n",
      "Epoch 276/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1668 - val_loss: 5.1446\n",
      "Epoch 277/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1654 - val_loss: 5.1174\n",
      "Epoch 278/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1592 - val_loss: 5.1319\n",
      "Epoch 279/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1569 - val_loss: 5.1232\n",
      "Epoch 280/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1594 - val_loss: 5.1214\n",
      "Epoch 281/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1534 - val_loss: 5.1321\n",
      "Epoch 282/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1585 - val_loss: 5.1531\n",
      "Epoch 283/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1564 - val_loss: 5.1254\n",
      "Epoch 284/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1491 - val_loss: 5.1345\n",
      "Epoch 285/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1419 - val_loss: 5.1054\n",
      "Epoch 286/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1538 - val_loss: 5.0907\n",
      "Epoch 287/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1537 - val_loss: 5.0876\n",
      "Epoch 288/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1434 - val_loss: 5.0934\n",
      "Epoch 289/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1442 - val_loss: 5.1040\n",
      "Epoch 290/1300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1424 - val_loss: 5.1141\n",
      "Epoch 291/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1488 - val_loss: 5.1214\n",
      "Epoch 292/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1495 - val_loss: 5.1245\n",
      "Epoch 293/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1463 - val_loss: 5.1195\n",
      "Epoch 294/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1333 - val_loss: 5.1019\n",
      "Epoch 295/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1324 - val_loss: 5.1072\n",
      "Epoch 296/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1331 - val_loss: 5.0971\n",
      "Epoch 297/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1333 - val_loss: 5.0746\n",
      "Epoch 298/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1469 - val_loss: 5.0871\n",
      "Epoch 299/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1436 - val_loss: 5.1103\n",
      "Epoch 300/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1483 - val_loss: 5.1112\n",
      "Epoch 301/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1377 - val_loss: 5.0804\n",
      "Epoch 302/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1249 - val_loss: 5.0830\n",
      "Epoch 303/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1238 - val_loss: 5.0931\n",
      "Epoch 304/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1254 - val_loss: 5.0741\n",
      "Epoch 305/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1222 - val_loss: 5.0776\n",
      "Epoch 306/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1223 - val_loss: 5.0747\n",
      "Epoch 307/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1193 - val_loss: 5.0987\n",
      "Epoch 308/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1344 - val_loss: 5.1095\n",
      "Epoch 309/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1248 - val_loss: 5.0720\n",
      "Epoch 310/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1231 - val_loss: 5.0774\n",
      "Epoch 311/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1156 - val_loss: 5.0842\n",
      "Epoch 312/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1134 - val_loss: 5.0611\n",
      "Epoch 313/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1297 - val_loss: 5.0369\n",
      "Epoch 314/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1108 - val_loss: 5.0622\n",
      "Epoch 315/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1161 - val_loss: 5.0550\n",
      "Epoch 316/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1156 - val_loss: 5.0564\n",
      "Epoch 317/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1066 - val_loss: 5.0496\n",
      "Epoch 318/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1047 - val_loss: 5.0594\n",
      "Epoch 319/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1038 - val_loss: 5.0369\n",
      "Epoch 320/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1137 - val_loss: 5.0548\n",
      "Epoch 321/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1046 - val_loss: 5.0465\n",
      "Epoch 322/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1022 - val_loss: 5.0558\n",
      "Epoch 323/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0959 - val_loss: 5.0446\n",
      "Epoch 324/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0981 - val_loss: 5.0385\n",
      "Epoch 325/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1078 - val_loss: 5.0208\n",
      "Epoch 326/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1016 - val_loss: 5.0223\n",
      "Epoch 327/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0967 - val_loss: 5.0117\n",
      "Epoch 328/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0986 - val_loss: 5.0427\n",
      "Epoch 329/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.0961 - val_loss: 5.0458\n",
      "Epoch 330/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0886 - val_loss: 5.0258\n",
      "Epoch 331/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0944 - val_loss: 4.9932\n",
      "Epoch 332/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0931 - val_loss: 5.0333\n",
      "Epoch 333/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0988 - val_loss: 5.0392\n",
      "Epoch 334/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0921 - val_loss: 5.0152\n",
      "Epoch 335/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0816 - val_loss: 5.0130\n",
      "Epoch 336/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0988 - val_loss: 5.0140\n",
      "Epoch 337/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0872 - val_loss: 4.9942\n",
      "Epoch 338/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0743 - val_loss: 4.9977\n",
      "Epoch 339/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0791 - val_loss: 4.9723\n",
      "Epoch 340/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0872 - val_loss: 4.9993\n",
      "Epoch 341/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0827 - val_loss: 5.0012\n",
      "Epoch 342/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0847 - val_loss: 4.9612\n",
      "Epoch 343/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0808 - val_loss: 5.0214\n",
      "Epoch 344/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0908 - val_loss: 5.0080\n",
      "Epoch 345/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0704 - val_loss: 4.9981\n",
      "Epoch 346/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0667 - val_loss: 4.9882\n",
      "Epoch 347/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0620 - val_loss: 4.9756\n",
      "Epoch 348/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0667 - val_loss: 4.9582\n",
      "Epoch 349/1300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0698 - val_loss: 4.9803\n",
      "Epoch 350/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0673 - val_loss: 4.9918\n",
      "Epoch 351/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0632 - val_loss: 4.9638\n",
      "Epoch 352/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0603 - val_loss: 4.9769\n",
      "Epoch 353/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0624 - val_loss: 4.9727\n",
      "Epoch 354/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0637 - val_loss: 4.9460\n",
      "Epoch 355/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0536 - val_loss: 4.9531\n",
      "Epoch 356/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0522 - val_loss: 4.9716\n",
      "Epoch 357/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0667 - val_loss: 4.9802\n",
      "Epoch 358/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0603 - val_loss: 4.9747\n",
      "Epoch 359/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0556 - val_loss: 4.9481\n",
      "Epoch 360/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0586 - val_loss: 4.9392\n",
      "Epoch 361/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0721 - val_loss: 4.9813\n",
      "Epoch 362/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0539 - val_loss: 4.9490\n",
      "Epoch 363/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0516 - val_loss: 4.9586\n",
      "Epoch 364/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0523 - val_loss: 4.9528\n",
      "Epoch 365/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0517 - val_loss: 4.9206\n",
      "Epoch 366/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0477 - val_loss: 4.9421\n",
      "Epoch 367/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0339 - val_loss: 4.9291\n",
      "Epoch 368/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0346 - val_loss: 4.9282\n",
      "Epoch 369/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0268 - val_loss: 4.9225\n",
      "Epoch 370/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0357 - val_loss: 4.9384\n",
      "Epoch 371/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0304 - val_loss: 4.9278\n",
      "Epoch 372/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0328 - val_loss: 4.9232\n",
      "Epoch 373/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0273 - val_loss: 4.9271\n",
      "Epoch 374/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0312 - val_loss: 4.9420\n",
      "Epoch 375/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0339 - val_loss: 4.9373\n",
      "Epoch 376/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0452 - val_loss: 4.8989\n",
      "Epoch 377/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0340 - val_loss: 4.9349\n",
      "Epoch 378/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0342 - val_loss: 4.9208\n",
      "Epoch 379/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0361 - val_loss: 4.9270\n",
      "Epoch 380/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.0182 - val_loss: 4.9210\n",
      "Epoch 381/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0277 - val_loss: 4.8957\n",
      "Epoch 382/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0209 - val_loss: 4.8649\n",
      "Epoch 383/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0240 - val_loss: 4.8918\n",
      "Epoch 384/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0126 - val_loss: 4.8872\n",
      "Epoch 385/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0087 - val_loss: 4.8998\n",
      "Epoch 386/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0118 - val_loss: 4.8895\n",
      "Epoch 387/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0102 - val_loss: 4.8897\n",
      "Epoch 388/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0137 - val_loss: 4.8474\n",
      "Epoch 389/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.0077 - val_loss: 4.8519\n",
      "Epoch 390/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9996 - val_loss: 4.8734\n",
      "Epoch 391/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0075 - val_loss: 4.8540\n",
      "Epoch 392/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0054 - val_loss: 4.8692\n",
      "Epoch 393/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0002 - val_loss: 4.8620\n",
      "Epoch 394/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0011 - val_loss: 4.8631\n",
      "Epoch 395/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0040 - val_loss: 4.8597\n",
      "Epoch 396/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9980 - val_loss: 4.8002\n",
      "Epoch 397/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0123 - val_loss: 4.8476\n",
      "Epoch 398/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9986 - val_loss: 4.8575\n",
      "Epoch 399/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0009 - val_loss: 4.8608\n",
      "Epoch 400/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9889 - val_loss: 4.8191\n",
      "Epoch 401/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9923 - val_loss: 4.8177\n",
      "Epoch 402/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9996 - val_loss: 4.7937\n",
      "Epoch 403/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9807 - val_loss: 4.8501\n",
      "Epoch 404/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9854 - val_loss: 4.8015\n",
      "Epoch 405/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9780 - val_loss: 4.8154\n",
      "Epoch 406/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9874 - val_loss: 4.7957\n",
      "Epoch 407/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9751 - val_loss: 4.8230\n",
      "Epoch 408/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9810 - val_loss: 4.8010\n",
      "Epoch 409/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9717 - val_loss: 4.8361\n",
      "Epoch 410/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9831 - val_loss: 4.7872\n",
      "Epoch 411/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9684 - val_loss: 4.7954\n",
      "Epoch 412/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9910 - val_loss: 4.7868\n",
      "Epoch 413/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9694 - val_loss: 4.8144\n",
      "Epoch 414/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9761 - val_loss: 4.7851\n",
      "Epoch 415/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9772 - val_loss: 4.7828\n",
      "Epoch 416/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9666 - val_loss: 4.7766\n",
      "Epoch 417/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9623 - val_loss: 4.7718\n",
      "Epoch 418/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9689 - val_loss: 4.7613\n",
      "Epoch 419/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9550 - val_loss: 4.7688\n",
      "Epoch 420/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9732 - val_loss: 4.7630\n",
      "Epoch 421/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9492 - val_loss: 4.7802\n",
      "Epoch 422/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9553 - val_loss: 4.7716\n",
      "Epoch 423/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9520 - val_loss: 4.7524\n",
      "Epoch 424/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9539 - val_loss: 4.7396\n",
      "Epoch 425/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9395 - val_loss: 4.7602\n",
      "Epoch 426/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9448 - val_loss: 4.7424\n",
      "Epoch 427/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9420 - val_loss: 4.7334\n",
      "Epoch 428/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9460 - val_loss: 4.7506\n",
      "Epoch 429/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9430 - val_loss: 4.7064\n",
      "Epoch 430/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9356 - val_loss: 4.7374\n",
      "Epoch 431/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9296 - val_loss: 4.7331\n",
      "Epoch 432/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9269 - val_loss: 4.7048\n",
      "Epoch 433/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9407 - val_loss: 4.7354\n",
      "Epoch 434/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9347 - val_loss: 4.7177\n",
      "Epoch 435/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9292 - val_loss: 4.7051\n",
      "Epoch 436/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9160 - val_loss: 4.7133\n",
      "Epoch 437/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9169 - val_loss: 4.7086\n",
      "Epoch 438/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9195 - val_loss: 4.6879\n",
      "Epoch 439/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9162 - val_loss: 4.6751\n",
      "Epoch 440/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9201 - val_loss: 4.6792\n",
      "Epoch 441/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9219 - val_loss: 4.6879\n",
      "Epoch 442/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9164 - val_loss: 4.7250\n",
      "Epoch 443/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9105 - val_loss: 4.6807\n",
      "Epoch 444/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9354 - val_loss: 4.6863\n",
      "Epoch 445/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9208 - val_loss: 4.7037\n",
      "Epoch 446/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9191 - val_loss: 4.6633\n",
      "Epoch 447/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9137 - val_loss: 4.6318\n",
      "Epoch 448/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9122 - val_loss: 4.6133\n",
      "Epoch 449/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9068 - val_loss: 4.6258\n",
      "Epoch 450/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8981 - val_loss: 4.6543\n",
      "Epoch 451/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8969 - val_loss: 4.6231\n",
      "Epoch 452/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9023 - val_loss: 4.6362\n",
      "Epoch 453/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8997 - val_loss: 4.6414\n",
      "Epoch 454/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9145 - val_loss: 4.6281\n",
      "Epoch 455/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9021 - val_loss: 4.6352\n",
      "Epoch 456/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8956 - val_loss: 4.6360\n",
      "Epoch 457/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8910 - val_loss: 4.6012\n",
      "Epoch 458/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9084 - val_loss: 4.6065\n",
      "Epoch 459/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8931 - val_loss: 4.6024\n",
      "Epoch 460/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8945 - val_loss: 4.6484\n",
      "Epoch 461/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8935 - val_loss: 4.6426\n",
      "Epoch 462/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9005 - val_loss: 4.5866\n",
      "Epoch 463/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8883 - val_loss: 4.5884\n",
      "Epoch 464/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8710 - val_loss: 4.5942\n",
      "Epoch 465/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8664 - val_loss: 4.5928\n",
      "Epoch 466/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8796 - val_loss: 4.5863\n",
      "Epoch 467/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8629 - val_loss: 4.5697\n",
      "Epoch 468/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8651 - val_loss: 4.5747\n",
      "Epoch 469/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8756 - val_loss: 4.5752\n",
      "Epoch 470/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8765 - val_loss: 4.5572\n",
      "Epoch 471/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8654 - val_loss: 4.5580\n",
      "Epoch 472/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8656 - val_loss: 4.5507\n",
      "Epoch 473/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8579 - val_loss: 4.5574\n",
      "Epoch 474/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8621 - val_loss: 4.5691\n",
      "Epoch 475/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8559 - val_loss: 4.5388\n",
      "Epoch 476/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8516 - val_loss: 4.5481\n",
      "Epoch 477/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8653 - val_loss: 4.5200\n",
      "Epoch 478/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8581 - val_loss: 4.5447\n",
      "Epoch 479/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8554 - val_loss: 4.5432\n",
      "Epoch 480/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8526 - val_loss: 4.5663\n",
      "Epoch 481/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8521 - val_loss: 4.5073\n",
      "Epoch 482/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8552 - val_loss: 4.5200\n",
      "Epoch 483/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8446 - val_loss: 4.4927\n",
      "Epoch 484/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8580 - val_loss: 4.5183\n",
      "Epoch 485/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8445 - val_loss: 4.5163\n",
      "Epoch 486/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8335 - val_loss: 4.5070\n",
      "Epoch 487/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8333 - val_loss: 4.4834\n",
      "Epoch 488/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8281 - val_loss: 4.4921\n",
      "Epoch 489/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.8252 - val_loss: 4.4717\n",
      "Epoch 490/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8259 - val_loss: 4.4884\n",
      "Epoch 491/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8288 - val_loss: 4.4640\n",
      "Epoch 492/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8255 - val_loss: 4.4855\n",
      "Epoch 493/1300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.8210 - val_loss: 4.4548\n",
      "Epoch 494/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8219 - val_loss: 4.4432\n",
      "Epoch 495/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8142 - val_loss: 4.4491\n",
      "Epoch 496/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8157 - val_loss: 4.4947\n",
      "Epoch 497/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8317 - val_loss: 4.4550\n",
      "Epoch 498/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8243 - val_loss: 4.4416\n",
      "Epoch 499/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8105 - val_loss: 4.4411\n",
      "Epoch 500/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8205 - val_loss: 4.4477\n",
      "Epoch 501/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8234 - val_loss: 4.4357\n",
      "Epoch 502/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8230 - val_loss: 4.4073\n",
      "Epoch 503/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8242 - val_loss: 4.4273\n",
      "Epoch 504/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8321 - val_loss: 4.4217\n",
      "Epoch 505/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8112 - val_loss: 4.4264\n",
      "Epoch 506/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8222 - val_loss: 4.4145\n",
      "Epoch 507/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.8088 - val_loss: 4.4238\n",
      "Epoch 508/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8080 - val_loss: 4.3973\n",
      "Epoch 509/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7981 - val_loss: 4.3858\n",
      "Epoch 510/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7896 - val_loss: 4.4194\n",
      "Epoch 511/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7950 - val_loss: 4.4037\n",
      "Epoch 512/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7860 - val_loss: 4.3909\n",
      "Epoch 513/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7868 - val_loss: 4.4064\n",
      "Epoch 514/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7857 - val_loss: 4.3742\n",
      "Epoch 515/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7831 - val_loss: 4.3719\n",
      "Epoch 516/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7752 - val_loss: 4.3710\n",
      "Epoch 517/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7846 - val_loss: 4.3794\n",
      "Epoch 518/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.8057 - val_loss: 4.3438\n",
      "Epoch 519/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7798 - val_loss: 4.3535\n",
      "Epoch 520/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7737 - val_loss: 4.3429\n",
      "Epoch 521/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7701 - val_loss: 4.3296\n",
      "Epoch 522/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7901 - val_loss: 4.3314\n",
      "Epoch 523/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7785 - val_loss: 4.3205\n",
      "Epoch 524/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7802 - val_loss: 4.3548\n",
      "Epoch 525/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7623 - val_loss: 4.3330\n",
      "Epoch 526/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7620 - val_loss: 4.3493\n",
      "Epoch 527/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.7641 - val_loss: 4.3159\n",
      "Epoch 528/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.7617 - val_loss: 4.3217\n",
      "Epoch 529/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7671 - val_loss: 4.3048\n",
      "Epoch 530/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7605 - val_loss: 4.3301\n",
      "Epoch 531/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7693 - val_loss: 4.2628\n",
      "Epoch 532/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7664 - val_loss: 4.3037\n",
      "Epoch 533/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7678 - val_loss: 4.3175\n",
      "Epoch 534/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7523 - val_loss: 4.3048\n",
      "Epoch 535/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7469 - val_loss: 4.2904\n",
      "Epoch 536/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7419 - val_loss: 4.3282\n",
      "Epoch 537/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7424 - val_loss: 4.3242\n",
      "Epoch 538/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7400 - val_loss: 4.3101\n",
      "Epoch 539/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7362 - val_loss: 4.2851\n",
      "Epoch 540/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7372 - val_loss: 4.2685\n",
      "Epoch 541/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7454 - val_loss: 4.2943\n",
      "Epoch 542/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7517 - val_loss: 4.2880\n",
      "Epoch 543/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7978 - val_loss: 4.2777\n",
      "Epoch 544/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7520 - val_loss: 4.2525\n",
      "Epoch 545/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7501 - val_loss: 4.2927\n",
      "Epoch 546/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7857 - val_loss: 4.2669\n",
      "Epoch 547/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7437 - val_loss: 4.2853\n",
      "Epoch 548/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7368 - val_loss: 4.2404\n",
      "Epoch 549/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7249 - val_loss: 4.2614\n",
      "Epoch 550/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7097 - val_loss: 4.2604\n",
      "Epoch 551/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7290 - val_loss: 4.2851\n",
      "Epoch 552/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7294 - val_loss: 4.2468\n",
      "Epoch 553/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7309 - val_loss: 4.2532\n",
      "Epoch 554/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7130 - val_loss: 4.2556\n",
      "Epoch 555/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7149 - val_loss: 4.3026\n",
      "Epoch 556/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7092 - val_loss: 4.2501\n",
      "Epoch 557/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7119 - val_loss: 4.2586\n",
      "Epoch 558/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7126 - val_loss: 4.2690\n",
      "Epoch 559/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7055 - val_loss: 4.2497\n",
      "Epoch 560/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7030 - val_loss: 4.2526\n",
      "Epoch 561/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7126 - val_loss: 4.2629\n",
      "Epoch 562/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7074 - val_loss: 4.2779\n",
      "Epoch 563/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6981 - val_loss: 4.2441\n",
      "Epoch 564/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6978 - val_loss: 4.2441\n",
      "Epoch 565/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7066 - val_loss: 4.2702\n",
      "Epoch 566/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6950 - val_loss: 4.2568\n",
      "Epoch 567/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6856 - val_loss: 4.2143\n",
      "Epoch 568/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6918 - val_loss: 4.2319\n",
      "Epoch 569/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6939 - val_loss: 4.2193\n",
      "Epoch 570/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6964 - val_loss: 4.2570\n",
      "Epoch 571/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6888 - val_loss: 4.2119\n",
      "Epoch 572/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6839 - val_loss: 4.2357\n",
      "Epoch 573/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6981 - val_loss: 4.2221\n",
      "Epoch 574/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6757 - val_loss: 4.2790\n",
      "Epoch 575/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6987 - val_loss: 4.2227\n",
      "Epoch 576/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6728 - val_loss: 4.2100\n",
      "Epoch 577/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.6771 - val_loss: 4.1984\n",
      "Epoch 578/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6722 - val_loss: 4.1997\n",
      "Epoch 579/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6716 - val_loss: 4.2144\n",
      "Epoch 580/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6793 - val_loss: 4.1934\n",
      "Epoch 581/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6677 - val_loss: 4.2219\n",
      "Epoch 582/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6763 - val_loss: 4.2108\n",
      "Epoch 583/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6639 - val_loss: 4.1863\n",
      "Epoch 584/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6596 - val_loss: 4.1975\n",
      "Epoch 585/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6593 - val_loss: 4.2221\n",
      "Epoch 586/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6550 - val_loss: 4.1907\n",
      "Epoch 587/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6531 - val_loss: 4.1982\n",
      "Epoch 588/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6570 - val_loss: 4.2047\n",
      "Epoch 589/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6538 - val_loss: 4.1979\n",
      "Epoch 590/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6542 - val_loss: 4.2068\n",
      "Epoch 591/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6611 - val_loss: 4.1528\n",
      "Epoch 592/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6594 - val_loss: 4.2030\n",
      "Epoch 593/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6841 - val_loss: 4.2032\n",
      "Epoch 594/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6704 - val_loss: 4.1966\n",
      "Epoch 595/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6642 - val_loss: 4.1218\n",
      "Epoch 596/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6544 - val_loss: 4.1692\n",
      "Epoch 597/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6716 - val_loss: 4.2104\n",
      "Epoch 598/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6472 - val_loss: 4.2183\n",
      "Epoch 599/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6493 - val_loss: 4.1827\n",
      "Epoch 600/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6401 - val_loss: 4.1819\n",
      "Epoch 601/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6435 - val_loss: 4.1987\n",
      "Epoch 602/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6758 - val_loss: 4.1461\n",
      "Epoch 603/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6990 - val_loss: 4.1465\n",
      "Epoch 604/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6901 - val_loss: 4.2382\n",
      "Epoch 605/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6430 - val_loss: 4.1718\n",
      "Epoch 606/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6559 - val_loss: 4.1827\n",
      "Epoch 607/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6506 - val_loss: 4.1330\n",
      "Epoch 608/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6375 - val_loss: 4.1916\n",
      "Epoch 609/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6317 - val_loss: 4.1615\n",
      "Epoch 610/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6475 - val_loss: 4.1330\n",
      "Epoch 611/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6471 - val_loss: 4.1461\n",
      "Epoch 612/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6403 - val_loss: 4.1491\n",
      "Epoch 613/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6169 - val_loss: 4.1605\n",
      "Epoch 614/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6185 - val_loss: 4.1346\n",
      "Epoch 615/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6296 - val_loss: 4.1392\n",
      "Epoch 616/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6129 - val_loss: 4.1288\n",
      "Epoch 617/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6079 - val_loss: 4.1432\n",
      "Epoch 618/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6206 - val_loss: 4.1564\n",
      "Epoch 619/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6108 - val_loss: 4.1403\n",
      "Epoch 620/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6278 - val_loss: 4.0887\n",
      "Epoch 621/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6067 - val_loss: 4.1570\n",
      "Epoch 622/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6149 - val_loss: 4.1477\n",
      "Epoch 623/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5933 - val_loss: 4.1814\n",
      "Epoch 624/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6252 - val_loss: 4.1137\n",
      "Epoch 625/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6228 - val_loss: 4.1568\n",
      "Epoch 626/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6097 - val_loss: 4.1560\n",
      "Epoch 627/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6176 - val_loss: 4.1342\n",
      "Epoch 628/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5992 - val_loss: 4.0902\n",
      "Epoch 629/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5894 - val_loss: 4.1428\n",
      "Epoch 630/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5888 - val_loss: 4.1258\n",
      "Epoch 631/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5861 - val_loss: 4.0994\n",
      "Epoch 632/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6045 - val_loss: 4.1207\n",
      "Epoch 633/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5928 - val_loss: 4.1333\n",
      "Epoch 634/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5944 - val_loss: 4.1512\n",
      "Epoch 635/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5847 - val_loss: 4.0596\n",
      "Epoch 636/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5991 - val_loss: 4.0953\n",
      "Epoch 637/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5932 - val_loss: 4.1667\n",
      "Epoch 638/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5822 - val_loss: 4.1002\n",
      "Epoch 639/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5815 - val_loss: 4.0940\n",
      "Epoch 640/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5980 - val_loss: 4.0789\n",
      "Epoch 641/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5912 - val_loss: 4.1114\n",
      "Epoch 642/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5830 - val_loss: 4.1174\n",
      "Epoch 643/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5766 - val_loss: 4.0857\n",
      "Epoch 644/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5791 - val_loss: 4.1273\n",
      "Epoch 645/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5711 - val_loss: 4.0901\n",
      "Epoch 646/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5723 - val_loss: 4.0859\n",
      "Epoch 647/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5656 - val_loss: 4.0849\n",
      "Epoch 648/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5693 - val_loss: 4.0866\n",
      "Epoch 649/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5585 - val_loss: 4.1201\n",
      "Epoch 650/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5607 - val_loss: 4.0583\n",
      "Epoch 651/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5555 - val_loss: 4.0944\n",
      "Epoch 652/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5747 - val_loss: 4.1041\n",
      "Epoch 653/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5596 - val_loss: 4.0289\n",
      "Epoch 654/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5569 - val_loss: 4.0627\n",
      "Epoch 655/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5544 - val_loss: 4.0399\n",
      "Epoch 656/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5623 - val_loss: 4.0748\n",
      "Epoch 657/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.5528 - val_loss: 4.0440\n",
      "Epoch 658/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5617 - val_loss: 4.0241\n",
      "Epoch 659/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5763 - val_loss: 4.1131\n",
      "Epoch 660/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5827 - val_loss: 4.0977\n",
      "Epoch 661/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5688 - val_loss: 4.0727\n",
      "Epoch 662/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5437 - val_loss: 4.0228\n",
      "Epoch 663/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5416 - val_loss: 4.0442\n",
      "Epoch 664/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5638 - val_loss: 4.0193\n",
      "Epoch 665/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5347 - val_loss: 4.0838\n",
      "Epoch 666/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5459 - val_loss: 4.0499\n",
      "Epoch 667/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5443 - val_loss: 4.0928\n",
      "Epoch 668/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5618 - val_loss: 4.0050\n",
      "Epoch 669/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5326 - val_loss: 4.0606\n",
      "Epoch 670/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5290 - val_loss: 4.0602\n",
      "Epoch 671/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5472 - val_loss: 4.0306\n",
      "Epoch 672/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5333 - val_loss: 4.0550\n",
      "Epoch 673/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5323 - val_loss: 4.0956\n",
      "Epoch 674/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5438 - val_loss: 4.0102\n",
      "Epoch 675/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5767 - val_loss: 4.0491\n",
      "Epoch 676/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5612 - val_loss: 4.0454\n",
      "Epoch 677/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5518 - val_loss: 4.0951\n",
      "Epoch 678/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5375 - val_loss: 4.0274\n",
      "Epoch 679/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5342 - val_loss: 4.0850\n",
      "Epoch 680/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5121 - val_loss: 4.0426\n",
      "Epoch 681/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5054 - val_loss: 4.0433\n",
      "Epoch 682/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5038 - val_loss: 4.0683\n",
      "Epoch 683/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5023 - val_loss: 4.0399\n",
      "Epoch 684/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5159 - val_loss: 3.9870\n",
      "Epoch 685/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5111 - val_loss: 4.0380\n",
      "Epoch 686/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5047 - val_loss: 4.0472\n",
      "Epoch 687/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5100 - val_loss: 4.0357\n",
      "Epoch 688/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5056 - val_loss: 4.0115\n",
      "Epoch 689/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5509 - val_loss: 4.0630\n",
      "Epoch 690/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5156 - val_loss: 4.0035\n",
      "Epoch 691/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5409 - val_loss: 4.0045\n",
      "Epoch 692/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5094 - val_loss: 4.0694\n",
      "Epoch 693/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5172 - val_loss: 4.0294\n",
      "Epoch 694/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5021 - val_loss: 4.0377\n",
      "Epoch 695/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5018 - val_loss: 3.9909\n",
      "Epoch 696/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5068 - val_loss: 4.0655\n",
      "Epoch 697/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5042 - val_loss: 3.9913\n",
      "Epoch 698/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.5041 - val_loss: 4.0020\n",
      "Epoch 699/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4873 - val_loss: 4.0132\n",
      "Epoch 700/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4955 - val_loss: 4.0468\n",
      "Epoch 701/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4931 - val_loss: 4.0149\n",
      "Epoch 702/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4852 - val_loss: 3.9761\n",
      "Epoch 703/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5009 - val_loss: 4.0467\n",
      "Epoch 704/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5189 - val_loss: 4.0488\n",
      "Epoch 705/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5309 - val_loss: 4.0047\n",
      "Epoch 706/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5082 - val_loss: 4.0048\n",
      "Epoch 707/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5056 - val_loss: 3.9798\n",
      "Epoch 708/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5173 - val_loss: 4.0275\n",
      "Epoch 709/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4767 - val_loss: 4.0061\n",
      "Epoch 710/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4658 - val_loss: 4.0111\n",
      "Epoch 711/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4775 - val_loss: 4.0221\n",
      "Epoch 712/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4706 - val_loss: 4.0065\n",
      "Epoch 713/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4729 - val_loss: 4.0063\n",
      "Epoch 714/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4774 - val_loss: 3.9971\n",
      "Epoch 715/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4849 - val_loss: 3.9771\n",
      "Epoch 716/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5114 - val_loss: 4.0519\n",
      "Epoch 717/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4821 - val_loss: 3.9974\n",
      "Epoch 718/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4869 - val_loss: 4.0100\n",
      "Epoch 719/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4789 - val_loss: 3.9644\n",
      "Epoch 720/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4923 - val_loss: 4.0491\n",
      "Epoch 721/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4823 - val_loss: 4.0005\n",
      "Epoch 722/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4647 - val_loss: 3.9933\n",
      "Epoch 723/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4566 - val_loss: 3.9484\n",
      "Epoch 724/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4839 - val_loss: 4.0238\n",
      "Epoch 725/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5013 - val_loss: 3.9875\n",
      "Epoch 726/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4673 - val_loss: 4.0112\n",
      "Epoch 727/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4835 - val_loss: 3.9793\n",
      "Epoch 728/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4591 - val_loss: 4.0246\n",
      "Epoch 729/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4510 - val_loss: 3.9900\n",
      "Epoch 730/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4647 - val_loss: 4.0084\n",
      "Epoch 731/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4871 - val_loss: 3.9809\n",
      "Epoch 732/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4820 - val_loss: 4.0236\n",
      "Epoch 733/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4562 - val_loss: 4.0074\n",
      "Epoch 734/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4466 - val_loss: 3.9803\n",
      "Epoch 735/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4519 - val_loss: 3.9315\n",
      "Epoch 736/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4552 - val_loss: 4.0111\n",
      "Epoch 737/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4626 - val_loss: 3.9913\n",
      "Epoch 738/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4530 - val_loss: 3.9837\n",
      "Epoch 739/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4436 - val_loss: 3.9633\n",
      "Epoch 740/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4501 - val_loss: 3.9902\n",
      "Epoch 741/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4362 - val_loss: 3.9504\n",
      "Epoch 742/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4493 - val_loss: 3.9696\n",
      "Epoch 743/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4454 - val_loss: 3.9708\n",
      "Epoch 744/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4415 - val_loss: 3.9716\n",
      "Epoch 745/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4443 - val_loss: 3.9660\n",
      "Epoch 746/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4448 - val_loss: 3.9287\n",
      "Epoch 747/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4502 - val_loss: 4.0141\n",
      "Epoch 748/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4367 - val_loss: 3.9774\n",
      "Epoch 749/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4709 - val_loss: 3.9618\n",
      "Epoch 750/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4361 - val_loss: 3.9558\n",
      "Epoch 751/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4278 - val_loss: 3.9523\n",
      "Epoch 752/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4387 - val_loss: 3.9754\n",
      "Epoch 753/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4300 - val_loss: 3.9585\n",
      "Epoch 754/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4298 - val_loss: 3.9665\n",
      "Epoch 755/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4433 - val_loss: 3.9578\n",
      "Epoch 756/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4603 - val_loss: 3.9133\n",
      "Epoch 757/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4555 - val_loss: 3.9185\n",
      "Epoch 758/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4568 - val_loss: 3.9922\n",
      "Epoch 759/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4216 - val_loss: 3.9384\n",
      "Epoch 760/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4299 - val_loss: 3.9663\n",
      "Epoch 761/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4340 - val_loss: 3.8970\n",
      "Epoch 762/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4314 - val_loss: 3.9833\n",
      "Epoch 763/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4441 - val_loss: 3.9550\n",
      "Epoch 764/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4242 - val_loss: 3.9332\n",
      "Epoch 765/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4322 - val_loss: 3.9419\n",
      "Epoch 766/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4190 - val_loss: 3.9316\n",
      "Epoch 767/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4272 - val_loss: 3.9375\n",
      "Epoch 768/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4120 - val_loss: 3.9336\n",
      "Epoch 769/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4145 - val_loss: 3.9617\n",
      "Epoch 770/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.4219 - val_loss: 3.9431\n",
      "Epoch 771/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4181 - val_loss: 3.9218\n",
      "Epoch 772/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4269 - val_loss: 3.9289\n",
      "Epoch 773/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4273 - val_loss: 3.9787\n",
      "Epoch 774/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4690 - val_loss: 4.0182\n",
      "Epoch 775/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4324 - val_loss: 3.9266\n",
      "Epoch 776/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4595 - val_loss: 4.0077\n",
      "Epoch 777/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4480 - val_loss: 3.9361\n",
      "Epoch 778/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4402 - val_loss: 3.9458\n",
      "Epoch 779/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4416 - val_loss: 3.9076\n",
      "Epoch 780/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4260 - val_loss: 3.9734\n",
      "Epoch 781/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4151 - val_loss: 3.9402\n",
      "Epoch 782/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4388 - val_loss: 3.9323\n",
      "Epoch 783/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4254 - val_loss: 3.9350\n",
      "Epoch 784/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4277 - val_loss: 3.9544\n",
      "Epoch 785/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4249 - val_loss: 3.9167\n",
      "Epoch 786/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4212 - val_loss: 3.9382\n",
      "Epoch 787/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4065 - val_loss: 3.9665\n",
      "Epoch 788/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4091 - val_loss: 3.8853\n",
      "Epoch 789/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4116 - val_loss: 3.8834\n",
      "Epoch 790/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3955 - val_loss: 3.9297\n",
      "Epoch 791/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3998 - val_loss: 3.9183\n",
      "Epoch 792/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4055 - val_loss: 3.9147\n",
      "Epoch 793/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4032 - val_loss: 3.8856\n",
      "Epoch 794/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4126 - val_loss: 3.9298\n",
      "Epoch 795/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3903 - val_loss: 3.9054\n",
      "Epoch 796/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3916 - val_loss: 3.9198\n",
      "Epoch 797/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3966 - val_loss: 3.9214\n",
      "Epoch 798/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3823 - val_loss: 3.9360\n",
      "Epoch 799/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3954 - val_loss: 3.8800\n",
      "Epoch 800/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3884 - val_loss: 3.9483\n",
      "Epoch 801/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4017 - val_loss: 3.9209\n",
      "Epoch 802/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4400 - val_loss: 3.8997\n",
      "Epoch 803/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.4212 - val_loss: 3.8472\n",
      "Epoch 804/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4265 - val_loss: 3.8794\n",
      "Epoch 805/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3894 - val_loss: 3.9524\n",
      "Epoch 806/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3982 - val_loss: 3.8990\n",
      "Epoch 807/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3925 - val_loss: 3.9477\n",
      "Epoch 808/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3994 - val_loss: 3.8770\n",
      "Epoch 809/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4189 - val_loss: 3.9720\n",
      "Epoch 810/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4152 - val_loss: 3.9285\n",
      "Epoch 811/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3791 - val_loss: 3.9117\n",
      "Epoch 812/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3945 - val_loss: 3.8559\n",
      "Epoch 813/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4016 - val_loss: 3.8866\n",
      "Epoch 814/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4069 - val_loss: 3.8783\n",
      "Epoch 815/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4047 - val_loss: 3.8489\n",
      "Epoch 816/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3786 - val_loss: 3.8790\n",
      "Epoch 817/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3691 - val_loss: 3.8668\n",
      "Epoch 818/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3667 - val_loss: 3.8807\n",
      "Epoch 819/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3611 - val_loss: 3.8516\n",
      "Epoch 820/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3542 - val_loss: 3.8637\n",
      "Epoch 821/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3577 - val_loss: 3.8805\n",
      "Epoch 822/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3610 - val_loss: 3.8898\n",
      "Epoch 823/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3583 - val_loss: 3.8522\n",
      "Epoch 824/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3578 - val_loss: 3.8959\n",
      "Epoch 825/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3682 - val_loss: 3.8531\n",
      "Epoch 826/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3627 - val_loss: 3.8748\n",
      "Epoch 827/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3696 - val_loss: 3.8959\n",
      "Epoch 828/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3685 - val_loss: 3.8795\n",
      "Epoch 829/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3558 - val_loss: 3.9061\n",
      "Epoch 830/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3502 - val_loss: 3.8501\n",
      "Epoch 831/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3509 - val_loss: 3.8755\n",
      "Epoch 832/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3573 - val_loss: 3.8558\n",
      "Epoch 833/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3613 - val_loss: 3.8769\n",
      "Epoch 834/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3490 - val_loss: 3.8331\n",
      "Epoch 835/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3461 - val_loss: 3.8649\n",
      "Epoch 836/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3424 - val_loss: 3.8478\n",
      "Epoch 837/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3444 - val_loss: 3.8936\n",
      "Epoch 838/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3513 - val_loss: 3.8439\n",
      "Epoch 839/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3515 - val_loss: 3.8819\n",
      "Epoch 840/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3749 - val_loss: 3.8520\n",
      "Epoch 841/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3481 - val_loss: 3.8359\n",
      "Epoch 842/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3531 - val_loss: 3.8488\n",
      "Epoch 843/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3522 - val_loss: 3.8487\n",
      "Epoch 844/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3708 - val_loss: 3.8629\n",
      "Epoch 845/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3578 - val_loss: 3.8215\n",
      "Epoch 846/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3432 - val_loss: 3.8334\n",
      "Epoch 847/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3450 - val_loss: 3.8623\n",
      "Epoch 848/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3445 - val_loss: 3.8685\n",
      "Epoch 849/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3314 - val_loss: 3.8042\n",
      "Epoch 850/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3333 - val_loss: 3.8269\n",
      "Epoch 851/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3272 - val_loss: 3.8143\n",
      "Epoch 852/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3377 - val_loss: 3.8460\n",
      "Epoch 853/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3383 - val_loss: 3.7984\n",
      "Epoch 854/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3379 - val_loss: 3.8432\n",
      "Epoch 855/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3262 - val_loss: 3.8244\n",
      "Epoch 856/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3338 - val_loss: 3.7940\n",
      "Epoch 857/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3418 - val_loss: 3.8074\n",
      "Epoch 858/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3315 - val_loss: 3.8484\n",
      "Epoch 859/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3346 - val_loss: 3.8444\n",
      "Epoch 860/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3111 - val_loss: 3.8161\n",
      "Epoch 861/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3462 - val_loss: 3.7906\n",
      "Epoch 862/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3293 - val_loss: 3.8732\n",
      "Epoch 863/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3365 - val_loss: 3.8256\n",
      "Epoch 864/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3062 - val_loss: 3.8016\n",
      "Epoch 865/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3365 - val_loss: 3.7917\n",
      "Epoch 866/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3235 - val_loss: 3.8123\n",
      "Epoch 867/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3613 - val_loss: 3.8935\n",
      "Epoch 868/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3500 - val_loss: 3.8135\n",
      "Epoch 869/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3436 - val_loss: 3.8270\n",
      "Epoch 870/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3363 - val_loss: 3.8301\n",
      "Epoch 871/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3161 - val_loss: 3.8504\n",
      "Epoch 872/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3021 - val_loss: 3.8303\n",
      "Epoch 873/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3133 - val_loss: 3.7561\n",
      "Epoch 874/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3349 - val_loss: 3.8406\n",
      "Epoch 875/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3117 - val_loss: 3.8081\n",
      "Epoch 876/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3058 - val_loss: 3.8154\n",
      "Epoch 877/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3243 - val_loss: 3.7873\n",
      "Epoch 878/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3485 - val_loss: 3.9054\n",
      "Epoch 879/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3320 - val_loss: 3.8053\n",
      "Epoch 880/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.3344 - val_loss: 3.7899\n",
      "Epoch 881/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3237 - val_loss: 3.7723\n",
      "Epoch 882/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3163 - val_loss: 3.8412\n",
      "Epoch 883/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2991 - val_loss: 3.7718\n",
      "Epoch 884/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2977 - val_loss: 3.7395\n",
      "Epoch 885/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3085 - val_loss: 3.8236\n",
      "Epoch 886/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3213 - val_loss: 3.7949\n",
      "Epoch 887/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3075 - val_loss: 3.8590\n",
      "Epoch 888/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3154 - val_loss: 3.7695\n",
      "Epoch 889/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3045 - val_loss: 3.8305\n",
      "Epoch 890/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3347 - val_loss: 3.7854\n",
      "Epoch 891/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3338 - val_loss: 3.8278\n",
      "Epoch 892/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3172 - val_loss: 3.7700\n",
      "Epoch 893/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2887 - val_loss: 3.7652\n",
      "Epoch 894/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2969 - val_loss: 3.7785\n",
      "Epoch 895/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3017 - val_loss: 3.7923\n",
      "Epoch 896/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3043 - val_loss: 3.8016\n",
      "Epoch 897/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3166 - val_loss: 3.7443\n",
      "Epoch 898/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2950 - val_loss: 3.8847\n",
      "Epoch 899/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3442 - val_loss: 3.8481\n",
      "Epoch 900/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3212 - val_loss: 3.7812\n",
      "Epoch 901/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3064 - val_loss: 3.8332\n",
      "Epoch 902/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2976 - val_loss: 3.7472\n",
      "Epoch 903/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2932 - val_loss: 3.8160\n",
      "Epoch 904/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3020 - val_loss: 3.7760\n",
      "Epoch 905/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2993 - val_loss: 3.7930\n",
      "Epoch 906/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2830 - val_loss: 3.7347\n",
      "Epoch 907/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2907 - val_loss: 3.7878\n",
      "Epoch 908/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3010 - val_loss: 3.8362\n",
      "Epoch 909/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2750 - val_loss: 3.7579\n",
      "Epoch 910/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2905 - val_loss: 3.7801\n",
      "Epoch 911/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2635 - val_loss: 3.7374\n",
      "Epoch 912/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2741 - val_loss: 3.7829\n",
      "Epoch 913/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2743 - val_loss: 3.7210\n",
      "Epoch 914/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2753 - val_loss: 3.8149\n",
      "Epoch 915/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2800 - val_loss: 3.7430\n",
      "Epoch 916/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2673 - val_loss: 3.7688\n",
      "Epoch 917/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2643 - val_loss: 3.7493\n",
      "Epoch 918/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2658 - val_loss: 3.7282\n",
      "Epoch 919/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2656 - val_loss: 3.7667\n",
      "Epoch 920/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2659 - val_loss: 3.7655\n",
      "Epoch 921/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2778 - val_loss: 3.8004\n",
      "Epoch 922/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2777 - val_loss: 3.7266\n",
      "Epoch 923/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2615 - val_loss: 3.7595\n",
      "Epoch 924/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2635 - val_loss: 3.7376\n",
      "Epoch 925/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2548 - val_loss: 3.7509\n",
      "Epoch 926/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2504 - val_loss: 3.7467\n",
      "Epoch 927/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2497 - val_loss: 3.7324\n",
      "Epoch 928/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2425 - val_loss: 3.7939\n",
      "Epoch 929/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2562 - val_loss: 3.7730\n",
      "Epoch 930/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2424 - val_loss: 3.7527\n",
      "Epoch 931/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2515 - val_loss: 3.7205\n",
      "Epoch 932/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2499 - val_loss: 3.7573\n",
      "Epoch 933/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2411 - val_loss: 3.7214\n",
      "Epoch 934/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2390 - val_loss: 3.7392\n",
      "Epoch 935/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2288 - val_loss: 3.7254\n",
      "Epoch 936/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2492 - val_loss: 3.7172\n",
      "Epoch 937/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2497 - val_loss: 3.7653\n",
      "Epoch 938/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2510 - val_loss: 3.7080\n",
      "Epoch 939/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2768 - val_loss: 3.6975\n",
      "Epoch 940/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2748 - val_loss: 3.7179\n",
      "Epoch 941/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2297 - val_loss: 3.7232\n",
      "Epoch 942/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2459 - val_loss: 3.6941\n",
      "Epoch 943/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2493 - val_loss: 3.7193\n",
      "Epoch 944/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2405 - val_loss: 3.7427\n",
      "Epoch 945/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2373 - val_loss: 3.7052\n",
      "Epoch 946/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2384 - val_loss: 3.6871\n",
      "Epoch 947/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2331 - val_loss: 3.7537\n",
      "Epoch 948/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2255 - val_loss: 3.7130\n",
      "Epoch 949/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2103 - val_loss: 3.6699\n",
      "Epoch 950/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2251 - val_loss: 3.7568\n",
      "Epoch 951/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2548 - val_loss: 3.7131\n",
      "Epoch 952/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2561 - val_loss: 3.7363\n",
      "Epoch 953/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2538 - val_loss: 3.6845\n",
      "Epoch 954/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2190 - val_loss: 3.7145\n",
      "Epoch 955/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2222 - val_loss: 3.6949\n",
      "Epoch 956/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2218 - val_loss: 3.6759\n",
      "Epoch 957/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2142 - val_loss: 3.6962\n",
      "Epoch 958/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2150 - val_loss: 3.6670\n",
      "Epoch 959/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2247 - val_loss: 3.7422\n",
      "Epoch 960/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2482 - val_loss: 3.7049\n",
      "Epoch 961/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2210 - val_loss: 3.7054\n",
      "Epoch 962/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2109 - val_loss: 3.6951\n",
      "Epoch 963/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2490 - val_loss: 3.7601\n",
      "Epoch 964/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2700 - val_loss: 3.6575\n",
      "Epoch 965/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2198 - val_loss: 3.6982\n",
      "Epoch 966/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2221 - val_loss: 3.7082\n",
      "Epoch 967/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2119 - val_loss: 3.6448\n",
      "Epoch 968/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2254 - val_loss: 3.6444\n",
      "Epoch 969/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2218 - val_loss: 3.7104\n",
      "Epoch 970/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2033 - val_loss: 3.7053\n",
      "Epoch 971/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2041 - val_loss: 3.7089\n",
      "Epoch 972/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2172 - val_loss: 3.6570\n",
      "Epoch 973/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2147 - val_loss: 3.6501\n",
      "Epoch 974/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2131 - val_loss: 3.6896\n",
      "Epoch 975/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2013 - val_loss: 3.6537\n",
      "Epoch 976/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2076 - val_loss: 3.6882\n",
      "Epoch 977/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1772 - val_loss: 3.6667\n",
      "Epoch 978/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2044 - val_loss: 3.6638\n",
      "Epoch 979/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2150 - val_loss: 3.6351\n",
      "Epoch 980/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1870 - val_loss: 3.6762\n",
      "Epoch 981/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1871 - val_loss: 3.6373\n",
      "Epoch 982/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1876 - val_loss: 3.6643\n",
      "Epoch 983/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1816 - val_loss: 3.6538\n",
      "Epoch 984/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1793 - val_loss: 3.6655\n",
      "Epoch 985/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1906 - val_loss: 3.6437\n",
      "Epoch 986/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2105 - val_loss: 3.7094\n",
      "Epoch 987/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2291 - val_loss: 3.6110\n",
      "Epoch 988/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2070 - val_loss: 3.6975\n",
      "Epoch 989/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1830 - val_loss: 3.6688\n",
      "Epoch 990/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1884 - val_loss: 3.6612\n",
      "Epoch 991/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1983 - val_loss: 3.6332\n",
      "Epoch 992/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2111 - val_loss: 3.6879\n",
      "Epoch 993/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1918 - val_loss: 3.6721\n",
      "Epoch 994/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1856 - val_loss: 3.5999\n",
      "Epoch 995/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1822 - val_loss: 3.6789\n",
      "Epoch 996/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1698 - val_loss: 3.6121\n",
      "Epoch 997/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1704 - val_loss: 3.6488\n",
      "Epoch 998/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1990 - val_loss: 3.5774\n",
      "Epoch 999/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1760 - val_loss: 3.6543\n",
      "Epoch 1000/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1905 - val_loss: 3.6422\n",
      "Epoch 1001/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1603 - val_loss: 3.6531\n",
      "Epoch 1002/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1585 - val_loss: 3.6469\n",
      "Epoch 1003/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1782 - val_loss: 3.6566\n",
      "Epoch 1004/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1637 - val_loss: 3.6108\n",
      "Epoch 1005/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1743 - val_loss: 3.7583\n",
      "Epoch 1006/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2068 - val_loss: 3.6348\n",
      "Epoch 1007/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1729 - val_loss: 3.6052\n",
      "Epoch 1008/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1743 - val_loss: 3.6219\n",
      "Epoch 1009/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1591 - val_loss: 3.6379\n",
      "Epoch 1010/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1683 - val_loss: 3.6396\n",
      "Epoch 1011/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1953 - val_loss: 3.6024\n",
      "Epoch 1012/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1611 - val_loss: 3.6459\n",
      "Epoch 1013/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1809 - val_loss: 3.6123\n",
      "Epoch 1014/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1595 - val_loss: 3.6325\n",
      "Epoch 1015/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1629 - val_loss: 3.6175\n",
      "Epoch 1016/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1528 - val_loss: 3.6049\n",
      "Epoch 1017/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1426 - val_loss: 3.6427\n",
      "Epoch 1018/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1404 - val_loss: 3.5883\n",
      "Epoch 1019/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1418 - val_loss: 3.6105\n",
      "Epoch 1020/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1487 - val_loss: 3.6802\n",
      "Epoch 1021/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1585 - val_loss: 3.5733\n",
      "Epoch 1022/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1755 - val_loss: 3.6479\n",
      "Epoch 1023/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2044 - val_loss: 3.6399\n",
      "Epoch 1024/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2244 - val_loss: 3.6336\n",
      "Epoch 1025/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1606 - val_loss: 3.6133\n",
      "Epoch 1026/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1680 - val_loss: 3.6829\n",
      "Epoch 1027/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1364 - val_loss: 3.5842\n",
      "Epoch 1028/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1570 - val_loss: 3.6218\n",
      "Epoch 1029/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1491 - val_loss: 3.6032\n",
      "Epoch 1030/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1358 - val_loss: 3.7178\n",
      "Epoch 1031/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1823 - val_loss: 3.5856\n",
      "Epoch 1032/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1722 - val_loss: 3.5897\n",
      "Epoch 1033/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1575 - val_loss: 3.5705\n",
      "Epoch 1034/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1630 - val_loss: 3.6187\n",
      "Epoch 1035/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1522 - val_loss: 3.5440\n",
      "Epoch 1036/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1534 - val_loss: 3.5945\n",
      "Epoch 1037/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1440 - val_loss: 3.5984\n",
      "Epoch 1038/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1553 - val_loss: 3.6051\n",
      "Epoch 1039/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1335 - val_loss: 3.5675\n",
      "Epoch 1040/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1264 - val_loss: 3.6305\n",
      "Epoch 1041/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1276 - val_loss: 3.5581\n",
      "Epoch 1042/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1251 - val_loss: 3.5808\n",
      "Epoch 1043/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1160 - val_loss: 3.5656\n",
      "Epoch 1044/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1162 - val_loss: 3.5397\n",
      "Epoch 1045/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1087 - val_loss: 3.5890\n",
      "Epoch 1046/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1244 - val_loss: 3.5589\n",
      "Epoch 1047/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1036 - val_loss: 3.5799\n",
      "Epoch 1048/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1302 - val_loss: 3.6333\n",
      "Epoch 1049/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1109 - val_loss: 3.5490\n",
      "Epoch 1050/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1040 - val_loss: 3.6129\n",
      "Epoch 1051/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1285 - val_loss: 3.5677\n",
      "Epoch 1052/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1033 - val_loss: 3.6098\n",
      "Epoch 1053/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1223 - val_loss: 3.5091\n",
      "Epoch 1054/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1020 - val_loss: 3.5832\n",
      "Epoch 1055/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0984 - val_loss: 3.5872\n",
      "Epoch 1056/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1345 - val_loss: 3.5537\n",
      "Epoch 1057/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1417 - val_loss: 3.6255\n",
      "Epoch 1058/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1879 - val_loss: 3.5599\n",
      "Epoch 1059/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1303 - val_loss: 3.5897\n",
      "Epoch 1060/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1386 - val_loss: 3.6020\n",
      "Epoch 1061/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1089 - val_loss: 3.5501\n",
      "Epoch 1062/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1231 - val_loss: 3.5611\n",
      "Epoch 1063/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1083 - val_loss: 3.5314\n",
      "Epoch 1064/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1697 - val_loss: 3.6438\n",
      "Epoch 1065/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2023 - val_loss: 3.5682\n",
      "Epoch 1066/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1203 - val_loss: 3.5262\n",
      "Epoch 1067/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1027 - val_loss: 3.5224\n",
      "Epoch 1068/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1010 - val_loss: 3.5357\n",
      "Epoch 1069/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1089 - val_loss: 3.5302\n",
      "Epoch 1070/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0803 - val_loss: 3.5202\n",
      "Epoch 1071/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1208 - val_loss: 3.5518\n",
      "Epoch 1072/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0976 - val_loss: 3.5545\n",
      "Epoch 1073/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0953 - val_loss: 3.5389\n",
      "Epoch 1074/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1063 - val_loss: 3.5484\n",
      "Epoch 1075/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0965 - val_loss: 3.5716\n",
      "Epoch 1076/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1103 - val_loss: 3.5442\n",
      "Epoch 1077/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1192 - val_loss: 3.5862\n",
      "Epoch 1078/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1088 - val_loss: 3.4697\n",
      "Epoch 1079/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0934 - val_loss: 3.5197\n",
      "Epoch 1080/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0914 - val_loss: 3.5492\n",
      "Epoch 1081/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0825 - val_loss: 3.5223\n",
      "Epoch 1082/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0910 - val_loss: 3.5314\n",
      "Epoch 1083/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0868 - val_loss: 3.4896\n",
      "Epoch 1084/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1018 - val_loss: 3.5514\n",
      "Epoch 1085/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1107 - val_loss: 3.4755\n",
      "Epoch 1086/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1243 - val_loss: 3.5645\n",
      "Epoch 1087/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1644 - val_loss: 3.5401\n",
      "Epoch 1088/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0898 - val_loss: 3.5496\n",
      "Epoch 1089/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0767 - val_loss: 3.4921\n",
      "Epoch 1090/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0640 - val_loss: 3.5121\n",
      "Epoch 1091/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0641 - val_loss: 3.5202\n",
      "Epoch 1092/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0733 - val_loss: 3.6233\n",
      "Epoch 1093/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.1315 - val_loss: 3.5564\n",
      "Epoch 1094/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1039 - val_loss: 3.5831\n",
      "Epoch 1095/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1139 - val_loss: 3.6048\n",
      "Epoch 1096/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1199 - val_loss: 3.5943\n",
      "Epoch 1097/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1237 - val_loss: 3.5026\n",
      "Epoch 1098/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1048 - val_loss: 3.5185\n",
      "Epoch 1099/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0870 - val_loss: 3.4948\n",
      "Epoch 1100/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0674 - val_loss: 3.5053\n",
      "Epoch 1101/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0576 - val_loss: 3.4972\n",
      "Epoch 1102/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0651 - val_loss: 3.4974\n",
      "Epoch 1103/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0821 - val_loss: 3.5453\n",
      "Epoch 1104/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0862 - val_loss: 3.4714\n",
      "Epoch 1105/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0866 - val_loss: 3.5949\n",
      "Epoch 1106/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1174 - val_loss: 3.4907\n",
      "Epoch 1107/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1228 - val_loss: 3.5113\n",
      "Epoch 1108/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1189 - val_loss: 3.4011\n",
      "Epoch 1109/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0830 - val_loss: 3.5868\n",
      "Epoch 1110/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1371 - val_loss: 3.5560\n",
      "Epoch 1111/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0832 - val_loss: 3.4923\n",
      "Epoch 1112/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1182 - val_loss: 3.4424\n",
      "Epoch 1113/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0790 - val_loss: 3.6042\n",
      "Epoch 1114/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0994 - val_loss: 3.5181\n",
      "Epoch 1115/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0641 - val_loss: 3.4719\n",
      "Epoch 1116/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1127 - val_loss: 3.5172\n",
      "Epoch 1117/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0742 - val_loss: 3.4923\n",
      "Epoch 1118/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0808 - val_loss: 3.5613\n",
      "Epoch 1119/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0857 - val_loss: 3.4837\n",
      "Epoch 1120/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0806 - val_loss: 3.4838\n",
      "Epoch 1121/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0993 - val_loss: 3.4996\n",
      "Epoch 1122/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1223 - val_loss: 3.5273\n",
      "Epoch 1123/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0776 - val_loss: 3.5037\n",
      "Epoch 1124/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0742 - val_loss: 3.4819\n",
      "Epoch 1125/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0515 - val_loss: 3.4911\n",
      "Epoch 1126/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0657 - val_loss: 3.4735\n",
      "Epoch 1127/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0853 - val_loss: 3.4595\n",
      "Epoch 1128/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0539 - val_loss: 3.4535\n",
      "Epoch 1129/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0645 - val_loss: 3.5265\n",
      "Epoch 1130/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0691 - val_loss: 3.4560\n",
      "Epoch 1131/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0410 - val_loss: 3.4997\n",
      "Epoch 1132/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0463 - val_loss: 3.4518\n",
      "Epoch 1133/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0436 - val_loss: 3.5004\n",
      "Epoch 1134/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0462 - val_loss: 3.5219\n",
      "Epoch 1135/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0463 - val_loss: 3.4524\n",
      "Epoch 1136/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0377 - val_loss: 3.4807\n",
      "Epoch 1137/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0558 - val_loss: 3.4532\n",
      "Epoch 1138/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0530 - val_loss: 3.5141\n",
      "Epoch 1139/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0765 - val_loss: 3.4582\n",
      "Epoch 1140/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0416 - val_loss: 3.5197\n",
      "Epoch 1141/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0538 - val_loss: 3.4695\n",
      "Epoch 1142/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0319 - val_loss: 3.4759\n",
      "Epoch 1143/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0735 - val_loss: 3.4719\n",
      "Epoch 1144/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0762 - val_loss: 3.4772\n",
      "Epoch 1145/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0796 - val_loss: 3.4816\n",
      "Epoch 1146/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0840 - val_loss: 3.5108\n",
      "Epoch 1147/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0827 - val_loss: 3.4898\n",
      "Epoch 1148/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0727 - val_loss: 3.4335\n",
      "Epoch 1149/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0777 - val_loss: 3.5467\n",
      "Epoch 1150/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0761 - val_loss: 3.5116\n",
      "Epoch 1151/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0727 - val_loss: 3.4426\n",
      "Epoch 1152/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0783 - val_loss: 3.4635\n",
      "Epoch 1153/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0482 - val_loss: 3.5260\n",
      "Epoch 1154/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0854 - val_loss: 3.5169\n",
      "Epoch 1155/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0336 - val_loss: 3.5226\n",
      "Epoch 1156/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0352 - val_loss: 3.4777\n",
      "Epoch 1157/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0489 - val_loss: 3.4275\n",
      "Epoch 1158/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0508 - val_loss: 3.4991\n",
      "Epoch 1159/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0369 - val_loss: 3.4832\n",
      "Epoch 1160/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0535 - val_loss: 3.4283\n",
      "Epoch 1161/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0441 - val_loss: 3.5111\n",
      "Epoch 1162/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0311 - val_loss: 3.5176\n",
      "Epoch 1163/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0419 - val_loss: 3.4297\n",
      "Epoch 1164/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0394 - val_loss: 3.4597\n",
      "Epoch 1165/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0300 - val_loss: 3.5227\n",
      "Epoch 1166/1300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0347 - val_loss: 3.4462\n",
      "Epoch 1167/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0556 - val_loss: 3.4092\n",
      "Epoch 1168/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0377 - val_loss: 3.4703\n",
      "Epoch 1169/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0258 - val_loss: 3.4483\n",
      "Epoch 1170/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0287 - val_loss: 3.4453\n",
      "Epoch 1171/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0315 - val_loss: 3.5071\n",
      "Epoch 1172/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0279 - val_loss: 3.4583\n",
      "Epoch 1173/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0379 - val_loss: 3.3991\n",
      "Epoch 1174/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0358 - val_loss: 3.4937\n",
      "Epoch 1175/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0481 - val_loss: 3.4601\n",
      "Epoch 1176/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0366 - val_loss: 3.4629\n",
      "Epoch 1177/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0156 - val_loss: 3.4569\n",
      "Epoch 1178/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0140 - val_loss: 3.4285\n",
      "Epoch 1179/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0280 - val_loss: 3.4516\n",
      "Epoch 1180/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0214 - val_loss: 3.4661\n",
      "Epoch 1181/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0263 - val_loss: 3.4577\n",
      "Epoch 1182/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0229 - val_loss: 3.4432\n",
      "Epoch 1183/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0090 - val_loss: 3.5082\n",
      "Epoch 1184/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0332 - val_loss: 3.4771\n",
      "Epoch 1185/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0291 - val_loss: 3.4953\n",
      "Epoch 1186/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0108 - val_loss: 3.4143\n",
      "Epoch 1187/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0410 - val_loss: 3.4462\n",
      "Epoch 1188/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0503 - val_loss: 3.4660\n",
      "Epoch 1189/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0153 - val_loss: 3.4599\n",
      "Epoch 1190/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0404 - val_loss: 3.4098\n",
      "Epoch 1191/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0490 - val_loss: 3.3886\n",
      "Epoch 1192/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0228 - val_loss: 3.4685\n",
      "Epoch 1193/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0588 - val_loss: 3.4987\n",
      "Epoch 1194/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0250 - val_loss: 3.4183\n",
      "Epoch 1195/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0182 - val_loss: 3.4765\n",
      "Epoch 1196/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0189 - val_loss: 3.4598\n",
      "Epoch 1197/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0193 - val_loss: 3.4830\n",
      "Epoch 1198/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0391 - val_loss: 3.4026\n",
      "Epoch 1199/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0274 - val_loss: 3.4539\n",
      "Epoch 1200/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0266 - val_loss: 3.4689\n",
      "Epoch 1201/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0121 - val_loss: 3.4167\n",
      "Epoch 1202/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0351 - val_loss: 3.4078\n",
      "Epoch 1203/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0365 - val_loss: 3.4797\n",
      "Epoch 1204/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0185 - val_loss: 3.4367\n",
      "Epoch 1205/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0495 - val_loss: 3.4013\n",
      "Epoch 1206/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0471 - val_loss: 3.4315\n",
      "Epoch 1207/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0250 - val_loss: 3.4725\n",
      "Epoch 1208/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0058 - val_loss: 3.3823\n",
      "Epoch 1209/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0344 - val_loss: 3.4735\n",
      "Epoch 1210/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0505 - val_loss: 3.4254\n",
      "Epoch 1211/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9997 - val_loss: 3.4000\n",
      "Epoch 1212/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0045 - val_loss: 3.4228\n",
      "Epoch 1213/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0070 - val_loss: 3.4408\n",
      "Epoch 1214/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0327 - val_loss: 3.5054\n",
      "Epoch 1215/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0279 - val_loss: 3.4328\n",
      "Epoch 1216/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0440 - val_loss: 3.4163\n",
      "Epoch 1217/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0180 - val_loss: 3.4472\n",
      "Epoch 1218/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0079 - val_loss: 3.4327\n",
      "Epoch 1219/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0172 - val_loss: 3.4756\n",
      "Epoch 1220/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9957 - val_loss: 3.3897\n",
      "Epoch 1221/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0131 - val_loss: 3.4261\n",
      "Epoch 1222/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0010 - val_loss: 3.4407\n",
      "Epoch 1223/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9889 - val_loss: 3.4144\n",
      "Epoch 1224/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9975 - val_loss: 3.4224\n",
      "Epoch 1225/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0116 - val_loss: 3.4147\n",
      "Epoch 1226/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0440 - val_loss: 3.4650\n",
      "Epoch 1227/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0415 - val_loss: 3.4354\n",
      "Epoch 1228/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0359 - val_loss: 3.4839\n",
      "Epoch 1229/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0358 - val_loss: 3.4094\n",
      "Epoch 1230/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0300 - val_loss: 3.4773\n",
      "Epoch 1231/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0132 - val_loss: 3.3940\n",
      "Epoch 1232/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9970 - val_loss: 3.4285\n",
      "Epoch 1233/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9872 - val_loss: 3.4044\n",
      "Epoch 1234/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0089 - val_loss: 3.4514\n",
      "Epoch 1235/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0188 - val_loss: 3.4035\n",
      "Epoch 1236/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0037 - val_loss: 3.4218\n",
      "Epoch 1237/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9990 - val_loss: 3.4300\n",
      "Epoch 1238/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0031 - val_loss: 3.3944\n",
      "Epoch 1239/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9994 - val_loss: 3.5041\n",
      "Epoch 1240/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0472 - val_loss: 3.4222\n",
      "Epoch 1241/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0037 - val_loss: 3.3969\n",
      "Epoch 1242/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9951 - val_loss: 3.4188\n",
      "Epoch 1243/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9779 - val_loss: 3.4021\n",
      "Epoch 1244/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0179 - val_loss: 3.3788\n",
      "Epoch 1245/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0309 - val_loss: 3.4481\n",
      "Epoch 1246/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0055 - val_loss: 3.4029\n",
      "Epoch 1247/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9869 - val_loss: 3.4348\n",
      "Epoch 1248/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9848 - val_loss: 3.4278\n",
      "Epoch 1249/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0429 - val_loss: 3.4520\n",
      "Epoch 1250/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0181 - val_loss: 3.4389\n",
      "Epoch 1251/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0432 - val_loss: 3.4889\n",
      "Epoch 1252/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0164 - val_loss: 3.4315\n",
      "Epoch 1253/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0174 - val_loss: 3.4306\n",
      "Epoch 1254/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9983 - val_loss: 3.4446\n",
      "Epoch 1255/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0020 - val_loss: 3.4311\n",
      "Epoch 1256/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9966 - val_loss: 3.3845\n",
      "Epoch 1257/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9997 - val_loss: 3.4031\n",
      "Epoch 1258/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0038 - val_loss: 3.4326\n",
      "Epoch 1259/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0108 - val_loss: 3.4724\n",
      "Epoch 1260/1300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.0532 - val_loss: 3.3976\n",
      "Epoch 1261/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0405 - val_loss: 3.4524\n",
      "Epoch 1262/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0393 - val_loss: 3.4625\n",
      "Epoch 1263/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9925 - val_loss: 3.3869\n",
      "Epoch 1264/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9950 - val_loss: 3.4095\n",
      "Epoch 1265/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0083 - val_loss: 3.4212\n",
      "Epoch 1266/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0146 - val_loss: 3.4328\n",
      "Epoch 1267/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0073 - val_loss: 3.3902\n",
      "Epoch 1268/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0037 - val_loss: 3.4597\n",
      "Epoch 1269/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0051 - val_loss: 3.4458\n",
      "Epoch 1270/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9834 - val_loss: 3.4337\n",
      "Epoch 1271/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9935 - val_loss: 3.3781\n",
      "Epoch 1272/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0155 - val_loss: 3.4638\n",
      "Epoch 1273/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0086 - val_loss: 3.4697\n",
      "Epoch 1274/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0022 - val_loss: 3.4117\n",
      "Epoch 1275/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9806 - val_loss: 3.4380\n",
      "Epoch 1276/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9908 - val_loss: 3.3484\n",
      "Epoch 1277/1300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0225 - val_loss: 3.4204\n",
      "Epoch 1278/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0110 - val_loss: 3.3419\n",
      "Epoch 1279/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0192 - val_loss: 3.4960\n",
      "Epoch 1280/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0500 - val_loss: 3.4240\n",
      "Epoch 1281/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0192 - val_loss: 3.4360\n",
      "Epoch 1282/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9983 - val_loss: 3.3794\n",
      "Epoch 1283/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9909 - val_loss: 3.4208\n",
      "Epoch 1284/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9953 - val_loss: 3.3993\n",
      "Epoch 1285/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9724 - val_loss: 3.3771\n",
      "Epoch 1286/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9742 - val_loss: 3.4681\n",
      "Epoch 1287/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9817 - val_loss: 3.3882\n",
      "Epoch 1288/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9637 - val_loss: 3.3936\n",
      "Epoch 1289/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9705 - val_loss: 3.3830\n",
      "Epoch 1290/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9701 - val_loss: 3.4324\n",
      "Epoch 1291/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9841 - val_loss: 3.3893\n",
      "Epoch 1292/1300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9729 - val_loss: 3.3785\n",
      "Epoch 1293/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9722 - val_loss: 3.3796\n",
      "Epoch 1294/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9919 - val_loss: 3.4187\n",
      "Epoch 1295/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9940 - val_loss: 3.4089\n",
      "Epoch 1296/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9782 - val_loss: 3.4594\n",
      "Epoch 1297/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9686 - val_loss: 3.3980\n",
      "Epoch 1298/1300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0197 - val_loss: 3.3623\n",
      "Epoch 1299/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0040 - val_loss: 3.4517\n",
      "Epoch 1300/1300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0121 - val_loss: 3.4688\n",
      "Train: 1.992, Test: 3.469\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy- LOL just kidding\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# # DO NOT Modify this gives 70%- actually\n",
    "reg_model = Sequential()\n",
    "a=reg_model.add(Dense(64, input_dim=10, activation=LeakyReLU()))\n",
    "reg_model.add(Dense(16, activation='relu'))\n",
    "# reg_model.add(Dropout(0.05))\n",
    "reg_model.add(Dense(8, activation='relu'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=1300, verbose=1)\n",
    "y_pred=reg_model.predict(X_test_std)\n",
    "train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e927ffc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-05ff59c6f4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anoconda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \"\"\"\n\u001b[1;32m--> 911\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    912\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;32mE:\\anoconda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    112\u001b[0m             \"y_true and y_pred have different number of output ({0}!={1})\".format(\n\u001b[0;32m    113\u001b[0m                 \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=8)"
     ]
    }
   ],
   "source": [
    "r2_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5a90fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-963b8dddb9ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madj_R2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mR2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0madj_R2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'R2' is not defined"
     ]
    }
   ],
   "source": [
    "n= len(X_train_std)\n",
    "p = len(X.columns)\n",
    "adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b6b31",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "007d9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X= scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec111016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a01dc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86f842d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e89d3c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.644530</td>\n",
       "      <td>0.561085</td>\n",
       "      <td>-0.056426</td>\n",
       "      <td>-0.053508</td>\n",
       "      <td>0.150036</td>\n",
       "      <td>-0.029116</td>\n",
       "      <td>-0.121246</td>\n",
       "      <td>-0.029008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.644541</td>\n",
       "      <td>0.561058</td>\n",
       "      <td>-0.056457</td>\n",
       "      <td>-0.053537</td>\n",
       "      <td>0.150010</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>-0.121294</td>\n",
       "      <td>-0.028705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.644560</td>\n",
       "      <td>0.561013</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>-0.053584</td>\n",
       "      <td>0.149968</td>\n",
       "      <td>-0.029109</td>\n",
       "      <td>-0.121374</td>\n",
       "      <td>-0.028199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.644633</td>\n",
       "      <td>0.560831</td>\n",
       "      <td>-0.056718</td>\n",
       "      <td>-0.053774</td>\n",
       "      <td>0.149797</td>\n",
       "      <td>-0.029090</td>\n",
       "      <td>-0.121694</td>\n",
       "      <td>-0.026176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.644781</td>\n",
       "      <td>0.560468</td>\n",
       "      <td>-0.057136</td>\n",
       "      <td>-0.054154</td>\n",
       "      <td>0.149455</td>\n",
       "      <td>-0.029052</td>\n",
       "      <td>-0.122335</td>\n",
       "      <td>-0.022130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.644530  0.561085 -0.056426 -0.053508  0.150036 -0.029116 -0.121246   \n",
       "1 -0.644541  0.561058 -0.056457 -0.053537  0.150010 -0.029114 -0.121294   \n",
       "2 -0.644560  0.561013 -0.056509 -0.053584  0.149968 -0.029109 -0.121374   \n",
       "3 -0.644633  0.560831 -0.056718 -0.053774  0.149797 -0.029090 -0.121694   \n",
       "4 -0.644781  0.560468 -0.057136 -0.054154  0.149455 -0.029052 -0.122335   \n",
       "\n",
       "          7  \n",
       "0 -0.029008  \n",
       "1 -0.028705  \n",
       "2 -0.028199  \n",
       "3 -0.026176  \n",
       "4 -0.022130  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df = pd.DataFrame(data = X_pca)\n",
    "PCA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d70b801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(PCA_df, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3002b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn import linear_model, tree, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57c06e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 76ms/step - loss: 10.6909 - val_loss: 13.0211\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.0487 - val_loss: 12.3067\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.4162 - val_loss: 11.2143\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7739 - val_loss: 10.1725\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2643 - val_loss: 9.6266\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3833 - val_loss: 9.5530\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4557 - val_loss: 9.7147\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0063 - val_loss: 9.8810\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4949 - val_loss: 9.7215\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.5955 - val_loss: 9.3110\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2829 - val_loss: 8.9818\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5886 - val_loss: 8.8893\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.9391 - val_loss: 8.7249\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8254 - val_loss: 8.1824\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.3692 - val_loss: 8.0910\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.0363 - val_loss: 7.7817\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.3312 - val_loss: 7.9732\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5303 - val_loss: 7.2367\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3405 - val_loss: 7.5950\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4028 - val_loss: 7.1366\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.7608 - val_loss: 7.3926\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.7545 - val_loss: 7.2912\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5538 - val_loss: 7.4275\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7522 - val_loss: 6.9855\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7811 - val_loss: 7.3118\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.8121 - val_loss: 6.6799\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4672 - val_loss: 7.2598\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.8921 - val_loss: 6.6058\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.8783 - val_loss: 7.3420\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6526 - val_loss: 6.6915\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5396 - val_loss: 7.1738\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.4269 - val_loss: 6.9103\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.2194 - val_loss: 6.5206\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7524 - val_loss: 7.3654\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8976 - val_loss: 6.8335\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.8827 - val_loss: 6.8366\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.4972 - val_loss: 6.8446\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.9268 - val_loss: 6.9172\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3528 - val_loss: 6.5686\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5239 - val_loss: 7.4161\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3461 - val_loss: 6.7681\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2517 - val_loss: 7.0253\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6830 - val_loss: 6.8591\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.8219 - val_loss: 7.2612\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.8807 - val_loss: 6.4196\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.7727 - val_loss: 7.1066\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6025 - val_loss: 6.7134\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.5118 - val_loss: 6.5839\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4915 - val_loss: 7.2873\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.4068 - val_loss: 6.6175\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.7012 - val_loss: 6.4711\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7508 - val_loss: 7.1022\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.8815 - val_loss: 6.6079\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5100 - val_loss: 7.0317\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6708 - val_loss: 6.7038\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.0028 - val_loss: 7.0899\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7805 - val_loss: 7.1131\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.0021 - val_loss: 6.7926\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.9566 - val_loss: 7.2101\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6945 - val_loss: 6.8176\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5589 - val_loss: 6.8447\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6841 - val_loss: 6.5609\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9354 - val_loss: 7.1848\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.7498 - val_loss: 6.5448\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2646 - val_loss: 6.8117\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3649 - val_loss: 6.7719\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.9484 - val_loss: 6.7607\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.3133 - val_loss: 6.7735\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.3296 - val_loss: 6.5573\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.0615 - val_loss: 7.0010\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6700 - val_loss: 6.7390\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2817 - val_loss: 6.7859\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.8404 - val_loss: 6.7025\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.3336 - val_loss: 6.9149\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.4075 - val_loss: 6.8172\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2922 - val_loss: 6.7056\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5383 - val_loss: 6.5860\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3853 - val_loss: 6.6839\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5048 - val_loss: 6.9387\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.5277 - val_loss: 6.9111\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3338 - val_loss: 6.5280\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2327 - val_loss: 6.9958\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.3796 - val_loss: 6.3146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.0784 - val_loss: 6.3855\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.0780 - val_loss: 6.5954\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.1259 - val_loss: 6.8859\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5791 - val_loss: 6.7462\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5056 - val_loss: 6.5011\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.7310 - val_loss: 7.2169\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6806 - val_loss: 6.5930\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.4190 - val_loss: 6.7183\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6605 - val_loss: 6.7766\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.2289 - val_loss: 6.6259\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6619 - val_loss: 6.7371\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2817 - val_loss: 6.7698\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8775 - val_loss: 6.8253\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.4339 - val_loss: 6.6390\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9283 - val_loss: 6.5649\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3658 - val_loss: 7.1437\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.3848 - val_loss: 6.8819\n",
      "Train: 5.125, Test: 6.882\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = Sequential()\n",
    "a=reg_model.add(Dense(6, input_dim=8, activation=LeakyReLU(),kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(3, activation=LeakyReLU(),kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(1, activation='linear',kernel_regularizer='l2'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer=opt)\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=100, verbose=1)\n",
    "y_pred=reg_model.predict(X_test)\n",
    "train_mse = reg_model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ef0b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=r2_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "355814c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45984030493851574"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train)\n",
    "p = len(X[1])\n",
    "adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29783097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8abf346",
   "metadata": {},
   "source": [
    "# AutoEncoder - standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b34d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\n",
    "# X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9659aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32b80c9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 65ms/step - loss: 0.1822 - val_loss: 0.1735\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1807 - val_loss: 0.1722\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1793 - val_loss: 0.1709\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1780 - val_loss: 0.1697\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1767 - val_loss: 0.1685\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1754 - val_loss: 0.1673\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1741 - val_loss: 0.1662\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1729 - val_loss: 0.1650\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1716 - val_loss: 0.1639\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1704 - val_loss: 0.1627\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1691 - val_loss: 0.1615\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1679 - val_loss: 0.1605\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1667 - val_loss: 0.1594\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1656 - val_loss: 0.1583\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1645 - val_loss: 0.1573\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1634 - val_loss: 0.1562\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1624 - val_loss: 0.1552\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1614 - val_loss: 0.1542\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1603 - val_loss: 0.1532\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1593 - val_loss: 0.1522\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1582 - val_loss: 0.1511\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1572 - val_loss: 0.1502\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1563 - val_loss: 0.1492\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1554 - val_loss: 0.1482\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1545 - val_loss: 0.1473\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1536 - val_loss: 0.1465\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1528 - val_loss: 0.1457\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1520 - val_loss: 0.1448\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1512 - val_loss: 0.1441\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1504 - val_loss: 0.1433\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1497 - val_loss: 0.1426\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1490 - val_loss: 0.1419\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1483 - val_loss: 0.1412\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1476 - val_loss: 0.1406\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1470 - val_loss: 0.1400\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1464 - val_loss: 0.1394\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1458 - val_loss: 0.1388\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1452 - val_loss: 0.1382\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1447 - val_loss: 0.1377\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1442 - val_loss: 0.1372\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1437 - val_loss: 0.1367\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1432 - val_loss: 0.1363\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1427 - val_loss: 0.1358\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1423 - val_loss: 0.1354\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1418 - val_loss: 0.1349\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1414 - val_loss: 0.1345\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1410 - val_loss: 0.1341\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1337\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1402 - val_loss: 0.1333\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1399 - val_loss: 0.1330\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1395 - val_loss: 0.1326\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1392 - val_loss: 0.1323\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1388 - val_loss: 0.1320\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1385 - val_loss: 0.1316\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1382 - val_loss: 0.1313\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1379 - val_loss: 0.1310\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1376 - val_loss: 0.1307\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1373 - val_loss: 0.1305\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1370 - val_loss: 0.1302\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1368 - val_loss: 0.1299\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1365 - val_loss: 0.1297\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1363 - val_loss: 0.1294\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1360 - val_loss: 0.1292\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1358 - val_loss: 0.1289\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1356 - val_loss: 0.1287\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1353 - val_loss: 0.1285\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1351 - val_loss: 0.1283\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1349 - val_loss: 0.1281\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1347 - val_loss: 0.1278\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1345 - val_loss: 0.1276\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1343 - val_loss: 0.1275\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1341 - val_loss: 0.1273\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1339 - val_loss: 0.1271\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1338 - val_loss: 0.1269\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1336 - val_loss: 0.1267\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1334 - val_loss: 0.1266\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1333 - val_loss: 0.1264\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1331 - val_loss: 0.1262\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1329 - val_loss: 0.1261\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1328 - val_loss: 0.1259\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1326 - val_loss: 0.1258\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1325 - val_loss: 0.1256\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1324 - val_loss: 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1322 - val_loss: 0.1253\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1321 - val_loss: 0.1252\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1319 - val_loss: 0.1251\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1318 - val_loss: 0.1249\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1317 - val_loss: 0.1248\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1315 - val_loss: 0.1247\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1314 - val_loss: 0.1245\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1313 - val_loss: 0.1244\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1312 - val_loss: 0.1243\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1311 - val_loss: 0.1242\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1309 - val_loss: 0.1240\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1308 - val_loss: 0.1239\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1307 - val_loss: 0.1238\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1306 - val_loss: 0.1237\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1305 - val_loss: 0.1236\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1304 - val_loss: 0.1235\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1303 - val_loss: 0.1234\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "encoded = Dense(5, activation='relu')(input_layer)\n",
    "decoded = Dense(X.shape[1], activation='relu')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X1, X2, Y1, Y2 = train_test_split(X, X, test_size=0.3, random_state=101)\n",
    "\n",
    "autoencoder.fit(X1, Y1,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose = 1,\n",
    "                validation_data=(X2, Y2))\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_ae = autoencoder.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63eacad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40151087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ae, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f145a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 65ms/step - loss: 10.8166 - val_loss: 13.4875\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.7882 - val_loss: 13.3525\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.5842 - val_loss: 13.1071\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.2828 - val_loss: 12.8432\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.9651 - val_loss: 12.5598\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.6803 - val_loss: 12.2813\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.4431 - val_loss: 12.0159\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2638 - val_loss: 11.7403\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0983 - val_loss: 11.4425\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9116 - val_loss: 11.1530\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7882 - val_loss: 10.8017\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6537 - val_loss: 10.5187\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5701 - val_loss: 10.3238\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7057 - val_loss: 10.2399\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6582 - val_loss: 10.2624\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5965 - val_loss: 10.2444\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6785 - val_loss: 10.3779\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5673 - val_loss: 10.4249\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5973 - val_loss: 10.4547\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4811 - val_loss: 10.3856\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6736 - val_loss: 10.2932\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5627 - val_loss: 10.2028\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6682 - val_loss: 10.2165\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4912 - val_loss: 10.2012\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4568 - val_loss: 10.0978\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8309 - val_loss: 10.1235\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6799 - val_loss: 10.2702\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5916 - val_loss: 10.3118\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4949 - val_loss: 10.2341\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6303 - val_loss: 10.1878\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5419 - val_loss: 10.1331\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6288 - val_loss: 10.0673\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5831 - val_loss: 10.1676\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5597 - val_loss: 10.1965\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5893 - val_loss: 10.2576\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2841 - val_loss: 10.1612\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6546 - val_loss: 10.0726\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4989 - val_loss: 10.0496\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5276 - val_loss: 10.0132\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5260 - val_loss: 10.1045\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6252 - val_loss: 10.2042\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4026 - val_loss: 10.1759\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6811 - val_loss: 10.2037\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5141 - val_loss: 10.2765\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5814 - val_loss: 10.2634\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4914 - val_loss: 10.2729\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5029 - val_loss: 10.1848\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2983 - val_loss: 10.1467\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5996 - val_loss: 10.1042\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4851 - val_loss: 10.1406\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4260 - val_loss: 10.1290\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5368 - val_loss: 10.1139\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5737 - val_loss: 10.1093\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3251 - val_loss: 10.0629\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5346 - val_loss: 10.1100\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5115 - val_loss: 10.1967\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.4569 - val_loss: 10.2159\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5285 - val_loss: 10.2689\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4139 - val_loss: 10.1576\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4687 - val_loss: 10.0660\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3609 - val_loss: 10.1402\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4902 - val_loss: 10.2106\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4050 - val_loss: 10.0520\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3509 - val_loss: 10.0332\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4364 - val_loss: 10.1230\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3788 - val_loss: 10.0137\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3698 - val_loss: 10.0299\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4346 - val_loss: 10.1190\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4238 - val_loss: 10.2158\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1939 - val_loss: 10.0410\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1528 - val_loss: 9.9214\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2568 - val_loss: 9.9758\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1864 - val_loss: 10.1893\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1384 - val_loss: 9.9451\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9947 - val_loss: 9.8353\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9490 - val_loss: 9.7651\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9911 - val_loss: 9.6950\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7538 - val_loss: 9.6904\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9886 - val_loss: 9.5798\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9522 - val_loss: 9.6522\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0392 - val_loss: 9.9715\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9132 - val_loss: 9.3150\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7042 - val_loss: 9.7784\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6560 - val_loss: 9.3018\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6006 - val_loss: 9.3167\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8951 - val_loss: 9.4552\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4615 - val_loss: 9.1452\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8502 - val_loss: 9.2413\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3274 - val_loss: 8.9869\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4917 - val_loss: 9.5533\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.1799 - val_loss: 9.0268\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3275 - val_loss: 8.9560\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4361 - val_loss: 8.9886\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2645 - val_loss: 9.2297\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.0722 - val_loss: 8.6530\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4017 - val_loss: 8.7403\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8779 - val_loss: 8.8078\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1263 - val_loss: 8.5269\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9582 - val_loss: 8.6195\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.1739 - val_loss: 9.0538\n",
      "Train: 7.072, Test: 9.054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(6, input_dim=10, activation=LeakyReLU(),kernel_initializer='normal',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(3, activation=LeakyReLU(),kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(1, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer=opt)\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=100, verbose=1)\n",
    "y_pred=reg_model.predict(X_test)\n",
    "train_mse = reg_model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e4a56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=r2_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77eb195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1690856401389571"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train)\n",
    "p = len(X[1])\n",
    "adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99359c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1568aa2e",
   "metadata": {},
   "source": [
    "# Stacked AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8d228cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "batch_size = 32\n",
    "input_dim = X_train[0].shape[0] #num of predictor variables \n",
    "learning_rate = 1e-4\n",
    "input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "#Input Layer\n",
    "encoder = Dense (100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "#Encoders first dense layer\n",
    "encoder = Dense (50, activation=\"relu\",\n",
    "activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "#Encoders second dense layer\n",
    "encoder = Dense (25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Code layer\n",
    "encoder = Dense (8, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoders first dense layer\n",
    "decoder = Dense(25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoders second dense layer\n",
    "decoder = Dense(50, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Decoders Third dense layer\n",
    "decoder = Dense(100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Output Layer\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\", activity_regularizer=regularizers.l1(learning_rate))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f0cebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 1.2595 - accuracy: 0.1257\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2302 - accuracy: 0.2286\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1804 - accuracy: 0.2286\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1124 - accuracy: 0.2286\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0687 - accuracy: 0.2286\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.2286\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9987 - accuracy: 0.2457\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9568 - accuracy: 0.2686\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9226 - accuracy: 0.2971\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8977 - accuracy: 0.3657\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.3829\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.3943\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8680 - accuracy: 0.3314\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.3029\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8504 - accuracy: 0.3029\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8409 - accuracy: 0.3029\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.3200\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.3314\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.3714\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.4514\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7923 - accuracy: 0.4857\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7862 - accuracy: 0.4857\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.4914\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.4914\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.4971\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7732 - accuracy: 0.5029\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7714 - accuracy: 0.4971\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.4971\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.4971\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7675 - accuracy: 0.4914\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7664 - accuracy: 0.4914\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.4914\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7640 - accuracy: 0.4857\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7629 - accuracy: 0.4800\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7610 - accuracy: 0.4686\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7590 - accuracy: 0.4571\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.4457\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.4571\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.4457\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.4571\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.4743\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.4571\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.4686\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.4514\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.4171\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.4057\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.4114\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.4057\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.3943\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.3943\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7368 - accuracy: 0.3943\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7361 - accuracy: 0.3657\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7356 - accuracy: 0.4457\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7350 - accuracy: 0.4400\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.4571\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.4343\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.4400\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.4400\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.4400\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7318 - accuracy: 0.4400\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.4629\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.5314\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.5314\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.5371\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.5486\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.5600\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.5771\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.5486\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.5486\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.5257\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.5371\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.5429\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.5371\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.5429\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.5486\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7246 - accuracy: 0.5543\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.5771\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.5829\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.5886\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.7199 - accuracy: 0.5257\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.5600\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.5314\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.5429\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.5314\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.5371\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.5143\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.5257\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.5257\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.5143\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.4971\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.4971\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.4971\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.4971\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.4971\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.4971\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.4914\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.5086\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.4971\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.4971\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.4971\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.4971\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.4800\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.4743\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.4743\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4743\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.4743\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.4914\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.4743\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.4743\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.4914\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.4114\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.4000\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.4057\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.4229\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.4514\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.4514\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.4857\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.4629\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.4971\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.5143\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.4971\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5314\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.5200\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.5257\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.5143\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.5314\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.5257\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5257\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.5371\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5371\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.5314\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5429\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.5314\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.5257\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.5486\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5543\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.5600\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5257\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.5429\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.5486\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.5600\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7056 - accuracy: 0.5543\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.5429\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5600\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.5543\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.5371\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5429\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.5486\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.5371\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.5371\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.5429\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5429\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5371\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.5429\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5429\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5371\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5371\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5429\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.5429\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5371\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.5371\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5429\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5543\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5429\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5429\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5600\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.5486\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.5429\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5657\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5886\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5486\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.5543\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5429\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5543\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5714\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5886\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5486\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5829\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5886\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.5600\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5714\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.5771\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5829\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5543\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.6000\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5714\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5829\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.6000\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5829\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.6114\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5429\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.6229\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.6000\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.6229\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6000\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6000\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.6286\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.6229\n"
     ]
    }
   ],
   "source": [
    "autoencoder_1 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_1.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_1 = autoencoder_1.fit(X_train, X_train,epochs=200,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d6d72642",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2_input = autoencoder_1.predict(X_train)\n",
    "autoencoder_2_input = np.concatenate((autoencoder_2_input , X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c802fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.6371\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.7514\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.7200\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.7314\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.7057\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.7429\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.7371\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.7543\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.7600\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.7629\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.7800\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7686\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7800\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.7914\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.7771\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.7657\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.7714\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.7743\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.7686\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.7771\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.7771\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.7686\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7800\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7743\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7657\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.7714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.7771\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.7800\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.7743\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.7771\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.7743\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.7686\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.7714\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.7714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.7771\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7629\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.7714\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.7571\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7657\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7686\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.7571\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.7686\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7743\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7686\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.7657\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.7686\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.7657\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.7657\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.7629\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7743\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7714\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.7629\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.7657\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7629\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7657\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7571\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7571\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7657\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7629\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7543\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7514\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7543\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7571\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7657\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7686\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7686\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7514\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7600\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7486\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7629\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7429\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7600\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7657\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7571\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7629\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7486\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7629\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7486\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7543\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7514\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7543\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7571\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.7571\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.7457\n"
     ]
    }
   ],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_2.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a793d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)\n",
    "autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "57d2cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 1ms/step - loss: 0.1772 - accuracy: 0.8429\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8486\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8429\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.83 - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8400\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8514\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8386\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8400\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8357\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8286\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8300\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8429\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8443\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8443\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8514\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8371\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8200\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.8343\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8371\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8514\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8471\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8357\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8400\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8371\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8343\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8429\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8371\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8486\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8457\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8457\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8471\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8400\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8329\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8343\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8386\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8329\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8371\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8500\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8429\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8429\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8514\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.8500\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8443\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8543\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8443\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "autoencoder_3 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_3.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "22ff8a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = Model(input_layer, encoder)\n",
    "X_ae1 = encoded.predict(X)\n",
    "X_ae1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "95838d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318800</td>\n",
       "      <td>1.074501</td>\n",
       "      <td>0.925603</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.445664</td>\n",
       "      <td>1.522639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.319359</td>\n",
       "      <td>1.074960</td>\n",
       "      <td>0.925644</td>\n",
       "      <td>0.060706</td>\n",
       "      <td>0.445611</td>\n",
       "      <td>1.522937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.320340</td>\n",
       "      <td>1.075920</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>0.060442</td>\n",
       "      <td>0.445836</td>\n",
       "      <td>1.523598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.324142</td>\n",
       "      <td>1.079639</td>\n",
       "      <td>0.924848</td>\n",
       "      <td>0.059435</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.526168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.328306</td>\n",
       "      <td>1.083765</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.450805</td>\n",
       "      <td>1.529232</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6    7\n",
       "0  0.0  1.318800  1.074501  0.925603  0.060879  0.445664  1.522639  0.0\n",
       "1  0.0  1.319359  1.074960  0.925644  0.060706  0.445611  1.522937  0.0\n",
       "2  0.0  1.320340  1.075920  0.925472  0.060442  0.445836  1.523598  0.0\n",
       "3  0.0  1.324142  1.079639  0.924848  0.059435  0.446809  1.526168  0.0\n",
       "4  0.0  1.328306  1.083765  0.925408  0.058882  0.450805  1.529232  0.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AEC_df = pd.DataFrame(data = X_ae1)\n",
    "AEC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d3bdfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(AEC_df, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4b13aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.6264 - val_loss: 13.2338\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.5360 - val_loss: 13.1645\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.4580 - val_loss: 13.0987\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.3793 - val_loss: 13.0307\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.2989 - val_loss: 12.9637\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.2186 - val_loss: 12.8912\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.1326 - val_loss: 12.8123\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.0392 - val_loss: 12.7254\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.9429 - val_loss: 12.6371\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.8498 - val_loss: 12.5520\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.7631 - val_loss: 12.4627\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.6735 - val_loss: 12.3760\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.5893 - val_loss: 12.2789\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.5006 - val_loss: 12.1788\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.4137 - val_loss: 12.0560\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.3140 - val_loss: 11.9416\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.2207 - val_loss: 11.8141\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.1140 - val_loss: 11.6893\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.0202 - val_loss: 11.5697\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.9406 - val_loss: 11.4437\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8576 - val_loss: 11.3089\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.7886 - val_loss: 11.1799\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.7254 - val_loss: 11.0509\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.6724 - val_loss: 10.9309\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.6134 - val_loss: 10.8218\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.5674 - val_loss: 10.7090\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.5201 - val_loss: 10.6021\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4864 - val_loss: 10.5066\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4548 - val_loss: 10.4318\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.4373 - val_loss: 10.3717\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4131 - val_loss: 10.3276\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3888 - val_loss: 10.2911\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3794 - val_loss: 10.2605\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3605 - val_loss: 10.2273\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3492 - val_loss: 10.1983\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3463 - val_loss: 10.1870\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3306 - val_loss: 10.1745\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3247 - val_loss: 10.1827\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3163 - val_loss: 10.1721\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3073 - val_loss: 10.1740\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2978 - val_loss: 10.1459\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2851 - val_loss: 10.1134\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2710 - val_loss: 10.0873\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.2639 - val_loss: 10.0730\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.2525 - val_loss: 10.0697\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2436 - val_loss: 10.0708\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2350 - val_loss: 10.0771\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.2229 - val_loss: 10.0673\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2138 - val_loss: 10.0111\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1999 - val_loss: 10.0046\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1957 - val_loss: 9.9787\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1793 - val_loss: 9.9640\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1677 - val_loss: 9.9516\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1611 - val_loss: 9.9239\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1629 - val_loss: 9.8727\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1436 - val_loss: 9.8729\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1420 - val_loss: 9.8794\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1210 - val_loss: 9.8664\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1124 - val_loss: 9.8649\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0996 - val_loss: 9.8287\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0950 - val_loss: 9.8087\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0791 - val_loss: 9.8156\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0701 - val_loss: 9.8113\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0610 - val_loss: 9.7884\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0490 - val_loss: 9.7712\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0472 - val_loss: 9.7660\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0368 - val_loss: 9.7605\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0203 - val_loss: 9.7643\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0050 - val_loss: 9.7343\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9924 - val_loss: 9.7161\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9933 - val_loss: 9.7162\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9713 - val_loss: 9.6819\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9642 - val_loss: 9.6663\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9538 - val_loss: 9.6251\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9321 - val_loss: 9.6028\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9331 - val_loss: 9.6365\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9219 - val_loss: 9.6052\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8919 - val_loss: 9.6186\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.8885 - val_loss: 9.5924\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.8674 - val_loss: 9.5659\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8508 - val_loss: 9.5211\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8382 - val_loss: 9.4912\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8237 - val_loss: 9.4973\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8072 - val_loss: 9.4974\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7874 - val_loss: 9.5181\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7803 - val_loss: 9.5443\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7613 - val_loss: 9.5030\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7430 - val_loss: 9.4796\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7341 - val_loss: 9.4576\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7170 - val_loss: 9.4270\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7047 - val_loss: 9.4016\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6864 - val_loss: 9.3624\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6852 - val_loss: 9.3497\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6664 - val_loss: 9.3570\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6365 - val_loss: 9.3511\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6246 - val_loss: 9.3762\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6181 - val_loss: 9.3971\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6005 - val_loss: 9.3872\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5805 - val_loss: 9.3604\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5662 - val_loss: 9.3022\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5483 - val_loss: 9.3261\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5315 - val_loss: 9.2637\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5275 - val_loss: 9.2356\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4901 - val_loss: 9.2093\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4724 - val_loss: 9.2429\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4602 - val_loss: 9.1950\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4403 - val_loss: 9.1214\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.4252 - val_loss: 9.1440\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.4014 - val_loss: 9.1947\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3811 - val_loss: 9.1957\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3760 - val_loss: 9.1803\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3485 - val_loss: 9.1647\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3219 - val_loss: 9.1456\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2959 - val_loss: 9.1437\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2883 - val_loss: 9.1915\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2635 - val_loss: 9.1214\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2403 - val_loss: 9.0926\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2229 - val_loss: 9.0182\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1913 - val_loss: 9.0090\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1751 - val_loss: 9.0573\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.1494 - val_loss: 9.0618\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1571 - val_loss: 9.0729\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1151 - val_loss: 8.9945\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0941 - val_loss: 8.9730\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0722 - val_loss: 8.9152\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0556 - val_loss: 8.9467\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0559 - val_loss: 8.8926\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0205 - val_loss: 8.9211\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9733 - val_loss: 8.9127\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9570 - val_loss: 8.9261\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.9516 - val_loss: 8.9025\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9222 - val_loss: 8.8643\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8928 - val_loss: 8.8456\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8895 - val_loss: 8.8148\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8762 - val_loss: 8.8326\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8639 - val_loss: 8.7948\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8422 - val_loss: 8.8115\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8331 - val_loss: 8.8230\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8065 - val_loss: 8.7564\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8094 - val_loss: 8.7796\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7933 - val_loss: 8.7976\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7815 - val_loss: 8.8116\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7659 - val_loss: 8.8328\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.7553 - val_loss: 8.8844\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7796 - val_loss: 8.8292\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.7454 - val_loss: 8.8243\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7360 - val_loss: 8.8330\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7236 - val_loss: 8.8201\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.7223 - val_loss: 8.8392\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7169 - val_loss: 8.8335\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7155 - val_loss: 8.8288\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7048 - val_loss: 8.7987\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7237 - val_loss: 8.8018\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6820 - val_loss: 8.7947\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6924 - val_loss: 8.7992\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6739 - val_loss: 8.8151\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6668 - val_loss: 8.7956\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6819 - val_loss: 8.7983\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6547 - val_loss: 8.7836\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6626 - val_loss: 8.7825\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6872 - val_loss: 8.7799\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6513 - val_loss: 8.7967\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6460 - val_loss: 8.7866\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6288 - val_loss: 8.7600\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6475 - val_loss: 8.7620\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6723 - val_loss: 8.7662\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6022 - val_loss: 8.7593\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5995 - val_loss: 8.7607\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5958 - val_loss: 8.7645\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5825 - val_loss: 8.7629\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5866 - val_loss: 8.7656\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5981 - val_loss: 8.7535\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5891 - val_loss: 8.7364\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5753 - val_loss: 8.7253\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5519 - val_loss: 8.7179\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5596 - val_loss: 8.7204\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5379 - val_loss: 8.7234\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5308 - val_loss: 8.7150\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5359 - val_loss: 8.7289\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5304 - val_loss: 8.7091\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5237 - val_loss: 8.7054\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5353 - val_loss: 8.7685\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5238 - val_loss: 8.6937\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5097 - val_loss: 8.6888\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5144 - val_loss: 8.6944\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5086 - val_loss: 8.6935\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5059 - val_loss: 8.6826\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5153 - val_loss: 8.6865\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4899 - val_loss: 8.6751\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4772 - val_loss: 8.6658\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5272 - val_loss: 8.6501\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4806 - val_loss: 8.6263\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4664 - val_loss: 8.6320\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4637 - val_loss: 8.6200\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.4633 - val_loss: 8.6049\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4694 - val_loss: 8.6066\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4541 - val_loss: 8.5961\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4549 - val_loss: 8.6254\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4749 - val_loss: 8.5882\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4593 - val_loss: 8.5766\n",
      "Train: 6.411, Test: 8.577\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT Modify\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(8, input_dim=8, activation='relu'))\n",
    "reg_model.add(Dense(4, activation='relu'))\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='SGD')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=200, verbose=1)\n",
    "\n",
    "train_mse = reg_model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "y_preds=reg_model.predict(X_test)\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "926bd5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,y_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dc281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac7b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda8c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88278f9f",
   "metadata": {},
   "source": [
    "# Independent component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3cc49f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=8)\n",
    "X_ica = ica.fit_transform(X)\n",
    "X_ica = pd.DataFrame(data = X_ica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b36b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.022781</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>-0.038583</td>\n",
       "      <td>-0.108172</td>\n",
       "      <td>-0.041023</td>\n",
       "      <td>-0.093598</td>\n",
       "      <td>-0.011073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020285</td>\n",
       "      <td>-0.022597</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.038582</td>\n",
       "      <td>-0.108187</td>\n",
       "      <td>-0.040975</td>\n",
       "      <td>-0.093622</td>\n",
       "      <td>-0.011098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020289</td>\n",
       "      <td>-0.022290</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>-0.038580</td>\n",
       "      <td>-0.108213</td>\n",
       "      <td>-0.040894</td>\n",
       "      <td>-0.093661</td>\n",
       "      <td>-0.011139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020303</td>\n",
       "      <td>-0.021062</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>-0.093819</td>\n",
       "      <td>-0.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020330</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>-0.038556</td>\n",
       "      <td>-0.108520</td>\n",
       "      <td>-0.039925</td>\n",
       "      <td>-0.094134</td>\n",
       "      <td>-0.011638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.020283 -0.022781  0.017370 -0.038583 -0.108172 -0.041023 -0.093598   \n",
       "1  0.020285 -0.022597  0.017342 -0.038582 -0.108187 -0.040975 -0.093622   \n",
       "2  0.020289 -0.022290  0.017297 -0.038580 -0.108213 -0.040894 -0.093661   \n",
       "3  0.020303 -0.021062  0.017116 -0.038572 -0.108315 -0.040571 -0.093819   \n",
       "4  0.020330 -0.018608  0.016753 -0.038556 -0.108520 -0.039925 -0.094134   \n",
       "\n",
       "          7  \n",
       "0 -0.011073  \n",
       "1 -0.011098  \n",
       "2 -0.011139  \n",
       "3 -0.011306  \n",
       "4 -0.011638  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fdb5280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ica, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66903e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 67ms/step - loss: 10.7883 - val_loss: 13.2048\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.3257 - val_loss: 12.7186\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.7685 - val_loss: 12.1164\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.3866 - val_loss: 11.5080\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.0628 - val_loss: 11.0104\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7313 - val_loss: 10.6259\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8943 - val_loss: 10.4057\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6909 - val_loss: 10.3392\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6909 - val_loss: 10.2952\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6639 - val_loss: 10.3796\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9928 - val_loss: 10.4413\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8727 - val_loss: 10.5398\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6551 - val_loss: 10.6020\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7700 - val_loss: 10.6096\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8639 - val_loss: 10.6014\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6125 - val_loss: 10.5293\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7584 - val_loss: 10.4557\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7457 - val_loss: 10.4195\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7851 - val_loss: 10.4504\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5019 - val_loss: 10.4530\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5948 - val_loss: 10.4126\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7233 - val_loss: 10.3380\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6719 - val_loss: 10.3072\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7041 - val_loss: 10.3357\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6037 - val_loss: 10.3203\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6144 - val_loss: 10.3656\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7326 - val_loss: 10.3732\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5844 - val_loss: 10.3579\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7178 - val_loss: 10.3159\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8855 - val_loss: 10.3875\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7429 - val_loss: 10.4902\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5938 - val_loss: 10.4514\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4886 - val_loss: 10.4143\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5731 - val_loss: 10.3279\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4549 - val_loss: 10.3113\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6077 - val_loss: 10.2388\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4541 - val_loss: 10.1932\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6369 - val_loss: 10.1739\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4764 - val_loss: 10.2003\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6445 - val_loss: 10.3281\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5480 - val_loss: 10.4363\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4947 - val_loss: 10.3879\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5015 - val_loss: 10.2863\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5103 - val_loss: 10.2751\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3548 - val_loss: 10.2129\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6073 - val_loss: 10.2820\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3583 - val_loss: 10.2607\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5734 - val_loss: 10.3270\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7579 - val_loss: 10.3744\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4321 - val_loss: 10.4388\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4694 - val_loss: 10.3405\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6774 - val_loss: 10.3709\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.6974 - val_loss: 10.3856\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5826 - val_loss: 10.4548\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3858 - val_loss: 10.4491\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4198 - val_loss: 10.3236\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3979 - val_loss: 10.1389\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4578 - val_loss: 10.1470\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3346 - val_loss: 10.0316\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2469 - val_loss: 10.0444\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7059 - val_loss: 10.3711\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4168 - val_loss: 10.5553\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5018 - val_loss: 10.1421\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5788 - val_loss: 10.2344\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3416 - val_loss: 10.4761\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3269 - val_loss: 10.2508\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4879 - val_loss: 10.1670\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2552 - val_loss: 10.1722\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0753 - val_loss: 9.9802\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4754 - val_loss: 10.0439\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2185 - val_loss: 10.1490\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2671 - val_loss: 10.3440\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2304 - val_loss: 10.2162\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2945 - val_loss: 9.9242\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2032 - val_loss: 10.0018\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1358 - val_loss: 9.9515\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0958 - val_loss: 10.0160\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0810 - val_loss: 9.9074\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9435 - val_loss: 9.9284\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0241 - val_loss: 10.0129\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2835 - val_loss: 10.0528\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3307 - val_loss: 9.9255\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9438 - val_loss: 9.9268\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0385 - val_loss: 9.8188\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8875 - val_loss: 9.8163\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7502 - val_loss: 9.8048\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8159 - val_loss: 10.0285\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8535 - val_loss: 9.7909\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8312 - val_loss: 9.8070\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5826 - val_loss: 10.0192\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9866 - val_loss: 9.8414\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9026 - val_loss: 9.7480\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5589 - val_loss: 10.0343\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.5681 - val_loss: 9.8253\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7547 - val_loss: 9.8153\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7376 - val_loss: 10.1266\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9734 - val_loss: 9.6866\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3262 - val_loss: 10.4230\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6991 - val_loss: 9.6902\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1556 - val_loss: 11.0494\n",
      "Train: 8.478, Test: 11.049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = Sequential()\n",
    "a=reg_model.add(Dense(3, input_dim=4, activation=LeakyReLU(),kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(2, activation=LeakyReLU(),kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(1, activation='linear',kernel_regularizer='l2'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer=opt)\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=100, verbose=1)\n",
    "y_pred=reg_model.predict(X_test)\n",
    "train_mse = reg_model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_mse = reg_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb52398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
