{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "81cb833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from sklearn.metrics import confusion_matrix , classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(1234)\n",
    "import os\n",
    "import random\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef72364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a468839",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1a030d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11  \\\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3   \n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0   \n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5   \n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0   \n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4977254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f8d132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdd8a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33103b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f399522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data['X11']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91ea07b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.3\n",
       "1    10.0\n",
       "2    17.5\n",
       "3    31.0\n",
       "4    34.0\n",
       "Name: X11, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be9fbbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "17\n",
      "8\n",
      "18\n",
      "17\n",
      "9\n",
      "14\n",
      "55\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#We check the number of unique values in each column\n",
    "a=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "for i in a:\n",
    "    print(len(X[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b7e7ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1c177d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this code reduces the  above outliers seen. This is done by chaning the values in the box plot based on inter quantile range \n",
    "# for i in X.columns:\n",
    "#     q1=X[i].quantile(0.25)\n",
    "#     q3=X[i].quantile(0.75)\n",
    "#     iqr=q3-q1\n",
    "#     ub=q3 + 1.5*iqr\n",
    "#     lb=q1 - 1.5*iqr\n",
    "#     uc=X[i].quantile(0.99)\n",
    "#     lc=X[i].quantile(0.01)\n",
    "#     for ind1 in X[i].index:\n",
    "#         if X.loc[ind1, i] >ub:            \n",
    "#             X.loc[ind1, i] =uc\n",
    "#         if X.loc[ind1, i] < lb:\n",
    "#             X.loc[ind1, i] =lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb85fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the boxplot for each variable\n",
    "# # subplots(): plot subplots\n",
    "# # figsize(): set the figure size\n",
    "# fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# # plot the boxplot using boxplot() from seaborn\n",
    "# # z: let the variable z define the boxplot\n",
    "# # x: data for which the boxplot is to be plotted\n",
    "# # orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# # whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# # ax: specifies the axes object to draw the plot o\n",
    "# # set_xlabel(): set the x-axis label\n",
    "# # fontsize: sets the font size of the x-axis label\n",
    "# for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "#     z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "#     z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f03ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3bdd997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9de59713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04c3b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "520d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "50c30fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2f2dea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_RF_Acc :  0.8073577453485754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, Y)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "RF_accuracies = cross_val_score(estimator = rf, X = X, y = Y, cv = kf,scoring=\"r2\")\n",
    "print(\"Mean_RF_Acc : \", RF_accuracies.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510874b",
   "metadata": {},
   "source": [
    "# So i just tried a neural network below, it is similar to the neural network given in the machine learning mastery, not really sure what it means but have to work on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f3856118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20a4a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "73c822c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "41e42b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8232db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dbb5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf887b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c9623fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "6/6 [==============================] - 1s 29ms/step - loss: 11.1810 - val_loss: 13.7671\n",
      "Epoch 2/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 11.0213 - val_loss: 13.6649\n",
      "Epoch 3/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.8988 - val_loss: 13.5659\n",
      "Epoch 4/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.7753 - val_loss: 13.4604\n",
      "Epoch 5/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.6402 - val_loss: 13.3492\n",
      "Epoch 6/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.4936 - val_loss: 13.2242\n",
      "Epoch 7/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.3446 - val_loss: 13.0745\n",
      "Epoch 8/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.1733 - val_loss: 12.9007\n",
      "Epoch 9/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.9972 - val_loss: 12.6963\n",
      "Epoch 10/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.7883 - val_loss: 12.4654\n",
      "Epoch 11/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.5717 - val_loss: 12.2016\n",
      "Epoch 12/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.3635 - val_loss: 11.9040\n",
      "Epoch 13/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.1280 - val_loss: 11.5949\n",
      "Epoch 14/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8775 - val_loss: 11.2764\n",
      "Epoch 15/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.6269 - val_loss: 10.9472\n",
      "Epoch 16/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.4058 - val_loss: 10.5909\n",
      "Epoch 17/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.1402 - val_loss: 10.2537\n",
      "Epoch 18/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8580 - val_loss: 9.9554\n",
      "Epoch 19/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.6134 - val_loss: 9.5968\n",
      "Epoch 20/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.3437 - val_loss: 9.3008\n",
      "Epoch 21/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.0835 - val_loss: 9.0363\n",
      "Epoch 22/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.8028 - val_loss: 8.8016\n",
      "Epoch 23/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.5580 - val_loss: 8.5567\n",
      "Epoch 24/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.3190 - val_loss: 8.3356\n",
      "Epoch 25/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.0710 - val_loss: 8.1249\n",
      "Epoch 26/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.8466 - val_loss: 7.9852\n",
      "Epoch 27/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5840 - val_loss: 7.8210\n",
      "Epoch 28/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.3426 - val_loss: 7.6669\n",
      "Epoch 29/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1603 - val_loss: 7.5198\n",
      "Epoch 30/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9983 - val_loss: 7.3329\n",
      "Epoch 31/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9017 - val_loss: 7.1091\n",
      "Epoch 32/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7395 - val_loss: 7.0192\n",
      "Epoch 33/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6114 - val_loss: 6.8794\n",
      "Epoch 34/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5369 - val_loss: 6.7660\n",
      "Epoch 35/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4602 - val_loss: 6.6194\n",
      "Epoch 36/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4104 - val_loss: 6.5153\n",
      "Epoch 37/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3554 - val_loss: 6.4413\n",
      "Epoch 38/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3163 - val_loss: 6.3856\n",
      "Epoch 39/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2672 - val_loss: 6.3416\n",
      "Epoch 40/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2422 - val_loss: 6.3003\n",
      "Epoch 41/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2286 - val_loss: 6.2962\n",
      "Epoch 42/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2091 - val_loss: 6.2334\n",
      "Epoch 43/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1777 - val_loss: 6.2332\n",
      "Epoch 44/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1615 - val_loss: 6.1953\n",
      "Epoch 45/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1333 - val_loss: 6.1811\n",
      "Epoch 46/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1287 - val_loss: 6.1562\n",
      "Epoch 47/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0950 - val_loss: 6.1141\n",
      "Epoch 48/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0804 - val_loss: 6.0849\n",
      "Epoch 49/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0659 - val_loss: 6.1026\n",
      "Epoch 50/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0698 - val_loss: 6.0805\n",
      "Epoch 51/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0450 - val_loss: 6.0620\n",
      "Epoch 52/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0302 - val_loss: 6.0391\n",
      "Epoch 53/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0343 - val_loss: 6.0068\n",
      "Epoch 54/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0213 - val_loss: 6.0484\n",
      "Epoch 55/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0093 - val_loss: 5.9899\n",
      "Epoch 56/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0084 - val_loss: 6.0018\n",
      "Epoch 57/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0062 - val_loss: 5.9773\n",
      "Epoch 58/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9788 - val_loss: 6.0182\n",
      "Epoch 59/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9982 - val_loss: 6.0304\n",
      "Epoch 60/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9900 - val_loss: 5.9878\n",
      "Epoch 61/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9949 - val_loss: 5.9627\n",
      "Epoch 62/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9615 - val_loss: 6.0011\n",
      "Epoch 63/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9729 - val_loss: 5.9654\n",
      "Epoch 64/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9795 - val_loss: 5.9434\n",
      "Epoch 65/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9662 - val_loss: 6.0176\n",
      "Epoch 66/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9752 - val_loss: 5.9469\n",
      "Epoch 67/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9652 - val_loss: 5.8720\n",
      "Epoch 68/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9537 - val_loss: 5.9380\n",
      "Epoch 69/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9433 - val_loss: 5.9435\n",
      "Epoch 70/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9415 - val_loss: 5.9145\n",
      "Epoch 71/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8961 - val_loss: 5.9497\n",
      "Epoch 72/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9145 - val_loss: 5.8930\n",
      "Epoch 73/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8872 - val_loss: 5.9555\n",
      "Epoch 74/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8928 - val_loss: 5.8665\n",
      "Epoch 75/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8909 - val_loss: 5.8956\n",
      "Epoch 76/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8821 - val_loss: 5.8786\n",
      "Epoch 77/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8789 - val_loss: 5.8824\n",
      "Epoch 78/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8636 - val_loss: 5.8339\n",
      "Epoch 79/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8658 - val_loss: 5.8568\n",
      "Epoch 80/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8467 - val_loss: 5.8471\n",
      "Epoch 81/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8426 - val_loss: 5.8638\n",
      "Epoch 82/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8361 - val_loss: 5.8236\n",
      "Epoch 83/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8254 - val_loss: 5.8282\n",
      "Epoch 84/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8413 - val_loss: 5.8289\n",
      "Epoch 85/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8282 - val_loss: 5.8358\n",
      "Epoch 86/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8113 - val_loss: 5.8162\n",
      "Epoch 87/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8167 - val_loss: 5.7966\n",
      "Epoch 88/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8026 - val_loss: 5.8188\n",
      "Epoch 89/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8205 - val_loss: 5.8035\n",
      "Epoch 90/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8462 - val_loss: 5.8917\n",
      "Epoch 91/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8137 - val_loss: 5.7561\n",
      "Epoch 92/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8296 - val_loss: 5.7790\n",
      "Epoch 93/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7878 - val_loss: 5.8224\n",
      "Epoch 94/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8007 - val_loss: 5.7686\n",
      "Epoch 95/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7773 - val_loss: 5.7632\n",
      "Epoch 96/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7797 - val_loss: 5.7721\n",
      "Epoch 97/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7963 - val_loss: 5.7977\n",
      "Epoch 98/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7791 - val_loss: 5.7474\n",
      "Epoch 99/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7912 - val_loss: 5.7529\n",
      "Epoch 100/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7935 - val_loss: 5.7456\n",
      "Epoch 101/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7741 - val_loss: 5.7339\n",
      "Epoch 102/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7774 - val_loss: 5.7190\n",
      "Epoch 103/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7639 - val_loss: 5.7777\n",
      "Epoch 104/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7686 - val_loss: 5.7296\n",
      "Epoch 105/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7505 - val_loss: 5.7453\n",
      "Epoch 106/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7540 - val_loss: 5.7324\n",
      "Epoch 107/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7496 - val_loss: 5.7183\n",
      "Epoch 108/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7572 - val_loss: 5.7292\n",
      "Epoch 109/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7449 - val_loss: 5.7269\n",
      "Epoch 110/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7440 - val_loss: 5.7560\n",
      "Epoch 111/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7450 - val_loss: 5.6676\n",
      "Epoch 112/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7265 - val_loss: 5.7063\n",
      "Epoch 113/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7271 - val_loss: 5.6809\n",
      "Epoch 114/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7218 - val_loss: 5.7088\n",
      "Epoch 115/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7319 - val_loss: 5.6901\n",
      "Epoch 116/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7292 - val_loss: 5.6953\n",
      "Epoch 117/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7317 - val_loss: 5.6733\n",
      "Epoch 118/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7135 - val_loss: 5.6738\n",
      "Epoch 119/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7064 - val_loss: 5.6857\n",
      "Epoch 120/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7227 - val_loss: 5.6887\n",
      "Epoch 121/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7039 - val_loss: 5.6880\n",
      "Epoch 122/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7083 - val_loss: 5.6432\n",
      "Epoch 123/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7140 - val_loss: 5.6843\n",
      "Epoch 124/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7048 - val_loss: 5.6387\n",
      "Epoch 125/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6970 - val_loss: 5.6697\n",
      "Epoch 126/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7064 - val_loss: 5.6686\n",
      "Epoch 127/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6977 - val_loss: 5.6616\n",
      "Epoch 128/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6796 - val_loss: 5.6387\n",
      "Epoch 129/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6984 - val_loss: 5.6309\n",
      "Epoch 130/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6791 - val_loss: 5.6500\n",
      "Epoch 131/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6841 - val_loss: 5.6513\n",
      "Epoch 132/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6788 - val_loss: 5.6562\n",
      "Epoch 133/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7110 - val_loss: 5.6189\n",
      "Epoch 134/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6834 - val_loss: 5.6796\n",
      "Epoch 135/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7181 - val_loss: 5.5990\n",
      "Epoch 136/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7168 - val_loss: 5.5810\n",
      "Epoch 137/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7142 - val_loss: 5.6298\n",
      "Epoch 138/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6830 - val_loss: 5.6029\n",
      "Epoch 139/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6811 - val_loss: 5.6182\n",
      "Epoch 140/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6587 - val_loss: 5.5809\n",
      "Epoch 141/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6578 - val_loss: 5.5890\n",
      "Epoch 142/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6573 - val_loss: 5.5455\n",
      "Epoch 143/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6609 - val_loss: 5.5672\n",
      "Epoch 144/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6710 - val_loss: 5.5913\n",
      "Epoch 145/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7141 - val_loss: 5.5828\n",
      "Epoch 146/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6772 - val_loss: 5.6076\n",
      "Epoch 147/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6792 - val_loss: 5.5277\n",
      "Epoch 148/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6622 - val_loss: 5.5927\n",
      "Epoch 149/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6630 - val_loss: 5.5796\n",
      "Epoch 150/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6823 - val_loss: 5.5619\n",
      "Epoch 151/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6470 - val_loss: 5.6042\n",
      "Epoch 152/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6668 - val_loss: 5.5771\n",
      "Epoch 153/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6571 - val_loss: 5.5498\n",
      "Epoch 154/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6578 - val_loss: 5.5464\n",
      "Epoch 155/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6527 - val_loss: 5.5240\n",
      "Epoch 156/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6343 - val_loss: 5.5676\n",
      "Epoch 157/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6471 - val_loss: 5.5304\n",
      "Epoch 158/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6413 - val_loss: 5.5507\n",
      "Epoch 159/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6280 - val_loss: 5.5293\n",
      "Epoch 160/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6471 - val_loss: 5.5119\n",
      "Epoch 161/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6468 - val_loss: 5.5561\n",
      "Epoch 162/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6574 - val_loss: 5.5538\n",
      "Epoch 163/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6316 - val_loss: 5.5217\n",
      "Epoch 164/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6211 - val_loss: 5.5008\n",
      "Epoch 165/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6151 - val_loss: 5.5779\n",
      "Epoch 166/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6770 - val_loss: 5.5556\n",
      "Epoch 167/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6176 - val_loss: 5.5032\n",
      "Epoch 168/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6160 - val_loss: 5.5169\n",
      "Epoch 169/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6049 - val_loss: 5.5128\n",
      "Epoch 170/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6032 - val_loss: 5.4985\n",
      "Epoch 171/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6146 - val_loss: 5.5025\n",
      "Epoch 172/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6056 - val_loss: 5.5079\n",
      "Epoch 173/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6066 - val_loss: 5.4882\n",
      "Epoch 174/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6040 - val_loss: 5.4656\n",
      "Epoch 175/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5972 - val_loss: 5.4627\n",
      "Epoch 176/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5793 - val_loss: 5.4853\n",
      "Epoch 177/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5972 - val_loss: 5.4910\n",
      "Epoch 178/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5837 - val_loss: 5.4644\n",
      "Epoch 179/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6082 - val_loss: 5.4597\n",
      "Epoch 180/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6036 - val_loss: 5.4717\n",
      "Epoch 181/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5783 - val_loss: 5.4726\n",
      "Epoch 182/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5826 - val_loss: 5.4407\n",
      "Epoch 183/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5709 - val_loss: 5.4877\n",
      "Epoch 184/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6154 - val_loss: 5.4680\n",
      "Epoch 185/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5786 - val_loss: 5.4672\n",
      "Epoch 186/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5747 - val_loss: 5.4619\n",
      "Epoch 187/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5772 - val_loss: 5.4667\n",
      "Epoch 188/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6183 - val_loss: 5.4189\n",
      "Epoch 189/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5800 - val_loss: 5.4649\n",
      "Epoch 190/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5754 - val_loss: 5.4589\n",
      "Epoch 191/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5748 - val_loss: 5.4293\n",
      "Epoch 192/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5748 - val_loss: 5.4272\n",
      "Epoch 193/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5700 - val_loss: 5.4180\n",
      "Epoch 194/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5770 - val_loss: 5.4074\n",
      "Epoch 195/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5837 - val_loss: 5.4083\n",
      "Epoch 196/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5698 - val_loss: 5.4536\n",
      "Epoch 197/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5739 - val_loss: 5.4014\n",
      "Epoch 198/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5496 - val_loss: 5.4240\n",
      "Epoch 199/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5739 - val_loss: 5.4064\n",
      "Epoch 200/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5517 - val_loss: 5.4346\n",
      "Epoch 201/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5704 - val_loss: 5.4218\n",
      "Epoch 202/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5484 - val_loss: 5.4048\n",
      "Epoch 203/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5437 - val_loss: 5.4023\n",
      "Epoch 204/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5473 - val_loss: 5.3806\n",
      "Epoch 205/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5438 - val_loss: 5.3599\n",
      "Epoch 206/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5377 - val_loss: 5.3442\n",
      "Epoch 207/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5335 - val_loss: 5.3956\n",
      "Epoch 208/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5343 - val_loss: 5.3678\n",
      "Epoch 209/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5472 - val_loss: 5.3804\n",
      "Epoch 210/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5359 - val_loss: 5.3543\n",
      "Epoch 211/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5341 - val_loss: 5.3916\n",
      "Epoch 212/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5409 - val_loss: 5.3833\n",
      "Epoch 213/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5438 - val_loss: 5.3435\n",
      "Epoch 214/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5389 - val_loss: 5.3627\n",
      "Epoch 215/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5503 - val_loss: 5.3775\n",
      "Epoch 216/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5423 - val_loss: 5.3295\n",
      "Epoch 217/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5474 - val_loss: 5.3669\n",
      "Epoch 218/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5279 - val_loss: 5.3252\n",
      "Epoch 219/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5090 - val_loss: 5.3609\n",
      "Epoch 220/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5351 - val_loss: 5.3635\n",
      "Epoch 221/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5138 - val_loss: 5.3653\n",
      "Epoch 222/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5169 - val_loss: 5.3087\n",
      "Epoch 223/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5023 - val_loss: 5.3414\n",
      "Epoch 224/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4923 - val_loss: 5.3348\n",
      "Epoch 225/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5115 - val_loss: 5.3362\n",
      "Epoch 226/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5081 - val_loss: 5.3076\n",
      "Epoch 227/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5133 - val_loss: 5.3401\n",
      "Epoch 228/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5105 - val_loss: 5.3036\n",
      "Epoch 229/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5072 - val_loss: 5.3295\n",
      "Epoch 230/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5027 - val_loss: 5.2917\n",
      "Epoch 231/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4918 - val_loss: 5.3213\n",
      "Epoch 232/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4881 - val_loss: 5.2961\n",
      "Epoch 233/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5125 - val_loss: 5.2838\n",
      "Epoch 234/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4769 - val_loss: 5.2837\n",
      "Epoch 235/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4834 - val_loss: 5.2959\n",
      "Epoch 236/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4850 - val_loss: 5.2798\n",
      "Epoch 237/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4811 - val_loss: 5.2642\n",
      "Epoch 238/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4792 - val_loss: 5.3006\n",
      "Epoch 239/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4752 - val_loss: 5.2596\n",
      "Epoch 240/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4998 - val_loss: 5.2881\n",
      "Epoch 241/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5168 - val_loss: 5.2476\n",
      "Epoch 242/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5061 - val_loss: 5.2904\n",
      "Epoch 243/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4762 - val_loss: 5.2535\n",
      "Epoch 244/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4877 - val_loss: 5.2520\n",
      "Epoch 245/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4792 - val_loss: 5.2509\n",
      "Epoch 246/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4635 - val_loss: 5.2719\n",
      "Epoch 247/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4716 - val_loss: 5.2496\n",
      "Epoch 248/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4635 - val_loss: 5.2665\n",
      "Epoch 249/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4862 - val_loss: 5.2067\n",
      "Epoch 250/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4872 - val_loss: 5.2224\n",
      "Epoch 251/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4650 - val_loss: 5.2093\n",
      "Epoch 252/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4531 - val_loss: 5.2469\n",
      "Epoch 253/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4788 - val_loss: 5.2281\n",
      "Epoch 254/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4653 - val_loss: 5.2097\n",
      "Epoch 255/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4529 - val_loss: 5.1841\n",
      "Epoch 256/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4594 - val_loss: 5.2205\n",
      "Epoch 257/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4410 - val_loss: 5.2157\n",
      "Epoch 258/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4370 - val_loss: 5.1948\n",
      "Epoch 259/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4388 - val_loss: 5.2205\n",
      "Epoch 260/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4461 - val_loss: 5.1997\n",
      "Epoch 261/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4340 - val_loss: 5.1973\n",
      "Epoch 262/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4573 - val_loss: 5.2072\n",
      "Epoch 263/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4500 - val_loss: 5.1977\n",
      "Epoch 264/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4242 - val_loss: 5.1947\n",
      "Epoch 265/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4420 - val_loss: 5.1502\n",
      "Epoch 266/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4435 - val_loss: 5.1986\n",
      "Epoch 267/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4455 - val_loss: 5.1813\n",
      "Epoch 268/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4256 - val_loss: 5.1549\n",
      "Epoch 269/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4377 - val_loss: 5.1849\n",
      "Epoch 270/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4505 - val_loss: 5.1760\n",
      "Epoch 271/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4136 - val_loss: 5.1333\n",
      "Epoch 272/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4278 - val_loss: 5.1299\n",
      "Epoch 273/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4055 - val_loss: 5.1810\n",
      "Epoch 274/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4195 - val_loss: 5.1206\n",
      "Epoch 275/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4420 - val_loss: 5.1463\n",
      "Epoch 276/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4442 - val_loss: 5.1388\n",
      "Epoch 277/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4521 - val_loss: 5.1358\n",
      "Epoch 278/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4306 - val_loss: 5.1563\n",
      "Epoch 279/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4029 - val_loss: 5.1487\n",
      "Epoch 280/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3957 - val_loss: 5.1286\n",
      "Epoch 281/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3984 - val_loss: 5.1301\n",
      "Epoch 282/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4010 - val_loss: 5.1072\n",
      "Epoch 283/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4003 - val_loss: 5.0970\n",
      "Epoch 284/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4066 - val_loss: 5.1106\n",
      "Epoch 285/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4066 - val_loss: 5.0972\n",
      "Epoch 286/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4087 - val_loss: 5.0781\n",
      "Epoch 287/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4028 - val_loss: 5.0746\n",
      "Epoch 288/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3905 - val_loss: 5.0736\n",
      "Epoch 289/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3806 - val_loss: 5.0812\n",
      "Epoch 290/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3955 - val_loss: 5.0894\n",
      "Epoch 291/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3842 - val_loss: 5.0514\n",
      "Epoch 292/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3967 - val_loss: 5.0785\n",
      "Epoch 293/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4167 - val_loss: 5.0498\n",
      "Epoch 294/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4041 - val_loss: 5.0821\n",
      "Epoch 295/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4002 - val_loss: 5.0533\n",
      "Epoch 296/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4289 - val_loss: 5.0987\n",
      "Epoch 297/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4180 - val_loss: 5.0721\n",
      "Epoch 298/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4577 - val_loss: 5.0953\n",
      "Epoch 299/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4683 - val_loss: 5.0748\n",
      "Epoch 300/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3829 - val_loss: 5.0367\n",
      "Epoch 301/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3643 - val_loss: 5.0564\n",
      "Epoch 302/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3767 - val_loss: 5.0268\n",
      "Epoch 303/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3868 - val_loss: 5.0353\n",
      "Epoch 304/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3789 - val_loss: 5.0146\n",
      "Epoch 305/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3624 - val_loss: 5.0117\n",
      "Epoch 306/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3596 - val_loss: 5.0550\n",
      "Epoch 307/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3699 - val_loss: 4.9997\n",
      "Epoch 308/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3887 - val_loss: 5.0144\n",
      "Epoch 309/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3574 - val_loss: 4.9863\n",
      "Epoch 310/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3582 - val_loss: 5.0215\n",
      "Epoch 311/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3486 - val_loss: 4.9488\n",
      "Epoch 312/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3867 - val_loss: 5.0084\n",
      "Epoch 313/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3708 - val_loss: 4.9912\n",
      "Epoch 314/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3747 - val_loss: 5.0267\n",
      "Epoch 315/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3854 - val_loss: 5.0050\n",
      "Epoch 316/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3629 - val_loss: 4.9690\n",
      "Epoch 317/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3580 - val_loss: 4.9664\n",
      "Epoch 318/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3589 - val_loss: 4.9662\n",
      "Epoch 319/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3423 - val_loss: 4.9577\n",
      "Epoch 320/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3310 - val_loss: 4.9854\n",
      "Epoch 321/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3355 - val_loss: 4.9740\n",
      "Epoch 322/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3382 - val_loss: 4.9124\n",
      "Epoch 323/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3464 - val_loss: 5.0061\n",
      "Epoch 324/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3423 - val_loss: 4.9405\n",
      "Epoch 325/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3269 - val_loss: 4.9434\n",
      "Epoch 326/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3193 - val_loss: 4.9829\n",
      "Epoch 327/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3617 - val_loss: 4.9319\n",
      "Epoch 328/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3454 - val_loss: 4.9460\n",
      "Epoch 329/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3340 - val_loss: 4.9458\n",
      "Epoch 330/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3162 - val_loss: 4.9657\n",
      "Epoch 331/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3180 - val_loss: 4.9357\n",
      "Epoch 332/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3025 - val_loss: 4.9654\n",
      "Epoch 333/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3347 - val_loss: 4.9641\n",
      "Epoch 334/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3221 - val_loss: 4.9154\n",
      "Epoch 335/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3403 - val_loss: 4.9494\n",
      "Epoch 336/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3209 - val_loss: 4.9163\n",
      "Epoch 337/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2954 - val_loss: 4.9487\n",
      "Epoch 338/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3047 - val_loss: 4.9337\n",
      "Epoch 339/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3105 - val_loss: 4.9231\n",
      "Epoch 340/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3181 - val_loss: 4.9193\n",
      "Epoch 341/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3168 - val_loss: 4.9137\n",
      "Epoch 342/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3126 - val_loss: 4.9097\n",
      "Epoch 343/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3066 - val_loss: 4.9025\n",
      "Epoch 344/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3048 - val_loss: 4.8916\n",
      "Epoch 345/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3007 - val_loss: 4.8752\n",
      "Epoch 346/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3398 - val_loss: 4.8627\n",
      "Epoch 347/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3072 - val_loss: 4.8809\n",
      "Epoch 348/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3059 - val_loss: 4.8914\n",
      "Epoch 349/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3094 - val_loss: 4.8590\n",
      "Epoch 350/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3260 - val_loss: 4.8854\n",
      "Epoch 351/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3054 - val_loss: 4.8448\n",
      "Epoch 352/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3188 - val_loss: 4.8455\n",
      "Epoch 353/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3128 - val_loss: 4.8836\n",
      "Epoch 354/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2836 - val_loss: 4.8118\n",
      "Epoch 355/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3008 - val_loss: 4.8350\n",
      "Epoch 356/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2684 - val_loss: 4.8457\n",
      "Epoch 357/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2682 - val_loss: 4.8427\n",
      "Epoch 358/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2699 - val_loss: 4.8160\n",
      "Epoch 359/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2748 - val_loss: 4.8260\n",
      "Epoch 360/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2701 - val_loss: 4.8481\n",
      "Epoch 361/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2600 - val_loss: 4.8554\n",
      "Epoch 362/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2823 - val_loss: 4.8221\n",
      "Epoch 363/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2717 - val_loss: 4.8314\n",
      "Epoch 364/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2647 - val_loss: 4.8087\n",
      "Epoch 365/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2680 - val_loss: 4.8678\n",
      "Epoch 366/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2721 - val_loss: 4.8073\n",
      "Epoch 367/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2878 - val_loss: 4.8261\n",
      "Epoch 368/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2945 - val_loss: 4.8409\n",
      "Epoch 369/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2712 - val_loss: 4.8153\n",
      "Epoch 370/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2511 - val_loss: 4.8280\n",
      "Epoch 371/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2465 - val_loss: 4.8222\n",
      "Epoch 372/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2477 - val_loss: 4.7978\n",
      "Epoch 373/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2389 - val_loss: 4.8172\n",
      "Epoch 374/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2334 - val_loss: 4.7878\n",
      "Epoch 375/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2572 - val_loss: 4.8078\n",
      "Epoch 376/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2923 - val_loss: 4.7876\n",
      "Epoch 377/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2746 - val_loss: 4.7877\n",
      "Epoch 378/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2456 - val_loss: 4.8320\n",
      "Epoch 379/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2748 - val_loss: 4.7983\n",
      "Epoch 380/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2453 - val_loss: 4.7901\n",
      "Epoch 381/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2337 - val_loss: 4.8126\n",
      "Epoch 382/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2358 - val_loss: 4.7267\n",
      "Epoch 383/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2376 - val_loss: 4.7809\n",
      "Epoch 384/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3114 - val_loss: 4.7777\n",
      "Epoch 385/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2807 - val_loss: 4.8060\n",
      "Epoch 386/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2858 - val_loss: 4.7485\n",
      "Epoch 387/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2488 - val_loss: 4.7789\n",
      "Epoch 388/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2288 - val_loss: 4.7598\n",
      "Epoch 389/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2288 - val_loss: 4.7409\n",
      "Epoch 390/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2230 - val_loss: 4.7683\n",
      "Epoch 391/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2324 - val_loss: 4.7290\n",
      "Epoch 392/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2132 - val_loss: 4.7496\n",
      "Epoch 393/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2235 - val_loss: 4.7633\n",
      "Epoch 394/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2362 - val_loss: 4.7333\n",
      "Epoch 395/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2206 - val_loss: 4.7608\n",
      "Epoch 396/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2171 - val_loss: 4.7172\n",
      "Epoch 397/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2234 - val_loss: 4.7380\n",
      "Epoch 398/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2206 - val_loss: 4.7604\n",
      "Epoch 399/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2471 - val_loss: 4.7495\n",
      "Epoch 400/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2257 - val_loss: 4.7265\n",
      "Epoch 401/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2252 - val_loss: 4.7272\n",
      "Epoch 402/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2325 - val_loss: 4.7690\n",
      "Epoch 403/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2233 - val_loss: 4.7119\n",
      "Epoch 404/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2615 - val_loss: 4.8007\n",
      "Epoch 405/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2549 - val_loss: 4.7312\n",
      "Epoch 406/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2415 - val_loss: 4.7077\n",
      "Epoch 407/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2027 - val_loss: 4.7353\n",
      "Epoch 408/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1931 - val_loss: 4.6814\n",
      "Epoch 409/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1816 - val_loss: 4.6508\n",
      "Epoch 410/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1995 - val_loss: 4.7279\n",
      "Epoch 411/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1961 - val_loss: 4.6540\n",
      "Epoch 412/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2523 - val_loss: 4.6657\n",
      "Epoch 413/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2189 - val_loss: 4.6528\n",
      "Epoch 414/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2127 - val_loss: 4.6544\n",
      "Epoch 415/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2062 - val_loss: 4.6854\n",
      "Epoch 416/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2230 - val_loss: 4.7086\n",
      "Epoch 417/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2628 - val_loss: 4.7025\n",
      "Epoch 418/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2062 - val_loss: 4.7112\n",
      "Epoch 419/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1927 - val_loss: 4.6744\n",
      "Epoch 420/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2178 - val_loss: 4.7049\n",
      "Epoch 421/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2032 - val_loss: 4.7335\n",
      "Epoch 422/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1918 - val_loss: 4.7287\n",
      "Epoch 423/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1796 - val_loss: 4.6859\n",
      "Epoch 424/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1775 - val_loss: 4.6736\n",
      "Epoch 425/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1955 - val_loss: 4.6689\n",
      "Epoch 426/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1961 - val_loss: 4.6502\n",
      "Epoch 427/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1680 - val_loss: 4.6687\n",
      "Epoch 428/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1959 - val_loss: 4.6449\n",
      "Epoch 429/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1702 - val_loss: 4.6641\n",
      "Epoch 430/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1654 - val_loss: 4.6528\n",
      "Epoch 431/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1906 - val_loss: 4.6803\n",
      "Epoch 432/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1673 - val_loss: 4.6450\n",
      "Epoch 433/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1502 - val_loss: 4.6937\n",
      "Epoch 434/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1587 - val_loss: 4.6528\n",
      "Epoch 435/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1392 - val_loss: 4.6754\n",
      "Epoch 436/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1309 - val_loss: 4.6417\n",
      "Epoch 437/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1434 - val_loss: 4.6668\n",
      "Epoch 438/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1381 - val_loss: 4.6432\n",
      "Epoch 439/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1425 - val_loss: 4.6699\n",
      "Epoch 440/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1493 - val_loss: 4.6855\n",
      "Epoch 441/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1547 - val_loss: 4.6803\n",
      "Epoch 442/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1303 - val_loss: 4.6604\n",
      "Epoch 443/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1453 - val_loss: 4.6485\n",
      "Epoch 444/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1747 - val_loss: 4.6328\n",
      "Epoch 445/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1625 - val_loss: 4.6430\n",
      "Epoch 446/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1768 - val_loss: 4.6163\n",
      "Epoch 447/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1428 - val_loss: 4.6206\n",
      "Epoch 448/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1311 - val_loss: 4.6438\n",
      "Epoch 449/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1340 - val_loss: 4.6245\n",
      "Epoch 450/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1420 - val_loss: 4.6407\n",
      "Epoch 451/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1324 - val_loss: 4.6328\n",
      "Epoch 452/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1223 - val_loss: 4.5781\n",
      "Epoch 453/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1343 - val_loss: 4.6373\n",
      "Epoch 454/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1126 - val_loss: 4.6143\n",
      "Epoch 455/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1039 - val_loss: 4.6102\n",
      "Epoch 456/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1082 - val_loss: 4.5879\n",
      "Epoch 457/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1048 - val_loss: 4.6064\n",
      "Epoch 458/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1182 - val_loss: 4.6521\n",
      "Epoch 459/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1050 - val_loss: 4.5640\n",
      "Epoch 460/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1246 - val_loss: 4.6728\n",
      "Epoch 461/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1241 - val_loss: 4.6260\n",
      "Epoch 462/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1044 - val_loss: 4.6295\n",
      "Epoch 463/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0960 - val_loss: 4.6096\n",
      "Epoch 464/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0996 - val_loss: 4.6204\n",
      "Epoch 465/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1112 - val_loss: 4.6678\n",
      "Epoch 466/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0952 - val_loss: 4.5558\n",
      "Epoch 467/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1339 - val_loss: 4.5771\n",
      "Epoch 468/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1511 - val_loss: 4.6624\n",
      "Epoch 469/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1222 - val_loss: 4.5724\n",
      "Epoch 470/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1473 - val_loss: 4.5889\n",
      "Epoch 471/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0968 - val_loss: 4.5529\n",
      "Epoch 472/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0960 - val_loss: 4.5815\n",
      "Epoch 473/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0951 - val_loss: 4.5563\n",
      "Epoch 474/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.0902 - val_loss: 4.5357\n",
      "Epoch 475/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1004 - val_loss: 4.5678\n",
      "Epoch 476/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0919 - val_loss: 4.5613\n",
      "Epoch 477/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0829 - val_loss: 4.5889\n",
      "Epoch 478/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0873 - val_loss: 4.5775\n",
      "Epoch 479/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0779 - val_loss: 4.5886\n",
      "Epoch 480/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0869 - val_loss: 4.5491\n",
      "Epoch 481/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0785 - val_loss: 4.5631\n",
      "Epoch 482/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0771 - val_loss: 4.6082\n",
      "Epoch 483/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0861 - val_loss: 4.5531\n",
      "Epoch 484/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0791 - val_loss: 4.5656\n",
      "Epoch 485/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0712 - val_loss: 4.5557\n",
      "Epoch 486/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0791 - val_loss: 4.6144\n",
      "Epoch 487/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1012 - val_loss: 4.5320\n",
      "Epoch 488/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0628 - val_loss: 4.5229\n",
      "Epoch 489/1500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.0893 - val_loss: 4.5556\n",
      "Epoch 490/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0615 - val_loss: 4.5302\n",
      "Epoch 491/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0539 - val_loss: 4.5681\n",
      "Epoch 492/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0682 - val_loss: 4.5548\n",
      "Epoch 493/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0536 - val_loss: 4.5587\n",
      "Epoch 494/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0733 - val_loss: 4.5192\n",
      "Epoch 495/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0690 - val_loss: 4.5360\n",
      "Epoch 496/1500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0808 - val_loss: 4.5203\n",
      "Epoch 497/1500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.0866 - val_loss: 4.5069\n",
      "Epoch 498/1500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.0801 - val_loss: 4.5332\n",
      "Epoch 499/1500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.0593 - val_loss: 4.5451\n",
      "Epoch 500/1500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.0863 - val_loss: 4.5105\n",
      "Epoch 501/1500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.0709 - val_loss: 4.5540\n",
      "Epoch 502/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0914 - val_loss: 4.5237\n",
      "Epoch 503/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0572 - val_loss: 4.5435\n",
      "Epoch 504/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0741 - val_loss: 4.5611\n",
      "Epoch 505/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0475 - val_loss: 4.4853\n",
      "Epoch 506/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0530 - val_loss: 4.4626\n",
      "Epoch 507/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0405 - val_loss: 4.5784\n",
      "Epoch 508/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0740 - val_loss: 4.5361\n",
      "Epoch 509/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0665 - val_loss: 4.5006\n",
      "Epoch 510/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0425 - val_loss: 4.5180\n",
      "Epoch 511/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0870 - val_loss: 4.5830\n",
      "Epoch 512/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0480 - val_loss: 4.5386\n",
      "Epoch 513/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0498 - val_loss: 4.5275\n",
      "Epoch 514/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0417 - val_loss: 4.4658\n",
      "Epoch 515/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0435 - val_loss: 4.4960\n",
      "Epoch 516/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0778 - val_loss: 4.4660\n",
      "Epoch 517/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0979 - val_loss: 4.5669\n",
      "Epoch 518/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0744 - val_loss: 4.4636\n",
      "Epoch 519/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1272 - val_loss: 4.5297\n",
      "Epoch 520/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1202 - val_loss: 4.5396\n",
      "Epoch 521/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1349 - val_loss: 4.5215\n",
      "Epoch 522/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0353 - val_loss: 4.4540\n",
      "Epoch 523/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1041 - val_loss: 4.4911\n",
      "Epoch 524/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0250 - val_loss: 4.4019\n",
      "Epoch 525/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0215 - val_loss: 4.4394\n",
      "Epoch 526/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0147 - val_loss: 4.4652\n",
      "Epoch 527/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0049 - val_loss: 4.4437\n",
      "Epoch 528/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0197 - val_loss: 4.4672\n",
      "Epoch 529/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0579 - val_loss: 4.4635\n",
      "Epoch 530/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0472 - val_loss: 4.5169\n",
      "Epoch 531/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0269 - val_loss: 4.4358\n",
      "Epoch 532/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0426 - val_loss: 4.4239\n",
      "Epoch 533/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0228 - val_loss: 4.4667\n",
      "Epoch 534/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0341 - val_loss: 4.4445\n",
      "Epoch 535/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0498 - val_loss: 4.4756\n",
      "Epoch 536/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0408 - val_loss: 4.4640\n",
      "Epoch 537/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0250 - val_loss: 4.4466\n",
      "Epoch 538/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0298 - val_loss: 4.4633\n",
      "Epoch 539/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0233 - val_loss: 4.4483\n",
      "Epoch 540/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0038 - val_loss: 4.4221\n",
      "Epoch 541/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9949 - val_loss: 4.4567\n",
      "Epoch 542/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9963 - val_loss: 4.4407\n",
      "Epoch 543/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9947 - val_loss: 4.4415\n",
      "Epoch 544/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9921 - val_loss: 4.4872\n",
      "Epoch 545/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0090 - val_loss: 4.4381\n",
      "Epoch 546/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9792 - val_loss: 4.4812\n",
      "Epoch 547/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9942 - val_loss: 4.4430\n",
      "Epoch 548/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0043 - val_loss: 4.4859\n",
      "Epoch 549/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9943 - val_loss: 4.4425\n",
      "Epoch 550/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9885 - val_loss: 4.4244\n",
      "Epoch 551/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9795 - val_loss: 4.4281\n",
      "Epoch 552/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0101 - val_loss: 4.5058\n",
      "Epoch 553/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0034 - val_loss: 4.4510\n",
      "Epoch 554/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0441 - val_loss: 4.4430\n",
      "Epoch 555/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0087 - val_loss: 4.5274\n",
      "Epoch 556/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0248 - val_loss: 4.4656\n",
      "Epoch 557/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9888 - val_loss: 4.4352\n",
      "Epoch 558/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9763 - val_loss: 4.4641\n",
      "Epoch 559/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9922 - val_loss: 4.4491\n",
      "Epoch 560/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9781 - val_loss: 4.4337\n",
      "Epoch 561/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9854 - val_loss: 4.4674\n",
      "Epoch 562/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0007 - val_loss: 4.4080\n",
      "Epoch 563/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9952 - val_loss: 4.4202\n",
      "Epoch 564/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9891 - val_loss: 4.4251\n",
      "Epoch 565/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9721 - val_loss: 4.4159\n",
      "Epoch 566/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9745 - val_loss: 4.4356\n",
      "Epoch 567/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9703 - val_loss: 4.4257\n",
      "Epoch 568/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9828 - val_loss: 4.3901\n",
      "Epoch 569/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9720 - val_loss: 4.4882\n",
      "Epoch 570/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9648 - val_loss: 4.4508\n",
      "Epoch 571/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9705 - val_loss: 4.4109\n",
      "Epoch 572/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9830 - val_loss: 4.4338\n",
      "Epoch 573/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9879 - val_loss: 4.4089\n",
      "Epoch 574/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9647 - val_loss: 4.4344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9802 - val_loss: 4.4505\n",
      "Epoch 576/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9782 - val_loss: 4.4058\n",
      "Epoch 577/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9655 - val_loss: 4.4414\n",
      "Epoch 578/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9665 - val_loss: 4.3979\n",
      "Epoch 579/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9741 - val_loss: 4.4458\n",
      "Epoch 580/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9782 - val_loss: 4.4010\n",
      "Epoch 581/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0345 - val_loss: 4.4665\n",
      "Epoch 582/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9887 - val_loss: 4.3805\n",
      "Epoch 583/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9782 - val_loss: 4.4193\n",
      "Epoch 584/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9692 - val_loss: 4.4621\n",
      "Epoch 585/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9482 - val_loss: 4.3959\n",
      "Epoch 586/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9843 - val_loss: 4.3796\n",
      "Epoch 587/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9525 - val_loss: 4.4415\n",
      "Epoch 588/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9661 - val_loss: 4.4502\n",
      "Epoch 589/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9635 - val_loss: 4.3802\n",
      "Epoch 590/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9883 - val_loss: 4.4850\n",
      "Epoch 591/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0057 - val_loss: 4.3761\n",
      "Epoch 592/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9775 - val_loss: 4.3853\n",
      "Epoch 593/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9789 - val_loss: 4.4086\n",
      "Epoch 594/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9736 - val_loss: 4.3433\n",
      "Epoch 595/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9836 - val_loss: 4.3818\n",
      "Epoch 596/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9885 - val_loss: 4.4905\n",
      "Epoch 597/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9717 - val_loss: 4.3670\n",
      "Epoch 598/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9817 - val_loss: 4.3947\n",
      "Epoch 599/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9656 - val_loss: 4.3782\n",
      "Epoch 600/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9473 - val_loss: 4.3769\n",
      "Epoch 601/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9476 - val_loss: 4.3505\n",
      "Epoch 602/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9335 - val_loss: 4.3596\n",
      "Epoch 603/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9436 - val_loss: 4.3255\n",
      "Epoch 604/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9404 - val_loss: 4.3513\n",
      "Epoch 605/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9726 - val_loss: 4.3739\n",
      "Epoch 606/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9665 - val_loss: 4.3534\n",
      "Epoch 607/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9802 - val_loss: 4.3611\n",
      "Epoch 608/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9262 - val_loss: 4.3284\n",
      "Epoch 609/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9396 - val_loss: 4.3225\n",
      "Epoch 610/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9482 - val_loss: 4.3474\n",
      "Epoch 611/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9454 - val_loss: 4.3840\n",
      "Epoch 612/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9443 - val_loss: 4.3267\n",
      "Epoch 613/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9440 - val_loss: 4.4264\n",
      "Epoch 614/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9656 - val_loss: 4.3200\n",
      "Epoch 615/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9348 - val_loss: 4.3697\n",
      "Epoch 616/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9503 - val_loss: 4.3929\n",
      "Epoch 617/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9423 - val_loss: 4.3149\n",
      "Epoch 618/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9539 - val_loss: 4.3368\n",
      "Epoch 619/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9170 - val_loss: 4.3894\n",
      "Epoch 620/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9345 - val_loss: 4.3480\n",
      "Epoch 621/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9201 - val_loss: 4.3341\n",
      "Epoch 622/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9598 - val_loss: 4.3451\n",
      "Epoch 623/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9383 - val_loss: 4.3640\n",
      "Epoch 624/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9191 - val_loss: 4.3529\n",
      "Epoch 625/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9161 - val_loss: 4.3600\n",
      "Epoch 626/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9277 - val_loss: 4.4112\n",
      "Epoch 627/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9641 - val_loss: 4.3340\n",
      "Epoch 628/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9295 - val_loss: 4.3577\n",
      "Epoch 629/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9379 - val_loss: 4.3458\n",
      "Epoch 630/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9315 - val_loss: 4.3541\n",
      "Epoch 631/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9309 - val_loss: 4.3398\n",
      "Epoch 632/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9163 - val_loss: 4.3099\n",
      "Epoch 633/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9078 - val_loss: 4.3381\n",
      "Epoch 634/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9132 - val_loss: 4.3625\n",
      "Epoch 635/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9171 - val_loss: 4.3486\n",
      "Epoch 636/1500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9020 - val_loss: 4.3015\n",
      "Epoch 637/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9163 - val_loss: 4.2950\n",
      "Epoch 638/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9524 - val_loss: 4.3693\n",
      "Epoch 639/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9260 - val_loss: 4.3561\n",
      "Epoch 640/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9028 - val_loss: 4.3045\n",
      "Epoch 641/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8985 - val_loss: 4.3427\n",
      "Epoch 642/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8794 - val_loss: 4.3241\n",
      "Epoch 643/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9223 - val_loss: 4.3438\n",
      "Epoch 644/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9030 - val_loss: 4.3642\n",
      "Epoch 645/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9400 - val_loss: 4.3053\n",
      "Epoch 646/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9456 - val_loss: 4.3502\n",
      "Epoch 647/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8872 - val_loss: 4.2948\n",
      "Epoch 648/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8957 - val_loss: 4.3002\n",
      "Epoch 649/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9144 - val_loss: 4.3310\n",
      "Epoch 650/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8924 - val_loss: 4.3695\n",
      "Epoch 651/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8970 - val_loss: 4.3044\n",
      "Epoch 652/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9224 - val_loss: 4.3495\n",
      "Epoch 653/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9009 - val_loss: 4.3146\n",
      "Epoch 654/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8837 - val_loss: 4.3449\n",
      "Epoch 655/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9116 - val_loss: 4.3658\n",
      "Epoch 656/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9327 - val_loss: 4.3006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8892 - val_loss: 4.3924\n",
      "Epoch 658/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8864 - val_loss: 4.3130\n",
      "Epoch 659/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8656 - val_loss: 4.2997\n",
      "Epoch 660/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8765 - val_loss: 4.3307\n",
      "Epoch 661/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8917 - val_loss: 4.2778\n",
      "Epoch 662/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8885 - val_loss: 4.2657\n",
      "Epoch 663/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8876 - val_loss: 4.3937\n",
      "Epoch 664/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9114 - val_loss: 4.3040\n",
      "Epoch 665/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9014 - val_loss: 4.3298\n",
      "Epoch 666/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8818 - val_loss: 4.2587\n",
      "Epoch 667/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8640 - val_loss: 4.2851\n",
      "Epoch 668/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8638 - val_loss: 4.2993\n",
      "Epoch 669/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9020 - val_loss: 4.3514\n",
      "Epoch 670/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8944 - val_loss: 4.2598\n",
      "Epoch 671/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8965 - val_loss: 4.3377\n",
      "Epoch 672/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8615 - val_loss: 4.2695\n",
      "Epoch 673/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8724 - val_loss: 4.2415\n",
      "Epoch 674/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8655 - val_loss: 4.2649\n",
      "Epoch 675/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8589 - val_loss: 4.3068\n",
      "Epoch 676/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8568 - val_loss: 4.2524\n",
      "Epoch 677/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8415 - val_loss: 4.2836\n",
      "Epoch 678/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8432 - val_loss: 4.3056\n",
      "Epoch 679/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8826 - val_loss: 4.2672\n",
      "Epoch 680/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8611 - val_loss: 4.2789\n",
      "Epoch 681/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8537 - val_loss: 4.2840\n",
      "Epoch 682/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8766 - val_loss: 4.2557\n",
      "Epoch 683/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8579 - val_loss: 4.2711\n",
      "Epoch 684/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8517 - val_loss: 4.3157\n",
      "Epoch 685/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8642 - val_loss: 4.2649\n",
      "Epoch 686/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8546 - val_loss: 4.2861\n",
      "Epoch 687/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8857 - val_loss: 4.2361\n",
      "Epoch 688/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8715 - val_loss: 4.3318\n",
      "Epoch 689/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8554 - val_loss: 4.2851\n",
      "Epoch 690/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8478 - val_loss: 4.2503\n",
      "Epoch 691/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8429 - val_loss: 4.2531\n",
      "Epoch 692/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8505 - val_loss: 4.2558\n",
      "Epoch 693/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8336 - val_loss: 4.2497\n",
      "Epoch 694/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8271 - val_loss: 4.2643\n",
      "Epoch 695/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8368 - val_loss: 4.1984\n",
      "Epoch 696/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9043 - val_loss: 4.2813\n",
      "Epoch 697/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8402 - val_loss: 4.2818\n",
      "Epoch 698/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9011 - val_loss: 4.2552\n",
      "Epoch 699/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8715 - val_loss: 4.2904\n",
      "Epoch 700/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8684 - val_loss: 4.2907\n",
      "Epoch 701/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8508 - val_loss: 4.2313\n",
      "Epoch 702/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8467 - val_loss: 4.2219\n",
      "Epoch 703/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8316 - val_loss: 4.2302\n",
      "Epoch 704/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8282 - val_loss: 4.2479\n",
      "Epoch 705/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8508 - val_loss: 4.2942\n",
      "Epoch 706/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8352 - val_loss: 4.2612\n",
      "Epoch 707/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8247 - val_loss: 4.2325\n",
      "Epoch 708/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8326 - val_loss: 4.2392\n",
      "Epoch 709/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8203 - val_loss: 4.2667\n",
      "Epoch 710/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8404 - val_loss: 4.2509\n",
      "Epoch 711/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8434 - val_loss: 4.2059\n",
      "Epoch 712/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8430 - val_loss: 4.2592\n",
      "Epoch 713/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8436 - val_loss: 4.2488\n",
      "Epoch 714/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 4.2240\n",
      "Epoch 715/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8186 - val_loss: 4.2147\n",
      "Epoch 716/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8429 - val_loss: 4.2271\n",
      "Epoch 717/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8663 - val_loss: 4.1940\n",
      "Epoch 718/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8357 - val_loss: 4.1937\n",
      "Epoch 719/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8990 - val_loss: 4.2873\n",
      "Epoch 720/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8421 - val_loss: 4.2593\n",
      "Epoch 721/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8552 - val_loss: 4.2331\n",
      "Epoch 722/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8566 - val_loss: 4.2240\n",
      "Epoch 723/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8471 - val_loss: 4.2287\n",
      "Epoch 724/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8320 - val_loss: 4.1851\n",
      "Epoch 725/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8074 - val_loss: 4.2086\n",
      "Epoch 726/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8334 - val_loss: 4.2541\n",
      "Epoch 727/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8354 - val_loss: 4.2272\n",
      "Epoch 728/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8030 - val_loss: 4.2296\n",
      "Epoch 729/1500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8065 - val_loss: 4.2355\n",
      "Epoch 730/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8106 - val_loss: 4.2518\n",
      "Epoch 731/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7883 - val_loss: 4.1884\n",
      "Epoch 732/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8028 - val_loss: 4.2333\n",
      "Epoch 733/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7951 - val_loss: 4.1481\n",
      "Epoch 734/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8039 - val_loss: 4.2543\n",
      "Epoch 735/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8061 - val_loss: 4.1388\n",
      "Epoch 736/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8262 - val_loss: 4.1042\n",
      "Epoch 737/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8345 - val_loss: 4.2133\n",
      "Epoch 738/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8269 - val_loss: 4.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8340 - val_loss: 4.1871\n",
      "Epoch 740/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7963 - val_loss: 4.1606\n",
      "Epoch 741/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8069 - val_loss: 4.1930\n",
      "Epoch 742/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7990 - val_loss: 4.1766\n",
      "Epoch 743/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8021 - val_loss: 4.2068\n",
      "Epoch 744/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7984 - val_loss: 4.2096\n",
      "Epoch 745/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8206 - val_loss: 4.1910\n",
      "Epoch 746/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7889 - val_loss: 4.2047\n",
      "Epoch 747/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7972 - val_loss: 4.1590\n",
      "Epoch 748/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7836 - val_loss: 4.1594\n",
      "Epoch 749/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8273 - val_loss: 4.1782\n",
      "Epoch 750/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8050 - val_loss: 4.1164\n",
      "Epoch 751/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7733 - val_loss: 4.1880\n",
      "Epoch 752/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7749 - val_loss: 4.1479\n",
      "Epoch 753/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7741 - val_loss: 4.1798\n",
      "Epoch 754/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7625 - val_loss: 4.1676\n",
      "Epoch 755/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7667 - val_loss: 4.1586\n",
      "Epoch 756/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7791 - val_loss: 4.2018\n",
      "Epoch 757/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7959 - val_loss: 4.1834\n",
      "Epoch 758/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8037 - val_loss: 4.1556\n",
      "Epoch 759/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7675 - val_loss: 4.1610\n",
      "Epoch 760/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7745 - val_loss: 4.1598\n",
      "Epoch 761/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7866 - val_loss: 4.1709\n",
      "Epoch 762/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8116 - val_loss: 4.2329\n",
      "Epoch 763/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7955 - val_loss: 4.1410\n",
      "Epoch 764/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8133 - val_loss: 4.1253\n",
      "Epoch 765/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8220 - val_loss: 4.1926\n",
      "Epoch 766/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8071 - val_loss: 4.1666\n",
      "Epoch 767/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8050 - val_loss: 4.1928\n",
      "Epoch 768/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7517 - val_loss: 4.1650\n",
      "Epoch 769/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7796 - val_loss: 4.1891\n",
      "Epoch 770/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8092 - val_loss: 4.2310\n",
      "Epoch 771/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8010 - val_loss: 4.1811\n",
      "Epoch 772/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7524 - val_loss: 4.1571\n",
      "Epoch 773/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7498 - val_loss: 4.1851\n",
      "Epoch 774/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7592 - val_loss: 4.1397\n",
      "Epoch 775/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7454 - val_loss: 4.1078\n",
      "Epoch 776/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7523 - val_loss: 4.1528\n",
      "Epoch 777/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7668 - val_loss: 4.1373\n",
      "Epoch 778/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7628 - val_loss: 4.2272\n",
      "Epoch 779/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7441 - val_loss: 4.1559\n",
      "Epoch 780/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7344 - val_loss: 4.1208\n",
      "Epoch 781/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7410 - val_loss: 4.1445\n",
      "Epoch 782/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7390 - val_loss: 4.1961\n",
      "Epoch 783/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7408 - val_loss: 4.1374\n",
      "Epoch 784/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7468 - val_loss: 4.1203\n",
      "Epoch 785/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7403 - val_loss: 4.1353\n",
      "Epoch 786/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7233 - val_loss: 4.1419\n",
      "Epoch 787/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7325 - val_loss: 4.1106\n",
      "Epoch 788/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7795 - val_loss: 4.1081\n",
      "Epoch 789/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7226 - val_loss: 4.1049\n",
      "Epoch 790/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7421 - val_loss: 4.1172\n",
      "Epoch 791/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7323 - val_loss: 4.1577\n",
      "Epoch 792/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7262 - val_loss: 4.1238\n",
      "Epoch 793/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7317 - val_loss: 4.1685\n",
      "Epoch 794/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7376 - val_loss: 4.1178\n",
      "Epoch 795/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7486 - val_loss: 4.1163\n",
      "Epoch 796/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7477 - val_loss: 4.0688\n",
      "Epoch 797/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7140 - val_loss: 4.1062\n",
      "Epoch 798/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7227 - val_loss: 4.1629\n",
      "Epoch 799/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7557 - val_loss: 4.0724\n",
      "Epoch 800/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7917 - val_loss: 4.0970\n",
      "Epoch 801/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7573 - val_loss: 4.1460\n",
      "Epoch 802/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7651 - val_loss: 4.1245\n",
      "Epoch 803/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7203 - val_loss: 4.1614\n",
      "Epoch 804/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7854 - val_loss: 4.0738\n",
      "Epoch 805/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7471 - val_loss: 4.1312\n",
      "Epoch 806/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7165 - val_loss: 4.1090\n",
      "Epoch 807/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7302 - val_loss: 4.1161\n",
      "Epoch 808/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7388 - val_loss: 4.0912\n",
      "Epoch 809/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7355 - val_loss: 4.0779\n",
      "Epoch 810/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7060 - val_loss: 4.1253\n",
      "Epoch 811/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7316 - val_loss: 4.1705\n",
      "Epoch 812/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7359 - val_loss: 4.0662\n",
      "Epoch 813/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7314 - val_loss: 4.1380\n",
      "Epoch 814/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7511 - val_loss: 4.0609\n",
      "Epoch 815/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7823 - val_loss: 4.1405\n",
      "Epoch 816/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7430 - val_loss: 4.1300\n",
      "Epoch 817/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7398 - val_loss: 4.0827\n",
      "Epoch 818/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7418 - val_loss: 4.1368\n",
      "Epoch 819/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7060 - val_loss: 4.0627\n",
      "Epoch 820/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7048 - val_loss: 4.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6944 - val_loss: 4.1130\n",
      "Epoch 822/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6890 - val_loss: 4.0683\n",
      "Epoch 823/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6918 - val_loss: 4.0728\n",
      "Epoch 824/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6811 - val_loss: 4.1116\n",
      "Epoch 825/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6970 - val_loss: 4.0669\n",
      "Epoch 826/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6878 - val_loss: 4.0909\n",
      "Epoch 827/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7246 - val_loss: 4.0550\n",
      "Epoch 828/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7536 - val_loss: 4.1680\n",
      "Epoch 829/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7466 - val_loss: 4.0592\n",
      "Epoch 830/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7224 - val_loss: 4.1556\n",
      "Epoch 831/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7126 - val_loss: 4.0234\n",
      "Epoch 832/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7134 - val_loss: 4.0118\n",
      "Epoch 833/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6731 - val_loss: 4.1411\n",
      "Epoch 834/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7224 - val_loss: 4.0790\n",
      "Epoch 835/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7198 - val_loss: 4.0274\n",
      "Epoch 836/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7074 - val_loss: 4.0461\n",
      "Epoch 837/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7240 - val_loss: 4.1038\n",
      "Epoch 838/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6729 - val_loss: 4.0705\n",
      "Epoch 839/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6774 - val_loss: 4.0391\n",
      "Epoch 840/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6682 - val_loss: 4.0943\n",
      "Epoch 841/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6966 - val_loss: 4.0362\n",
      "Epoch 842/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6969 - val_loss: 4.0739\n",
      "Epoch 843/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6899 - val_loss: 4.0308\n",
      "Epoch 844/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7277 - val_loss: 4.0600\n",
      "Epoch 845/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7357 - val_loss: 4.0217\n",
      "Epoch 846/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7038 - val_loss: 4.0898\n",
      "Epoch 847/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6942 - val_loss: 4.0405\n",
      "Epoch 848/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6626 - val_loss: 4.0667\n",
      "Epoch 849/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6683 - val_loss: 4.0476\n",
      "Epoch 850/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6644 - val_loss: 4.0206\n",
      "Epoch 851/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6409 - val_loss: 4.0472\n",
      "Epoch 852/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6357 - val_loss: 4.0169\n",
      "Epoch 853/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6718 - val_loss: 4.0810\n",
      "Epoch 854/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6655 - val_loss: 4.0094\n",
      "Epoch 855/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6726 - val_loss: 4.0281\n",
      "Epoch 856/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6561 - val_loss: 4.0534\n",
      "Epoch 857/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6561 - val_loss: 4.0226\n",
      "Epoch 858/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6817 - val_loss: 4.0241\n",
      "Epoch 859/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6740 - val_loss: 3.9978\n",
      "Epoch 860/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6601 - val_loss: 4.0243\n",
      "Epoch 861/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6564 - val_loss: 4.0132\n",
      "Epoch 862/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6648 - val_loss: 4.0442\n",
      "Epoch 863/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6604 - val_loss: 3.9960\n",
      "Epoch 864/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6688 - val_loss: 4.0404\n",
      "Epoch 865/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6419 - val_loss: 4.0480\n",
      "Epoch 866/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6500 - val_loss: 3.9983\n",
      "Epoch 867/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6343 - val_loss: 3.9895\n",
      "Epoch 868/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6338 - val_loss: 4.0183\n",
      "Epoch 869/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6637 - val_loss: 4.0563\n",
      "Epoch 870/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6276 - val_loss: 3.9753\n",
      "Epoch 871/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6357 - val_loss: 4.0009\n",
      "Epoch 872/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6214 - val_loss: 4.0213\n",
      "Epoch 873/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6308 - val_loss: 3.9810\n",
      "Epoch 874/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6132 - val_loss: 3.9780\n",
      "Epoch 875/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6532 - val_loss: 4.0355\n",
      "Epoch 876/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6478 - val_loss: 3.9909\n",
      "Epoch 877/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6298 - val_loss: 3.9824\n",
      "Epoch 878/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6143 - val_loss: 4.0052\n",
      "Epoch 879/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6280 - val_loss: 3.9428\n",
      "Epoch 880/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6499 - val_loss: 3.9686\n",
      "Epoch 881/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7454 - val_loss: 4.0279\n",
      "Epoch 882/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7285 - val_loss: 4.0116\n",
      "Epoch 883/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6825 - val_loss: 4.0461\n",
      "Epoch 884/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6553 - val_loss: 3.9958\n",
      "Epoch 885/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6276 - val_loss: 4.0229\n",
      "Epoch 886/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6873 - val_loss: 3.9528\n",
      "Epoch 887/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7028 - val_loss: 4.0537\n",
      "Epoch 888/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6860 - val_loss: 3.9490\n",
      "Epoch 889/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6083 - val_loss: 3.9638\n",
      "Epoch 890/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6180 - val_loss: 3.9131\n",
      "Epoch 891/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6186 - val_loss: 3.9507\n",
      "Epoch 892/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5937 - val_loss: 3.9407\n",
      "Epoch 893/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6381 - val_loss: 3.9902\n",
      "Epoch 894/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6705 - val_loss: 4.0003\n",
      "Epoch 895/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6272 - val_loss: 3.9632\n",
      "Epoch 896/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6379 - val_loss: 4.0613\n",
      "Epoch 897/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6426 - val_loss: 3.9425\n",
      "Epoch 898/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6511 - val_loss: 3.9888\n",
      "Epoch 899/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6402 - val_loss: 3.9246\n",
      "Epoch 900/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6223 - val_loss: 3.9801\n",
      "Epoch 901/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5928 - val_loss: 3.9760\n",
      "Epoch 902/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6141 - val_loss: 3.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 903/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6148 - val_loss: 3.9231\n",
      "Epoch 904/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6057 - val_loss: 3.9665\n",
      "Epoch 905/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6183 - val_loss: 3.8981\n",
      "Epoch 906/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6249 - val_loss: 3.9868\n",
      "Epoch 907/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6088 - val_loss: 3.9412\n",
      "Epoch 908/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5900 - val_loss: 3.9390\n",
      "Epoch 909/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6078 - val_loss: 3.9330\n",
      "Epoch 910/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6476 - val_loss: 3.8957\n",
      "Epoch 911/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6256 - val_loss: 3.9712\n",
      "Epoch 912/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6184 - val_loss: 3.9295\n",
      "Epoch 913/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6190 - val_loss: 4.0396\n",
      "Epoch 914/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6122 - val_loss: 3.9458\n",
      "Epoch 915/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6391 - val_loss: 3.9307\n",
      "Epoch 916/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6116 - val_loss: 3.9880\n",
      "Epoch 917/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6090 - val_loss: 3.8846\n",
      "Epoch 918/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6009 - val_loss: 3.9296\n",
      "Epoch 919/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6188 - val_loss: 3.8828\n",
      "Epoch 920/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6002 - val_loss: 3.8997\n",
      "Epoch 921/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5679 - val_loss: 3.9779\n",
      "Epoch 922/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5754 - val_loss: 3.8915\n",
      "Epoch 923/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5751 - val_loss: 3.8524\n",
      "Epoch 924/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5882 - val_loss: 4.0124\n",
      "Epoch 925/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6161 - val_loss: 3.8873\n",
      "Epoch 926/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5826 - val_loss: 3.9503\n",
      "Epoch 927/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5540 - val_loss: 3.8783\n",
      "Epoch 928/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5517 - val_loss: 3.8820\n",
      "Epoch 929/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5697 - val_loss: 3.8978\n",
      "Epoch 930/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5656 - val_loss: 3.8651\n",
      "Epoch 931/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5764 - val_loss: 3.8628\n",
      "Epoch 932/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5951 - val_loss: 3.8504\n",
      "Epoch 933/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5486 - val_loss: 3.9160\n",
      "Epoch 934/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6006 - val_loss: 3.8768\n",
      "Epoch 935/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6427 - val_loss: 3.9173\n",
      "Epoch 936/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5752 - val_loss: 3.8195\n",
      "Epoch 937/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6111 - val_loss: 3.9477\n",
      "Epoch 938/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6177 - val_loss: 3.8374\n",
      "Epoch 939/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6374 - val_loss: 3.9136\n",
      "Epoch 940/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5913 - val_loss: 3.9033\n",
      "Epoch 941/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5955 - val_loss: 3.8421\n",
      "Epoch 942/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5867 - val_loss: 3.9146\n",
      "Epoch 943/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5833 - val_loss: 3.8719\n",
      "Epoch 944/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5543 - val_loss: 3.9252\n",
      "Epoch 945/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5741 - val_loss: 3.8287\n",
      "Epoch 946/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5381 - val_loss: 3.8562\n",
      "Epoch 947/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5712 - val_loss: 3.9021\n",
      "Epoch 948/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5293 - val_loss: 3.8293\n",
      "Epoch 949/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5406 - val_loss: 3.8385\n",
      "Epoch 950/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5366 - val_loss: 3.8767\n",
      "Epoch 951/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5334 - val_loss: 3.8135\n",
      "Epoch 952/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5663 - val_loss: 3.9433\n",
      "Epoch 953/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5872 - val_loss: 3.8314\n",
      "Epoch 954/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5872 - val_loss: 3.9050\n",
      "Epoch 955/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5661 - val_loss: 3.8123\n",
      "Epoch 956/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5446 - val_loss: 3.8462\n",
      "Epoch 957/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5708 - val_loss: 3.8628\n",
      "Epoch 958/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6112 - val_loss: 3.8121\n",
      "Epoch 959/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5872 - val_loss: 3.9243\n",
      "Epoch 960/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6608 - val_loss: 3.8551\n",
      "Epoch 961/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5374 - val_loss: 3.9041\n",
      "Epoch 962/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5679 - val_loss: 3.7757\n",
      "Epoch 963/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6116 - val_loss: 3.9182\n",
      "Epoch 964/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5839 - val_loss: 3.8339\n",
      "Epoch 965/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5472 - val_loss: 3.8035\n",
      "Epoch 966/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5606 - val_loss: 3.8728\n",
      "Epoch 967/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5579 - val_loss: 3.8267\n",
      "Epoch 968/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5273 - val_loss: 3.7903\n",
      "Epoch 969/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5641 - val_loss: 3.8129\n",
      "Epoch 970/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5420 - val_loss: 3.7667\n",
      "Epoch 971/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5183 - val_loss: 3.7685\n",
      "Epoch 972/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5184 - val_loss: 3.7016\n",
      "Epoch 973/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5532 - val_loss: 3.7796\n",
      "Epoch 974/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5559 - val_loss: 3.7900\n",
      "Epoch 975/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5143 - val_loss: 3.7967\n",
      "Epoch 976/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4836 - val_loss: 3.7557\n",
      "Epoch 977/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5134 - val_loss: 3.7915\n",
      "Epoch 978/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5676 - val_loss: 3.8911\n",
      "Epoch 979/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5948 - val_loss: 3.7385\n",
      "Epoch 980/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5204 - val_loss: 3.8021\n",
      "Epoch 981/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5253 - val_loss: 3.7491\n",
      "Epoch 982/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4975 - val_loss: 3.7413\n",
      "Epoch 983/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5411 - val_loss: 3.7614\n",
      "Epoch 984/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5664 - val_loss: 3.8890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5835 - val_loss: 3.7762\n",
      "Epoch 986/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5397 - val_loss: 3.8172\n",
      "Epoch 987/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6004 - val_loss: 3.7506\n",
      "Epoch 988/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5167 - val_loss: 3.7784\n",
      "Epoch 989/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4865 - val_loss: 3.7982\n",
      "Epoch 990/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4755 - val_loss: 3.7255\n",
      "Epoch 991/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5195 - val_loss: 3.7383\n",
      "Epoch 992/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5071 - val_loss: 3.7024\n",
      "Epoch 993/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4911 - val_loss: 3.7484\n",
      "Epoch 994/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5075 - val_loss: 3.8269\n",
      "Epoch 995/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5327 - val_loss: 3.7204\n",
      "Epoch 996/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5016 - val_loss: 3.8294\n",
      "Epoch 997/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5773 - val_loss: 3.8587\n",
      "Epoch 998/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5475 - val_loss: 3.7509\n",
      "Epoch 999/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4991 - val_loss: 3.6995\n",
      "Epoch 1000/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5447 - val_loss: 3.6905\n",
      "Epoch 1001/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4902 - val_loss: 3.7542\n",
      "Epoch 1002/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4982 - val_loss: 3.7769\n",
      "Epoch 1003/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5233 - val_loss: 3.6382\n",
      "Epoch 1004/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4890 - val_loss: 3.8432\n",
      "Epoch 1005/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5391 - val_loss: 3.7342\n",
      "Epoch 1006/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4759 - val_loss: 3.7402\n",
      "Epoch 1007/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4984 - val_loss: 3.6663\n",
      "Epoch 1008/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5055 - val_loss: 3.6596\n",
      "Epoch 1009/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5175 - val_loss: 3.8161\n",
      "Epoch 1010/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5138 - val_loss: 3.7278\n",
      "Epoch 1011/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4817 - val_loss: 3.8695\n",
      "Epoch 1012/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6246 - val_loss: 3.6763\n",
      "Epoch 1013/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5058 - val_loss: 3.7814\n",
      "Epoch 1014/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4433 - val_loss: 3.6845\n",
      "Epoch 1015/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5053 - val_loss: 3.7756\n",
      "Epoch 1016/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5115 - val_loss: 3.7229\n",
      "Epoch 1017/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4901 - val_loss: 3.6804\n",
      "Epoch 1018/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4621 - val_loss: 3.7262\n",
      "Epoch 1019/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4929 - val_loss: 3.7304\n",
      "Epoch 1020/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5027 - val_loss: 3.7180\n",
      "Epoch 1021/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5044 - val_loss: 3.7368\n",
      "Epoch 1022/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4921 - val_loss: 3.6596\n",
      "Epoch 1023/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4785 - val_loss: 3.6802\n",
      "Epoch 1024/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4368 - val_loss: 3.6830\n",
      "Epoch 1025/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4389 - val_loss: 3.7610\n",
      "Epoch 1026/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4596 - val_loss: 3.7546\n",
      "Epoch 1027/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4786 - val_loss: 3.7120\n",
      "Epoch 1028/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4431 - val_loss: 3.6644\n",
      "Epoch 1029/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4483 - val_loss: 3.6645\n",
      "Epoch 1030/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4381 - val_loss: 3.6613\n",
      "Epoch 1031/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4150 - val_loss: 3.7061\n",
      "Epoch 1032/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4479 - val_loss: 3.6946\n",
      "Epoch 1033/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4189 - val_loss: 3.6276\n",
      "Epoch 1034/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4464 - val_loss: 3.7047\n",
      "Epoch 1035/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4119 - val_loss: 3.6803\n",
      "Epoch 1036/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4102 - val_loss: 3.6696\n",
      "Epoch 1037/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4519 - val_loss: 3.6748\n",
      "Epoch 1038/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4311 - val_loss: 3.6099\n",
      "Epoch 1039/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4294 - val_loss: 3.6650\n",
      "Epoch 1040/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4135 - val_loss: 3.6564\n",
      "Epoch 1041/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4285 - val_loss: 3.7235\n",
      "Epoch 1042/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4032 - val_loss: 3.6111\n",
      "Epoch 1043/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4402 - val_loss: 3.6696\n",
      "Epoch 1044/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4809 - val_loss: 3.6475\n",
      "Epoch 1045/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4396 - val_loss: 3.6304\n",
      "Epoch 1046/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4417 - val_loss: 3.6861\n",
      "Epoch 1047/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4718 - val_loss: 3.6879\n",
      "Epoch 1048/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4162 - val_loss: 3.6486\n",
      "Epoch 1049/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4470 - val_loss: 3.7425\n",
      "Epoch 1050/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4446 - val_loss: 3.6284\n",
      "Epoch 1051/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4007 - val_loss: 3.6776\n",
      "Epoch 1052/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4129 - val_loss: 3.6598\n",
      "Epoch 1053/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4359 - val_loss: 3.6047\n",
      "Epoch 1054/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4730 - val_loss: 3.6842\n",
      "Epoch 1055/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4523 - val_loss: 3.6548\n",
      "Epoch 1056/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4822 - val_loss: 3.7323\n",
      "Epoch 1057/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4614 - val_loss: 3.6511\n",
      "Epoch 1058/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4734 - val_loss: 3.7608\n",
      "Epoch 1059/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4882 - val_loss: 3.6370\n",
      "Epoch 1060/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4370 - val_loss: 3.7252\n",
      "Epoch 1061/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4798 - val_loss: 3.5939\n",
      "Epoch 1062/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4760 - val_loss: 3.7406\n",
      "Epoch 1063/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4616 - val_loss: 3.6837\n",
      "Epoch 1064/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4440 - val_loss: 3.6000\n",
      "Epoch 1065/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4280 - val_loss: 3.6453\n",
      "Epoch 1066/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4211 - val_loss: 3.6626\n",
      "Epoch 1067/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3920 - val_loss: 3.6072\n",
      "Epoch 1068/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4076 - val_loss: 3.6829\n",
      "Epoch 1069/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4331 - val_loss: 3.6356\n",
      "Epoch 1070/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4106 - val_loss: 3.5604\n",
      "Epoch 1071/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4237 - val_loss: 3.6000\n",
      "Epoch 1072/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3787 - val_loss: 3.6055\n",
      "Epoch 1073/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3891 - val_loss: 3.6229\n",
      "Epoch 1074/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3960 - val_loss: 3.6262\n",
      "Epoch 1075/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4143 - val_loss: 3.5941\n",
      "Epoch 1076/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4611 - val_loss: 3.6453\n",
      "Epoch 1077/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4527 - val_loss: 3.6095\n",
      "Epoch 1078/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4398 - val_loss: 3.6919\n",
      "Epoch 1079/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4375 - val_loss: 3.5742\n",
      "Epoch 1080/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3897 - val_loss: 3.6401\n",
      "Epoch 1081/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3932 - val_loss: 3.6488\n",
      "Epoch 1082/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4036 - val_loss: 3.5770\n",
      "Epoch 1083/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4031 - val_loss: 3.6599\n",
      "Epoch 1084/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3996 - val_loss: 3.6169\n",
      "Epoch 1085/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4325 - val_loss: 3.6660\n",
      "Epoch 1086/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4306 - val_loss: 3.5922\n",
      "Epoch 1087/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4017 - val_loss: 3.6756\n",
      "Epoch 1088/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4237 - val_loss: 3.6126\n",
      "Epoch 1089/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4343 - val_loss: 3.6263\n",
      "Epoch 1090/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4184 - val_loss: 3.5697\n",
      "Epoch 1091/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4512 - val_loss: 3.6039\n",
      "Epoch 1092/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4197 - val_loss: 3.6856\n",
      "Epoch 1093/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4293 - val_loss: 3.5449\n",
      "Epoch 1094/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4057 - val_loss: 3.6055\n",
      "Epoch 1095/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4116 - val_loss: 3.6882\n",
      "Epoch 1096/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3950 - val_loss: 3.5412\n",
      "Epoch 1097/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3907 - val_loss: 3.6167\n",
      "Epoch 1098/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3783 - val_loss: 3.6422\n",
      "Epoch 1099/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3941 - val_loss: 3.5380\n",
      "Epoch 1100/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4061 - val_loss: 3.6482\n",
      "Epoch 1101/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4100 - val_loss: 3.6414\n",
      "Epoch 1102/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3727 - val_loss: 3.5327\n",
      "Epoch 1103/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3838 - val_loss: 3.6217\n",
      "Epoch 1104/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3775 - val_loss: 3.6268\n",
      "Epoch 1105/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4039 - val_loss: 3.5865\n",
      "Epoch 1106/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3806 - val_loss: 3.6003\n",
      "Epoch 1107/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3668 - val_loss: 3.6293\n",
      "Epoch 1108/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3810 - val_loss: 3.5848\n",
      "Epoch 1109/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3642 - val_loss: 3.5611\n",
      "Epoch 1110/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3727 - val_loss: 3.5912\n",
      "Epoch 1111/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3578 - val_loss: 3.6238\n",
      "Epoch 1112/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3674 - val_loss: 3.6004\n",
      "Epoch 1113/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4283 - val_loss: 3.6677\n",
      "Epoch 1114/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5063 - val_loss: 3.6378\n",
      "Epoch 1115/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3955 - val_loss: 3.6233\n",
      "Epoch 1116/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3959 - val_loss: 3.5938\n",
      "Epoch 1117/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3790 - val_loss: 3.6148\n",
      "Epoch 1118/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3998 - val_loss: 3.5261\n",
      "Epoch 1119/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3764 - val_loss: 3.6132\n",
      "Epoch 1120/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3993 - val_loss: 3.5798\n",
      "Epoch 1121/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3899 - val_loss: 3.5796\n",
      "Epoch 1122/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4191 - val_loss: 3.7108\n",
      "Epoch 1123/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4650 - val_loss: 3.5644\n",
      "Epoch 1124/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4149 - val_loss: 3.6545\n",
      "Epoch 1125/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4148 - val_loss: 3.6111\n",
      "Epoch 1126/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3850 - val_loss: 3.5842\n",
      "Epoch 1127/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3922 - val_loss: 3.5588\n",
      "Epoch 1128/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3882 - val_loss: 3.6085\n",
      "Epoch 1129/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3682 - val_loss: 3.6236\n",
      "Epoch 1130/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3843 - val_loss: 3.5527\n",
      "Epoch 1131/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3690 - val_loss: 3.6397\n",
      "Epoch 1132/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3704 - val_loss: 3.5733\n",
      "Epoch 1133/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3606 - val_loss: 3.5655\n",
      "Epoch 1134/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3563 - val_loss: 3.5717\n",
      "Epoch 1135/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3468 - val_loss: 3.5667\n",
      "Epoch 1136/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3387 - val_loss: 3.5746\n",
      "Epoch 1137/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3232 - val_loss: 3.5986\n",
      "Epoch 1138/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3711 - val_loss: 3.5771\n",
      "Epoch 1139/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4276 - val_loss: 3.6421\n",
      "Epoch 1140/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4175 - val_loss: 3.4967\n",
      "Epoch 1141/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4346 - val_loss: 3.6289\n",
      "Epoch 1142/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3471 - val_loss: 3.5695\n",
      "Epoch 1143/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3558 - val_loss: 3.5560\n",
      "Epoch 1144/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3574 - val_loss: 3.5176\n",
      "Epoch 1145/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3673 - val_loss: 3.5682\n",
      "Epoch 1146/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3426 - val_loss: 3.4901\n",
      "Epoch 1147/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3427 - val_loss: 3.5151\n",
      "Epoch 1148/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3521 - val_loss: 3.5861\n",
      "Epoch 1149/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3313 - val_loss: 3.5544\n",
      "Epoch 1150/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3543 - val_loss: 3.5328\n",
      "Epoch 1151/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3566 - val_loss: 3.5972\n",
      "Epoch 1152/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3492 - val_loss: 3.5545\n",
      "Epoch 1153/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3513 - val_loss: 3.4918\n",
      "Epoch 1154/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3618 - val_loss: 3.5191\n",
      "Epoch 1155/1500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3581 - val_loss: 3.5425\n",
      "Epoch 1156/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3224 - val_loss: 3.5234\n",
      "Epoch 1157/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3376 - val_loss: 3.5670\n",
      "Epoch 1158/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3470 - val_loss: 3.5076\n",
      "Epoch 1159/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3734 - val_loss: 3.4997\n",
      "Epoch 1160/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3193 - val_loss: 3.4805\n",
      "Epoch 1161/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3216 - val_loss: 3.5402\n",
      "Epoch 1162/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3738 - val_loss: 3.5686\n",
      "Epoch 1163/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3617 - val_loss: 3.5074\n",
      "Epoch 1164/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4078 - val_loss: 3.5888\n",
      "Epoch 1165/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3833 - val_loss: 3.5566\n",
      "Epoch 1166/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3231 - val_loss: 3.5100\n",
      "Epoch 1167/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3136 - val_loss: 3.5212\n",
      "Epoch 1168/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3846 - val_loss: 3.6196\n",
      "Epoch 1169/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4509 - val_loss: 3.4882\n",
      "Epoch 1170/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3644 - val_loss: 3.6045\n",
      "Epoch 1171/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3796 - val_loss: 3.5082\n",
      "Epoch 1172/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3592 - val_loss: 3.5432\n",
      "Epoch 1173/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3577 - val_loss: 3.5390\n",
      "Epoch 1174/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3667 - val_loss: 3.4437\n",
      "Epoch 1175/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3545 - val_loss: 3.5740\n",
      "Epoch 1176/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3413 - val_loss: 3.5226\n",
      "Epoch 1177/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3328 - val_loss: 3.5465\n",
      "Epoch 1178/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3392 - val_loss: 3.5345\n",
      "Epoch 1179/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3293 - val_loss: 3.5104\n",
      "Epoch 1180/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2989 - val_loss: 3.5624\n",
      "Epoch 1181/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2917 - val_loss: 3.5802\n",
      "Epoch 1182/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3360 - val_loss: 3.4705\n",
      "Epoch 1183/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3300 - val_loss: 3.4973\n",
      "Epoch 1184/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2908 - val_loss: 3.5233\n",
      "Epoch 1185/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3124 - val_loss: 3.5129\n",
      "Epoch 1186/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3207 - val_loss: 3.5535\n",
      "Epoch 1187/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3261 - val_loss: 3.5091\n",
      "Epoch 1188/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3260 - val_loss: 3.5520\n",
      "Epoch 1189/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3297 - val_loss: 3.4656\n",
      "Epoch 1190/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3313 - val_loss: 3.4574\n",
      "Epoch 1191/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3485 - val_loss: 3.6400\n",
      "Epoch 1192/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3630 - val_loss: 3.4836\n",
      "Epoch 1193/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3201 - val_loss: 3.4854\n",
      "Epoch 1194/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2983 - val_loss: 3.5297\n",
      "Epoch 1195/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3573 - val_loss: 3.5045\n",
      "Epoch 1196/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3177 - val_loss: 3.5284\n",
      "Epoch 1197/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3360 - val_loss: 3.5116\n",
      "Epoch 1198/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3624 - val_loss: 3.6417\n",
      "Epoch 1199/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4211 - val_loss: 3.5117\n",
      "Epoch 1200/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3222 - val_loss: 3.4775\n",
      "Epoch 1201/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2913 - val_loss: 3.5131\n",
      "Epoch 1202/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2785 - val_loss: 3.4655\n",
      "Epoch 1203/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2774 - val_loss: 3.4445\n",
      "Epoch 1204/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3155 - val_loss: 3.5026\n",
      "Epoch 1205/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2966 - val_loss: 3.4950\n",
      "Epoch 1206/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2933 - val_loss: 3.4195\n",
      "Epoch 1207/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3345 - val_loss: 3.4435\n",
      "Epoch 1208/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2864 - val_loss: 3.4899\n",
      "Epoch 1209/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2965 - val_loss: 3.4701\n",
      "Epoch 1210/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3106 - val_loss: 3.4719\n",
      "Epoch 1211/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3482 - val_loss: 3.5106\n",
      "Epoch 1212/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3421 - val_loss: 3.4684\n",
      "Epoch 1213/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3303 - val_loss: 3.5687\n",
      "Epoch 1214/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3325 - val_loss: 3.4386\n",
      "Epoch 1215/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3014 - val_loss: 3.4627\n",
      "Epoch 1216/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3029 - val_loss: 3.4855\n",
      "Epoch 1217/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3369 - val_loss: 3.4190\n",
      "Epoch 1218/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3052 - val_loss: 3.4756\n",
      "Epoch 1219/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3049 - val_loss: 3.5006\n",
      "Epoch 1220/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3178 - val_loss: 3.3977\n",
      "Epoch 1221/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4054 - val_loss: 3.4257\n",
      "Epoch 1222/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3879 - val_loss: 3.5077\n",
      "Epoch 1223/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3663 - val_loss: 3.5478\n",
      "Epoch 1224/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3691 - val_loss: 3.5401\n",
      "Epoch 1225/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3507 - val_loss: 3.4536\n",
      "Epoch 1226/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3127 - val_loss: 3.5385\n",
      "Epoch 1227/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2791 - val_loss: 3.4955\n",
      "Epoch 1228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3070 - val_loss: 3.5534\n",
      "Epoch 1229/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3397 - val_loss: 3.4700\n",
      "Epoch 1230/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3780 - val_loss: 3.5065\n",
      "Epoch 1231/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3362 - val_loss: 3.5897\n",
      "Epoch 1232/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2897 - val_loss: 3.4689\n",
      "Epoch 1233/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2768 - val_loss: 3.4837\n",
      "Epoch 1234/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2829 - val_loss: 3.4490\n",
      "Epoch 1235/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2470 - val_loss: 3.4856\n",
      "Epoch 1236/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2893 - val_loss: 3.4873\n",
      "Epoch 1237/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2755 - val_loss: 3.4389\n",
      "Epoch 1238/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3010 - val_loss: 3.4873\n",
      "Epoch 1239/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2915 - val_loss: 3.4366\n",
      "Epoch 1240/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3201 - val_loss: 3.3586\n",
      "Epoch 1241/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3658 - val_loss: 3.5733\n",
      "Epoch 1242/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3430 - val_loss: 3.4110\n",
      "Epoch 1243/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3200 - val_loss: 3.4961\n",
      "Epoch 1244/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2806 - val_loss: 3.4763\n",
      "Epoch 1245/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2909 - val_loss: 3.4612\n",
      "Epoch 1246/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2584 - val_loss: 3.4017\n",
      "Epoch 1247/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3015 - val_loss: 3.4745\n",
      "Epoch 1248/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2780 - val_loss: 3.4379\n",
      "Epoch 1249/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2808 - val_loss: 3.4340\n",
      "Epoch 1250/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2894 - val_loss: 3.4049\n",
      "Epoch 1251/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2491 - val_loss: 3.4286\n",
      "Epoch 1252/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2863 - val_loss: 3.4174\n",
      "Epoch 1253/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2752 - val_loss: 3.3875\n",
      "Epoch 1254/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2958 - val_loss: 3.3952\n",
      "Epoch 1255/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2872 - val_loss: 3.3591\n",
      "Epoch 1256/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2978 - val_loss: 3.4747\n",
      "Epoch 1257/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2872 - val_loss: 3.4273\n",
      "Epoch 1258/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3655 - val_loss: 3.3896\n",
      "Epoch 1259/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3548 - val_loss: 3.4741\n",
      "Epoch 1260/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2971 - val_loss: 3.4340\n",
      "Epoch 1261/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2705 - val_loss: 3.4431\n",
      "Epoch 1262/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2778 - val_loss: 3.3210\n",
      "Epoch 1263/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3231 - val_loss: 3.4080\n",
      "Epoch 1264/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2908 - val_loss: 3.4642\n",
      "Epoch 1265/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3076 - val_loss: 3.3418\n",
      "Epoch 1266/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3213 - val_loss: 3.3579\n",
      "Epoch 1267/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3186 - val_loss: 3.5033\n",
      "Epoch 1268/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2721 - val_loss: 3.3884\n",
      "Epoch 1269/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2985 - val_loss: 3.3291\n",
      "Epoch 1270/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3529 - val_loss: 3.4694\n",
      "Epoch 1271/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3138 - val_loss: 3.4102\n",
      "Epoch 1272/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2760 - val_loss: 3.3792\n",
      "Epoch 1273/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2736 - val_loss: 3.5028\n",
      "Epoch 1274/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3244 - val_loss: 3.3568\n",
      "Epoch 1275/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3267 - val_loss: 3.4753\n",
      "Epoch 1276/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3369 - val_loss: 3.3577\n",
      "Epoch 1277/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3327 - val_loss: 3.4631\n",
      "Epoch 1278/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3528 - val_loss: 3.3837\n",
      "Epoch 1279/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3870 - val_loss: 3.5178\n",
      "Epoch 1280/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2844 - val_loss: 3.3397\n",
      "Epoch 1281/1500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3218 - val_loss: 3.4601\n",
      "Epoch 1282/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3094 - val_loss: 3.3917\n",
      "Epoch 1283/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3071 - val_loss: 3.4297\n",
      "Epoch 1284/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2877 - val_loss: 3.3750\n",
      "Epoch 1285/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2479 - val_loss: 3.3898\n",
      "Epoch 1286/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2694 - val_loss: 3.4548\n",
      "Epoch 1287/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2628 - val_loss: 3.3882\n",
      "Epoch 1288/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2576 - val_loss: 3.3715\n",
      "Epoch 1289/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2699 - val_loss: 3.3710\n",
      "Epoch 1290/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2568 - val_loss: 3.4180\n",
      "Epoch 1291/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2420 - val_loss: 3.3580\n",
      "Epoch 1292/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3242 - val_loss: 3.3814\n",
      "Epoch 1293/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2934 - val_loss: 3.3859\n",
      "Epoch 1294/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2952 - val_loss: 3.3895\n",
      "Epoch 1295/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2963 - val_loss: 3.3974\n",
      "Epoch 1296/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2644 - val_loss: 3.3765\n",
      "Epoch 1297/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2889 - val_loss: 3.4738\n",
      "Epoch 1298/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2817 - val_loss: 3.3763\n",
      "Epoch 1299/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2567 - val_loss: 3.4193\n",
      "Epoch 1300/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2955 - val_loss: 3.3909\n",
      "Epoch 1301/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2663 - val_loss: 3.3692\n",
      "Epoch 1302/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2814 - val_loss: 3.3844\n",
      "Epoch 1303/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2640 - val_loss: 3.4542\n",
      "Epoch 1304/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3500 - val_loss: 3.4075\n",
      "Epoch 1305/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3503 - val_loss: 3.5028\n",
      "Epoch 1306/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3273 - val_loss: 3.3900\n",
      "Epoch 1307/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3839 - val_loss: 3.4538\n",
      "Epoch 1308/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2874 - val_loss: 3.3126\n",
      "Epoch 1309/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3090 - val_loss: 3.4013\n",
      "Epoch 1310/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2825 - val_loss: 3.4448\n",
      "Epoch 1311/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2723 - val_loss: 3.3688\n",
      "Epoch 1312/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3280 - val_loss: 3.4901\n",
      "Epoch 1313/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3153 - val_loss: 3.3370\n",
      "Epoch 1314/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2557 - val_loss: 3.5195\n",
      "Epoch 1315/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2986 - val_loss: 3.3778\n",
      "Epoch 1316/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2869 - val_loss: 3.4172\n",
      "Epoch 1317/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2806 - val_loss: 3.3501\n",
      "Epoch 1318/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2482 - val_loss: 3.3981\n",
      "Epoch 1319/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2347 - val_loss: 3.4162\n",
      "Epoch 1320/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2508 - val_loss: 3.3494\n",
      "Epoch 1321/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2717 - val_loss: 3.3814\n",
      "Epoch 1322/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2819 - val_loss: 3.3951\n",
      "Epoch 1323/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3104 - val_loss: 3.4642\n",
      "Epoch 1324/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2934 - val_loss: 3.4226\n",
      "Epoch 1325/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2637 - val_loss: 3.3455\n",
      "Epoch 1326/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2367 - val_loss: 3.4809\n",
      "Epoch 1327/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2712 - val_loss: 3.3756\n",
      "Epoch 1328/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2465 - val_loss: 3.3206\n",
      "Epoch 1329/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2439 - val_loss: 3.4742\n",
      "Epoch 1330/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3029 - val_loss: 3.5476\n",
      "Epoch 1331/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2403 - val_loss: 3.3890\n",
      "Epoch 1332/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2640 - val_loss: 3.4241\n",
      "Epoch 1333/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2409 - val_loss: 3.3925\n",
      "Epoch 1334/1500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2231 - val_loss: 3.4678\n",
      "Epoch 1335/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2454 - val_loss: 3.3932\n",
      "Epoch 1336/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3240 - val_loss: 3.5547\n",
      "Epoch 1337/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3066 - val_loss: 3.4299\n",
      "Epoch 1338/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2845 - val_loss: 3.5215\n",
      "Epoch 1339/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2634 - val_loss: 3.3555\n",
      "Epoch 1340/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2489 - val_loss: 3.3783\n",
      "Epoch 1341/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2448 - val_loss: 3.3886\n",
      "Epoch 1342/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2481 - val_loss: 3.3456\n",
      "Epoch 1343/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2353 - val_loss: 3.3972\n",
      "Epoch 1344/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2443 - val_loss: 3.4218\n",
      "Epoch 1345/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2674 - val_loss: 3.3805\n",
      "Epoch 1346/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2335 - val_loss: 3.3548\n",
      "Epoch 1347/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2510 - val_loss: 3.3273\n",
      "Epoch 1348/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2284 - val_loss: 3.4222\n",
      "Epoch 1349/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2555 - val_loss: 3.4439\n",
      "Epoch 1350/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2548 - val_loss: 3.3761\n",
      "Epoch 1351/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2139 - val_loss: 3.3579\n",
      "Epoch 1352/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2306 - val_loss: 3.4859\n",
      "Epoch 1353/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2668 - val_loss: 3.3349\n",
      "Epoch 1354/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3278 - val_loss: 3.4282\n",
      "Epoch 1355/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3613 - val_loss: 3.4754\n",
      "Epoch 1356/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3495 - val_loss: 3.4835\n",
      "Epoch 1357/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2657 - val_loss: 3.3630\n",
      "Epoch 1358/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2578 - val_loss: 3.2906\n",
      "Epoch 1359/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3024 - val_loss: 3.4452\n",
      "Epoch 1360/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2777 - val_loss: 3.3680\n",
      "Epoch 1361/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2260 - val_loss: 3.3949\n",
      "Epoch 1362/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2891 - val_loss: 3.3326\n",
      "Epoch 1363/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2885 - val_loss: 3.3546\n",
      "Epoch 1364/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2444 - val_loss: 3.4009\n",
      "Epoch 1365/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2725 - val_loss: 3.3262\n",
      "Epoch 1366/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2140 - val_loss: 3.4959\n",
      "Epoch 1367/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2477 - val_loss: 3.4356\n",
      "Epoch 1368/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2267 - val_loss: 3.3857\n",
      "Epoch 1369/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2802 - val_loss: 3.4133\n",
      "Epoch 1370/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2413 - val_loss: 3.3569\n",
      "Epoch 1371/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2014 - val_loss: 3.3519\n",
      "Epoch 1372/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2381 - val_loss: 3.3022\n",
      "Epoch 1373/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2461 - val_loss: 3.3624\n",
      "Epoch 1374/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2254 - val_loss: 3.3728\n",
      "Epoch 1375/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1996 - val_loss: 3.2786\n",
      "Epoch 1376/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2499 - val_loss: 3.3353\n",
      "Epoch 1377/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2093 - val_loss: 3.3261\n",
      "Epoch 1378/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2601 - val_loss: 3.3211\n",
      "Epoch 1379/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2360 - val_loss: 3.4110\n",
      "Epoch 1380/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2348 - val_loss: 3.2986\n",
      "Epoch 1381/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2608 - val_loss: 3.3445\n",
      "Epoch 1382/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2552 - val_loss: 3.3760\n",
      "Epoch 1383/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2124 - val_loss: 3.3109\n",
      "Epoch 1384/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2119 - val_loss: 3.3488\n",
      "Epoch 1385/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2440 - val_loss: 3.3227\n",
      "Epoch 1386/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2806 - val_loss: 3.3754\n",
      "Epoch 1387/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2766 - val_loss: 3.3990\n",
      "Epoch 1388/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2690 - val_loss: 3.4541\n",
      "Epoch 1389/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3377 - val_loss: 3.2714\n",
      "Epoch 1390/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3536 - val_loss: 3.3430\n",
      "Epoch 1391/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2808 - val_loss: 3.3529\n",
      "Epoch 1392/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2781 - val_loss: 3.3862\n",
      "Epoch 1393/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2401 - val_loss: 3.2812\n",
      "Epoch 1394/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2380 - val_loss: 3.2321\n",
      "Epoch 1395/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2026 - val_loss: 3.3582\n",
      "Epoch 1396/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1901 - val_loss: 3.2840\n",
      "Epoch 1397/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1694 - val_loss: 3.3059\n",
      "Epoch 1398/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1711 - val_loss: 3.3728\n",
      "Epoch 1399/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2245 - val_loss: 3.3269\n",
      "Epoch 1400/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2053 - val_loss: 3.3037\n",
      "Epoch 1401/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2240 - val_loss: 3.3635\n",
      "Epoch 1402/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2021 - val_loss: 3.3015\n",
      "Epoch 1403/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2161 - val_loss: 3.4101\n",
      "Epoch 1404/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2558 - val_loss: 3.2721\n",
      "Epoch 1405/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1869 - val_loss: 3.3188\n",
      "Epoch 1406/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2030 - val_loss: 3.3932\n",
      "Epoch 1407/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2146 - val_loss: 3.3296\n",
      "Epoch 1408/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2319 - val_loss: 3.3085\n",
      "Epoch 1409/1500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.2007 - val_loss: 3.3219\n",
      "Epoch 1410/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2658 - val_loss: 3.3364\n",
      "Epoch 1411/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2035 - val_loss: 3.2837\n",
      "Epoch 1412/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1992 - val_loss: 3.2700\n",
      "Epoch 1413/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1697 - val_loss: 3.3360\n",
      "Epoch 1414/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1776 - val_loss: 3.3165\n",
      "Epoch 1415/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1828 - val_loss: 3.3051\n",
      "Epoch 1416/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1887 - val_loss: 3.3292\n",
      "Epoch 1417/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2091 - val_loss: 3.2761\n",
      "Epoch 1418/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1764 - val_loss: 3.3062\n",
      "Epoch 1419/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1775 - val_loss: 3.4143\n",
      "Epoch 1420/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3286 - val_loss: 3.2603\n",
      "Epoch 1421/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1938 - val_loss: 3.4446\n",
      "Epoch 1422/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3208 - val_loss: 3.3604\n",
      "Epoch 1423/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2449 - val_loss: 3.3372\n",
      "Epoch 1424/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2615 - val_loss: 3.2345\n",
      "Epoch 1425/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1665 - val_loss: 3.2984\n",
      "Epoch 1426/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1685 - val_loss: 3.3165\n",
      "Epoch 1427/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1906 - val_loss: 3.3110\n",
      "Epoch 1428/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1967 - val_loss: 3.2931\n",
      "Epoch 1429/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2032 - val_loss: 3.2794\n",
      "Epoch 1430/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1997 - val_loss: 3.3185\n",
      "Epoch 1431/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2083 - val_loss: 3.2923\n",
      "Epoch 1432/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2382 - val_loss: 3.4099\n",
      "Epoch 1433/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2463 - val_loss: 3.3026\n",
      "Epoch 1434/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2445 - val_loss: 3.4587\n",
      "Epoch 1435/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2598 - val_loss: 3.2560\n",
      "Epoch 1436/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2456 - val_loss: 3.3534\n",
      "Epoch 1437/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2265 - val_loss: 3.3427\n",
      "Epoch 1438/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2351 - val_loss: 3.2602\n",
      "Epoch 1439/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2695 - val_loss: 3.2067\n",
      "Epoch 1440/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2243 - val_loss: 3.3366\n",
      "Epoch 1441/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1938 - val_loss: 3.3470\n",
      "Epoch 1442/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2371 - val_loss: 3.3060\n",
      "Epoch 1443/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1823 - val_loss: 3.3032\n",
      "Epoch 1444/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1837 - val_loss: 3.3325\n",
      "Epoch 1445/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2155 - val_loss: 3.2755\n",
      "Epoch 1446/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2191 - val_loss: 3.3209\n",
      "Epoch 1447/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1820 - val_loss: 3.3263\n",
      "Epoch 1448/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2098 - val_loss: 3.3061\n",
      "Epoch 1449/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2232 - val_loss: 3.4101\n",
      "Epoch 1450/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2996 - val_loss: 3.2837\n",
      "Epoch 1451/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2067 - val_loss: 3.4156\n",
      "Epoch 1452/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2669 - val_loss: 3.2691\n",
      "Epoch 1453/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2168 - val_loss: 3.2876\n",
      "Epoch 1454/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1680 - val_loss: 3.2629\n",
      "Epoch 1455/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2002 - val_loss: 3.2185\n",
      "Epoch 1456/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2286 - val_loss: 3.4461\n",
      "Epoch 1457/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2451 - val_loss: 3.2761\n",
      "Epoch 1458/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2551 - val_loss: 3.3774\n",
      "Epoch 1459/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2267 - val_loss: 3.2898\n",
      "Epoch 1460/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2147 - val_loss: 3.4397\n",
      "Epoch 1461/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2543 - val_loss: 3.2485\n",
      "Epoch 1462/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2222 - val_loss: 3.3839\n",
      "Epoch 1463/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2297 - val_loss: 3.2105\n",
      "Epoch 1464/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1735 - val_loss: 3.2745\n",
      "Epoch 1465/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1686 - val_loss: 3.3055\n",
      "Epoch 1466/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2281 - val_loss: 3.3103\n",
      "Epoch 1467/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2122 - val_loss: 3.2626\n",
      "Epoch 1468/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1674 - val_loss: 3.2760\n",
      "Epoch 1469/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1518 - val_loss: 3.3032\n",
      "Epoch 1470/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1845 - val_loss: 3.2484\n",
      "Epoch 1471/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1876 - val_loss: 3.2802\n",
      "Epoch 1472/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1470 - val_loss: 3.2894\n",
      "Epoch 1473/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1408 - val_loss: 3.2443\n",
      "Epoch 1474/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1410 - val_loss: 3.2669\n",
      "Epoch 1475/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1670 - val_loss: 3.3002\n",
      "Epoch 1476/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1679 - val_loss: 3.2627\n",
      "Epoch 1477/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1372 - val_loss: 3.2833\n",
      "Epoch 1478/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1721 - val_loss: 3.3073\n",
      "Epoch 1479/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1598 - val_loss: 3.2822\n",
      "Epoch 1480/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1652 - val_loss: 3.2908\n",
      "Epoch 1481/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1627 - val_loss: 3.2637\n",
      "Epoch 1482/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1614 - val_loss: 3.2541\n",
      "Epoch 1483/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1803 - val_loss: 3.3111\n",
      "Epoch 1484/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2000 - val_loss: 3.3203\n",
      "Epoch 1485/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1871 - val_loss: 3.2242\n",
      "Epoch 1486/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2056 - val_loss: 3.3409\n",
      "Epoch 1487/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2278 - val_loss: 3.2577\n",
      "Epoch 1488/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2168 - val_loss: 3.2949\n",
      "Epoch 1489/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2226 - val_loss: 3.2562\n",
      "Epoch 1490/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2012 - val_loss: 3.3632\n",
      "Epoch 1491/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2163 - val_loss: 3.2787\n",
      "Epoch 1492/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2251 - val_loss: 3.3636\n",
      "Epoch 1493/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1850 - val_loss: 3.2470\n",
      "Epoch 1494/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1892 - val_loss: 3.2308\n",
      "Epoch 1495/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1738 - val_loss: 3.2964\n",
      "Epoch 1496/1500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1330 - val_loss: 3.2645\n",
      "Epoch 1497/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2383 - val_loss: 3.2673\n",
      "Epoch 1498/1500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2080 - val_loss: 3.3111\n",
      "Epoch 1499/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2215 - val_loss: 3.2628\n",
      "Epoch 1500/1500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2050 - val_loss: 3.2331\n",
      "Train: 2.163, Test: 3.233\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # DO NOT Modify this gives 74% accuracy- LOL just kidding\n",
    "# reg_model = Sequential()\n",
    "# a=reg_model.add(Dense(8, input_dim=10, activation='relu',kernel_initializer='he_uniform',kernel_regularizer='l2'))\n",
    "# # reg_model.add(Dense(4, activation='relu',kernel_regularizer='l2'))\n",
    "# reg_model.add(Dropout(0.2))\n",
    "# reg_model.add(Dense(1, activation='linear'))\n",
    "# reg_model.compile(loss='mae', \n",
    "#                 optimizer='SGD')\n",
    "\n",
    "\n",
    "# history = reg_model.fit(X_train_std, Y_train, \n",
    "#                             validation_data=(X_test_std, Y_test), \n",
    "#                             epochs=100, verbose=1)\n",
    "\n",
    "# train_mse = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "# test_mse = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# # plot loss during training\n",
    "# plt.title('Loss / Mean Squared Error')\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# # DO NOT Modify this gives 70%- actually\n",
    "tf.random.set_seed(1)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(64, input_dim=10, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(16, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(8, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(1))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=1500, verbose=1)\n",
    "y_pred=reg_model.predict(X_test_std)\n",
    "train_mae = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mae = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mae, test_mae))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean absolute Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e927ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=reg_model.predict(X_train_std)\n",
    "R2=r2_score(Y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f5a90fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757265543489126"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train_std)\n",
    "p = len(X[1])\n",
    "adj_R2_train = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6e4b99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=reg_model.predict(X_test_std)\n",
    "R2=r2_score(Y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "744d18fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496418870856295"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train_std)\n",
    "p = len(X[1])\n",
    "adj_R2_test = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b6b31",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "007d9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X= scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ec111016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a01dc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "86f842d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 9)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e89d3c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.933396</td>\n",
       "      <td>-1.815459</td>\n",
       "      <td>-1.149201</td>\n",
       "      <td>-0.169943</td>\n",
       "      <td>0.471828</td>\n",
       "      <td>-0.398843</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.435945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.933780</td>\n",
       "      <td>-1.815191</td>\n",
       "      <td>-1.147765</td>\n",
       "      <td>-0.170004</td>\n",
       "      <td>0.473926</td>\n",
       "      <td>-0.398018</td>\n",
       "      <td>-0.064108</td>\n",
       "      <td>0.064483</td>\n",
       "      <td>0.436006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.934420</td>\n",
       "      <td>-1.814744</td>\n",
       "      <td>-1.145372</td>\n",
       "      <td>-0.170107</td>\n",
       "      <td>0.477423</td>\n",
       "      <td>-0.396643</td>\n",
       "      <td>-0.063928</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.436107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.936979</td>\n",
       "      <td>-1.812956</td>\n",
       "      <td>-1.135800</td>\n",
       "      <td>-0.170517</td>\n",
       "      <td>0.491409</td>\n",
       "      <td>-0.391141</td>\n",
       "      <td>-0.063210</td>\n",
       "      <td>0.067044</td>\n",
       "      <td>0.436512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.942098</td>\n",
       "      <td>-1.809381</td>\n",
       "      <td>-1.116655</td>\n",
       "      <td>-0.171336</td>\n",
       "      <td>0.519382</td>\n",
       "      <td>-0.380137</td>\n",
       "      <td>-0.061773</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>0.437322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.933396 -1.815459 -1.149201 -0.169943  0.471828 -0.398843 -0.064216   \n",
       "1 -1.933780 -1.815191 -1.147765 -0.170004  0.473926 -0.398018 -0.064108   \n",
       "2 -1.934420 -1.814744 -1.145372 -0.170107  0.477423 -0.396643 -0.063928   \n",
       "3 -1.936979 -1.812956 -1.135800 -0.170517  0.491409 -0.391141 -0.063210   \n",
       "4 -1.942098 -1.809381 -1.116655 -0.171336  0.519382 -0.380137 -0.061773   \n",
       "\n",
       "          7         8  \n",
       "0  0.064176  0.435945  \n",
       "1  0.064483  0.436006  \n",
       "2  0.064995  0.436107  \n",
       "3  0.067044  0.436512  \n",
       "4  0.071141  0.437322  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df = pd.DataFrame(data = X_pca)\n",
    "PCA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d70b801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(PCA_df, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3002b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn import linear_model, tree, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "57c06e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "6/6 [==============================] - 1s 31ms/step - loss: 11.1084 - val_loss: 13.6679\n",
      "Epoch 2/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.9334 - val_loss: 13.5441\n",
      "Epoch 3/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.7851 - val_loss: 13.4245\n",
      "Epoch 4/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.6906 - val_loss: 13.3056\n",
      "Epoch 5/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.5438 - val_loss: 13.1773\n",
      "Epoch 6/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.3200 - val_loss: 13.0268\n",
      "Epoch 7/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.1505 - val_loss: 12.8464\n",
      "Epoch 8/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.9656 - val_loss: 12.6415\n",
      "Epoch 9/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.7743 - val_loss: 12.4088\n",
      "Epoch 10/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.4384 - val_loss: 12.1449\n",
      "Epoch 11/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.3131 - val_loss: 11.8538\n",
      "Epoch 12/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.0508 - val_loss: 11.5296\n",
      "Epoch 13/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.7334 - val_loss: 11.1759\n",
      "Epoch 14/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.6166 - val_loss: 10.7858\n",
      "Epoch 15/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.2579 - val_loss: 10.4045\n",
      "Epoch 16/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.0782 - val_loss: 10.0010\n",
      "Epoch 17/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.6494 - val_loss: 9.6502\n",
      "Epoch 18/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.2632 - val_loss: 9.3390\n",
      "Epoch 19/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.3211 - val_loss: 9.0818\n",
      "Epoch 20/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.9706 - val_loss: 8.8075\n",
      "Epoch 21/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.8385 - val_loss: 8.5841\n",
      "Epoch 22/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.5140 - val_loss: 8.3896\n",
      "Epoch 23/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.2686 - val_loss: 8.1941\n",
      "Epoch 24/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.9306 - val_loss: 7.9908\n",
      "Epoch 25/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.7667 - val_loss: 7.8555\n",
      "Epoch 26/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.0663 - val_loss: 7.7383\n",
      "Epoch 27/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.8327 - val_loss: 7.6252\n",
      "Epoch 28/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6840 - val_loss: 7.5148\n",
      "Epoch 29/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.5908 - val_loss: 7.4110\n",
      "Epoch 30/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4300 - val_loss: 7.3140\n",
      "Epoch 31/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4883 - val_loss: 7.2123\n",
      "Epoch 32/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4520 - val_loss: 7.1323\n",
      "Epoch 33/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1224 - val_loss: 7.0357\n",
      "Epoch 34/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1770 - val_loss: 6.9220\n",
      "Epoch 35/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.3007 - val_loss: 6.8697\n",
      "Epoch 36/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6109 - val_loss: 6.8145\n",
      "Epoch 37/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1024 - val_loss: 6.7741\n",
      "Epoch 38/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1373 - val_loss: 6.7645\n",
      "Epoch 39/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9747 - val_loss: 6.7691\n",
      "Epoch 40/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1592 - val_loss: 6.7719\n",
      "Epoch 41/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8611 - val_loss: 6.7368\n",
      "Epoch 42/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8487 - val_loss: 6.6823\n",
      "Epoch 43/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6719 - val_loss: 6.6372\n",
      "Epoch 44/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8513 - val_loss: 6.6429\n",
      "Epoch 45/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0959 - val_loss: 6.6141\n",
      "Epoch 46/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1590 - val_loss: 6.5717\n",
      "Epoch 47/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5787 - val_loss: 6.5497\n",
      "Epoch 48/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8685 - val_loss: 6.5290\n",
      "Epoch 49/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8477 - val_loss: 6.5173\n",
      "Epoch 50/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8687 - val_loss: 6.5376\n",
      "Epoch 51/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6812 - val_loss: 6.5294\n",
      "Epoch 52/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7705 - val_loss: 6.4869\n",
      "Epoch 53/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9080 - val_loss: 6.4448\n",
      "Epoch 54/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9610 - val_loss: 6.4107\n",
      "Epoch 55/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9118 - val_loss: 6.4297\n",
      "Epoch 56/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0856 - val_loss: 6.4170\n",
      "Epoch 57/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7956 - val_loss: 6.4166\n",
      "Epoch 58/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0411 - val_loss: 6.4218\n",
      "Epoch 59/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7201 - val_loss: 6.3882\n",
      "Epoch 60/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.8320 - val_loss: 6.3530\n",
      "Epoch 61/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7261 - val_loss: 6.3260\n",
      "Epoch 62/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6746 - val_loss: 6.3402\n",
      "Epoch 63/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8009 - val_loss: 6.3745\n",
      "Epoch 64/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5982 - val_loss: 6.4038\n",
      "Epoch 65/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5257 - val_loss: 6.3995\n",
      "Epoch 66/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0012 - val_loss: 6.4004\n",
      "Epoch 67/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5302 - val_loss: 6.3869\n",
      "Epoch 68/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7324 - val_loss: 6.3882\n",
      "Epoch 69/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6571 - val_loss: 6.3932\n",
      "Epoch 70/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6073 - val_loss: 6.4192\n",
      "Epoch 71/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6266 - val_loss: 6.4828\n",
      "Epoch 72/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9787 - val_loss: 6.4627\n",
      "Epoch 73/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5635 - val_loss: 6.3849\n",
      "Epoch 74/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6387 - val_loss: 6.3281\n",
      "Epoch 75/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9362 - val_loss: 6.3199\n",
      "Epoch 76/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7414 - val_loss: 6.2973\n",
      "Epoch 77/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1970 - val_loss: 6.2785\n",
      "Epoch 78/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8945 - val_loss: 6.2656\n",
      "Epoch 79/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4832 - val_loss: 6.2480\n",
      "Epoch 80/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8935 - val_loss: 6.2541\n",
      "Epoch 81/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7046 - val_loss: 6.2555\n",
      "Epoch 82/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6195 - val_loss: 6.2484\n",
      "Epoch 83/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5756 - val_loss: 6.2648\n",
      "Epoch 84/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5794 - val_loss: 6.2716\n",
      "Epoch 85/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7474 - val_loss: 6.2676\n",
      "Epoch 86/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8316 - val_loss: 6.2380\n",
      "Epoch 87/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7734 - val_loss: 6.2111\n",
      "Epoch 88/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6738 - val_loss: 6.1853\n",
      "Epoch 89/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5646 - val_loss: 6.1999\n",
      "Epoch 90/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7353 - val_loss: 6.2403\n",
      "Epoch 91/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6141 - val_loss: 6.2916\n",
      "Epoch 92/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5932 - val_loss: 6.3234\n",
      "Epoch 93/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5524 - val_loss: 6.2691\n",
      "Epoch 94/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7071 - val_loss: 6.2045\n",
      "Epoch 95/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4592 - val_loss: 6.1464\n",
      "Epoch 96/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7902 - val_loss: 6.1575\n",
      "Epoch 97/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5561 - val_loss: 6.1538\n",
      "Epoch 98/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5442 - val_loss: 6.1888\n",
      "Epoch 99/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6731 - val_loss: 6.2090\n",
      "Epoch 100/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6708 - val_loss: 6.2110\n",
      "Epoch 101/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5633 - val_loss: 6.2027\n",
      "Epoch 102/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4463 - val_loss: 6.1922\n",
      "Epoch 103/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6173 - val_loss: 6.1523\n",
      "Epoch 104/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5726 - val_loss: 6.1070\n",
      "Epoch 105/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3036 - val_loss: 6.0882\n",
      "Epoch 106/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7635 - val_loss: 6.1073\n",
      "Epoch 107/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7813 - val_loss: 6.1521\n",
      "Epoch 108/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4194 - val_loss: 6.1295\n",
      "Epoch 109/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5603 - val_loss: 6.1147\n",
      "Epoch 110/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8017 - val_loss: 6.0846\n",
      "Epoch 111/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4311 - val_loss: 6.0524\n",
      "Epoch 112/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4048 - val_loss: 6.0468\n",
      "Epoch 113/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5957 - val_loss: 6.0566\n",
      "Epoch 114/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7351 - val_loss: 6.0547\n",
      "Epoch 115/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4210 - val_loss: 6.0473\n",
      "Epoch 116/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4986 - val_loss: 6.0240\n",
      "Epoch 117/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6288 - val_loss: 5.9957\n",
      "Epoch 118/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5383 - val_loss: 5.9899\n",
      "Epoch 119/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2764 - val_loss: 6.0124\n",
      "Epoch 120/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1757 - val_loss: 6.0589\n",
      "Epoch 121/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5237 - val_loss: 6.0922\n",
      "Epoch 122/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4444 - val_loss: 6.0988\n",
      "Epoch 123/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5057 - val_loss: 6.0704\n",
      "Epoch 124/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2140 - val_loss: 6.0248\n",
      "Epoch 125/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6891 - val_loss: 5.9797\n",
      "Epoch 126/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6700 - val_loss: 5.9536\n",
      "Epoch 127/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1224 - val_loss: 5.9434\n",
      "Epoch 128/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4488 - val_loss: 5.9728\n",
      "Epoch 129/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6075 - val_loss: 5.9985\n",
      "Epoch 130/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6606 - val_loss: 5.9905\n",
      "Epoch 131/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1831 - val_loss: 5.9977\n",
      "Epoch 132/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5698 - val_loss: 6.0061\n",
      "Epoch 133/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7072 - val_loss: 5.9893\n",
      "Epoch 134/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3071 - val_loss: 5.9700\n",
      "Epoch 135/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3836 - val_loss: 5.9258\n",
      "Epoch 136/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5366 - val_loss: 5.9086\n",
      "Epoch 137/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4300 - val_loss: 5.9435\n",
      "Epoch 138/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3001 - val_loss: 5.9397\n",
      "Epoch 139/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3343 - val_loss: 5.9495\n",
      "Epoch 140/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5158 - val_loss: 5.9953\n",
      "Epoch 141/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4723 - val_loss: 6.0368\n",
      "Epoch 142/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5541 - val_loss: 6.0671\n",
      "Epoch 143/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3249 - val_loss: 6.0787\n",
      "Epoch 144/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4250 - val_loss: 6.0581\n",
      "Epoch 145/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3527 - val_loss: 6.0339\n",
      "Epoch 146/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3492 - val_loss: 6.0002\n",
      "Epoch 147/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4633 - val_loss: 5.9947\n",
      "Epoch 148/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5404 - val_loss: 6.0023\n",
      "Epoch 149/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3361 - val_loss: 6.0147\n",
      "Epoch 150/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4344 - val_loss: 6.0212\n",
      "Epoch 151/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5577 - val_loss: 5.9944\n",
      "Epoch 152/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4838 - val_loss: 5.9598\n",
      "Epoch 153/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4811 - val_loss: 5.9338\n",
      "Epoch 154/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2531 - val_loss: 5.9315\n",
      "Epoch 155/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4324 - val_loss: 5.8888\n",
      "Epoch 156/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1552 - val_loss: 5.8946\n",
      "Epoch 157/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6300 - val_loss: 5.9425\n",
      "Epoch 158/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2781 - val_loss: 5.9599\n",
      "Epoch 159/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3767 - val_loss: 5.9588\n",
      "Epoch 160/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2140 - val_loss: 5.9369\n",
      "Epoch 161/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5932 - val_loss: 5.9165\n",
      "Epoch 162/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3982 - val_loss: 5.9165\n",
      "Epoch 163/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3440 - val_loss: 5.9204\n",
      "Epoch 164/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4537 - val_loss: 5.9510\n",
      "Epoch 165/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4140 - val_loss: 5.9564\n",
      "Epoch 166/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4624 - val_loss: 5.9588\n",
      "Epoch 167/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4807 - val_loss: 5.9540\n",
      "Epoch 168/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1606 - val_loss: 5.9063\n",
      "Epoch 169/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1857 - val_loss: 5.9028\n",
      "Epoch 170/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2306 - val_loss: 5.9013\n",
      "Epoch 171/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4825 - val_loss: 5.8747\n",
      "Epoch 172/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1466 - val_loss: 5.8524\n",
      "Epoch 173/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2828 - val_loss: 5.8417\n",
      "Epoch 174/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3946 - val_loss: 5.8766\n",
      "Epoch 175/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4732 - val_loss: 5.8727\n",
      "Epoch 176/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4669 - val_loss: 5.8507\n",
      "Epoch 177/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2617 - val_loss: 5.8401\n",
      "Epoch 178/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5382 - val_loss: 5.8455\n",
      "Epoch 179/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3785 - val_loss: 5.8464\n",
      "Epoch 180/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1951 - val_loss: 5.8775\n",
      "Epoch 181/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1343 - val_loss: 5.8901\n",
      "Epoch 182/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1313 - val_loss: 5.8892\n",
      "Epoch 183/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6625 - val_loss: 5.8661\n",
      "Epoch 184/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1382 - val_loss: 5.8785\n",
      "Epoch 185/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4101 - val_loss: 5.9068\n",
      "Epoch 186/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3651 - val_loss: 5.9373\n",
      "Epoch 187/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4287 - val_loss: 5.9338\n",
      "Epoch 188/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2903 - val_loss: 5.9201\n",
      "Epoch 189/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3401 - val_loss: 5.9038\n",
      "Epoch 190/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2331 - val_loss: 5.8610\n",
      "Epoch 191/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4373 - val_loss: 5.8122\n",
      "Epoch 192/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3146 - val_loss: 5.7938\n",
      "Epoch 193/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3231 - val_loss: 5.8130\n",
      "Epoch 194/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3467 - val_loss: 5.8568\n",
      "Epoch 195/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4688 - val_loss: 5.8585\n",
      "Epoch 196/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1836 - val_loss: 5.8610\n",
      "Epoch 197/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4051 - val_loss: 5.8274\n",
      "Epoch 198/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3862 - val_loss: 5.8318\n",
      "Epoch 199/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1785 - val_loss: 5.8023\n",
      "Epoch 200/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4316 - val_loss: 5.7902\n",
      "Epoch 201/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2296 - val_loss: 5.7894\n",
      "Epoch 202/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5841 - val_loss: 5.8045\n",
      "Epoch 203/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2741 - val_loss: 5.8160\n",
      "Epoch 204/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2085 - val_loss: 5.7904\n",
      "Epoch 205/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2213 - val_loss: 5.8001\n",
      "Epoch 206/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6653 - val_loss: 5.7798\n",
      "Epoch 207/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4172 - val_loss: 5.7537\n",
      "Epoch 208/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4727 - val_loss: 5.7465\n",
      "Epoch 209/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3975 - val_loss: 5.7476\n",
      "Epoch 210/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4605 - val_loss: 5.7030\n",
      "Epoch 211/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3425 - val_loss: 5.6734\n",
      "Epoch 212/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3019 - val_loss: 5.6794\n",
      "Epoch 213/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2223 - val_loss: 5.6973\n",
      "Epoch 214/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1344 - val_loss: 5.7122\n",
      "Epoch 215/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3729 - val_loss: 5.7411\n",
      "Epoch 216/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3548 - val_loss: 5.7127\n",
      "Epoch 217/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2934 - val_loss: 5.6625\n",
      "Epoch 218/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3161 - val_loss: 5.6487\n",
      "Epoch 219/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2985 - val_loss: 5.7033\n",
      "Epoch 220/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4183 - val_loss: 5.7587\n",
      "Epoch 221/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0801 - val_loss: 5.7762\n",
      "Epoch 222/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3912 - val_loss: 5.7793\n",
      "Epoch 223/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1941 - val_loss: 5.7367\n",
      "Epoch 224/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4876 - val_loss: 5.6919\n",
      "Epoch 225/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2373 - val_loss: 5.6487\n",
      "Epoch 226/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3960 - val_loss: 5.6353\n",
      "Epoch 227/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2448 - val_loss: 5.6629\n",
      "Epoch 228/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3385 - val_loss: 5.7223\n",
      "Epoch 229/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2611 - val_loss: 5.7030\n",
      "Epoch 230/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1182 - val_loss: 5.6768\n",
      "Epoch 231/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3694 - val_loss: 5.6579\n",
      "Epoch 232/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3225 - val_loss: 5.6246\n",
      "Epoch 233/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4018 - val_loss: 5.6009\n",
      "Epoch 234/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2040 - val_loss: 5.5915\n",
      "Epoch 235/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1256 - val_loss: 5.6635\n",
      "Epoch 236/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3481 - val_loss: 5.7296\n",
      "Epoch 237/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1493 - val_loss: 5.7459\n",
      "Epoch 238/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3073 - val_loss: 5.7041\n",
      "Epoch 239/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3632 - val_loss: 5.6502\n",
      "Epoch 240/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4048 - val_loss: 5.6441\n",
      "Epoch 241/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4077 - val_loss: 5.6652\n",
      "Epoch 242/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3656 - val_loss: 5.6707\n",
      "Epoch 243/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9761 - val_loss: 5.6648\n",
      "Epoch 244/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4016 - val_loss: 5.6495\n",
      "Epoch 245/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9573 - val_loss: 5.6675\n",
      "Epoch 246/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0099 - val_loss: 5.6687\n",
      "Epoch 247/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1389 - val_loss: 5.6766\n",
      "Epoch 248/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5038 - val_loss: 5.6466\n",
      "Epoch 249/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0693 - val_loss: 5.6241\n",
      "Epoch 250/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5326 - val_loss: 5.6233\n",
      "Epoch 251/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0033 - val_loss: 5.6477\n",
      "Epoch 252/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1225 - val_loss: 5.6601\n",
      "Epoch 253/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0355 - val_loss: 5.6716\n",
      "Epoch 254/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1271 - val_loss: 5.7343\n",
      "Epoch 255/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0774 - val_loss: 5.7121\n",
      "Epoch 256/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2590 - val_loss: 5.7004\n",
      "Epoch 257/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1482 - val_loss: 5.6704\n",
      "Epoch 258/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8828 - val_loss: 5.6657\n",
      "Epoch 259/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2388 - val_loss: 5.7058\n",
      "Epoch 260/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9491 - val_loss: 5.7775\n",
      "Epoch 261/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0996 - val_loss: 5.7819\n",
      "Epoch 262/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1631 - val_loss: 5.6863\n",
      "Epoch 263/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3482 - val_loss: 5.6168\n",
      "Epoch 264/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5249 - val_loss: 5.5793\n",
      "Epoch 265/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3001 - val_loss: 5.5908\n",
      "Epoch 266/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1283 - val_loss: 5.6044\n",
      "Epoch 267/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1374 - val_loss: 5.6277\n",
      "Epoch 268/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0885 - val_loss: 5.6321\n",
      "Epoch 269/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2086 - val_loss: 5.6653\n",
      "Epoch 270/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1951 - val_loss: 5.7175\n",
      "Epoch 271/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1891 - val_loss: 5.6957\n",
      "Epoch 272/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1730 - val_loss: 5.6534\n",
      "Epoch 273/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2212 - val_loss: 5.6093\n",
      "Epoch 274/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1729 - val_loss: 5.5625\n",
      "Epoch 275/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1223 - val_loss: 5.5304\n",
      "Epoch 276/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3638 - val_loss: 5.5418\n",
      "Epoch 277/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9971 - val_loss: 5.5530\n",
      "Epoch 278/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8693 - val_loss: 5.5475\n",
      "Epoch 279/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4111 - val_loss: 5.5200\n",
      "Epoch 280/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2856 - val_loss: 5.4871\n",
      "Epoch 281/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2566 - val_loss: 5.5063\n",
      "Epoch 282/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4658 - val_loss: 5.5412\n",
      "Epoch 283/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2390 - val_loss: 5.5476\n",
      "Epoch 284/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0017 - val_loss: 5.5596\n",
      "Epoch 285/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0018 - val_loss: 5.5155\n",
      "Epoch 286/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0355 - val_loss: 5.5005\n",
      "Epoch 287/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1115 - val_loss: 5.4846\n",
      "Epoch 288/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1544 - val_loss: 5.4775\n",
      "Epoch 289/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3425 - val_loss: 5.5210\n",
      "Epoch 290/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3267 - val_loss: 5.5349\n",
      "Epoch 291/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2691 - val_loss: 5.4990\n",
      "Epoch 292/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5850 - val_loss: 5.4652\n",
      "Epoch 293/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0538 - val_loss: 5.4633\n",
      "Epoch 294/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1474 - val_loss: 5.4785\n",
      "Epoch 295/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4047 - val_loss: 5.5098\n",
      "Epoch 296/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0000 - val_loss: 5.5160\n",
      "Epoch 297/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3231 - val_loss: 5.4969\n",
      "Epoch 298/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1473 - val_loss: 5.4801\n",
      "Epoch 299/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6627 - val_loss: 5.4580\n",
      "Epoch 300/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9723 - val_loss: 5.4931\n",
      "Epoch 301/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9930 - val_loss: 5.5014\n",
      "Epoch 302/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7957 - val_loss: 5.4941\n",
      "Epoch 303/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0296 - val_loss: 5.4994\n",
      "Epoch 304/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2743 - val_loss: 5.4842\n",
      "Epoch 305/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4356 - val_loss: 5.4816\n",
      "Epoch 306/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0314 - val_loss: 5.4747\n",
      "Epoch 307/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9424 - val_loss: 5.4713\n",
      "Epoch 308/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3870 - val_loss: 5.4753\n",
      "Epoch 309/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1756 - val_loss: 5.4818\n",
      "Epoch 310/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0623 - val_loss: 5.4847\n",
      "Epoch 311/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1962 - val_loss: 5.4561\n",
      "Epoch 312/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1302 - val_loss: 5.4502\n",
      "Epoch 313/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1100 - val_loss: 5.4486\n",
      "Epoch 314/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9994 - val_loss: 5.5196\n",
      "Epoch 315/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0465 - val_loss: 5.5071\n",
      "Epoch 316/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9516 - val_loss: 5.4720\n",
      "Epoch 317/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2782 - val_loss: 5.4508\n",
      "Epoch 318/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1204 - val_loss: 5.4619\n",
      "Epoch 319/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9684 - val_loss: 5.4658\n",
      "Epoch 320/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1106 - val_loss: 5.4873\n",
      "Epoch 321/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1769 - val_loss: 5.4850\n",
      "Epoch 322/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0500 - val_loss: 5.4504\n",
      "Epoch 323/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1598 - val_loss: 5.4418\n",
      "Epoch 324/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4622 - val_loss: 5.4531\n",
      "Epoch 325/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3417 - val_loss: 5.4432\n",
      "Epoch 326/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8675 - val_loss: 5.4271\n",
      "Epoch 327/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.2160 - val_loss: 5.4450\n",
      "Epoch 328/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2312 - val_loss: 5.5034\n",
      "Epoch 329/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8290 - val_loss: 5.4981\n",
      "Epoch 330/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1024 - val_loss: 5.4782\n",
      "Epoch 331/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0627 - val_loss: 5.4612\n",
      "Epoch 332/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9836 - val_loss: 5.4472\n",
      "Epoch 333/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0061 - val_loss: 5.4535\n",
      "Epoch 334/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8164 - val_loss: 5.4557\n",
      "Epoch 335/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1223 - val_loss: 5.4591\n",
      "Epoch 336/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1365 - val_loss: 5.4715\n",
      "Epoch 337/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8937 - val_loss: 5.5112\n",
      "Epoch 338/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1136 - val_loss: 5.5527\n",
      "Epoch 339/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2134 - val_loss: 5.5360\n",
      "Epoch 340/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1445 - val_loss: 5.4961\n",
      "Epoch 341/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0805 - val_loss: 5.4657\n",
      "Epoch 342/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3296 - val_loss: 5.4576\n",
      "Epoch 343/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1883 - val_loss: 5.4872\n",
      "Epoch 344/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1819 - val_loss: 5.5189\n",
      "Epoch 345/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2742 - val_loss: 5.5373\n",
      "Epoch 346/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1121 - val_loss: 5.4890\n",
      "Epoch 347/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8570 - val_loss: 5.4657\n",
      "Epoch 348/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3070 - val_loss: 5.4580\n",
      "Epoch 349/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9796 - val_loss: 5.4284\n",
      "Epoch 350/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9528 - val_loss: 5.4080\n",
      "Epoch 351/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1007 - val_loss: 5.3919\n",
      "Epoch 352/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2451 - val_loss: 5.4192\n",
      "Epoch 353/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3252 - val_loss: 5.4406\n",
      "Epoch 354/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1515 - val_loss: 5.4428\n",
      "Epoch 355/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0285 - val_loss: 5.4441\n",
      "Epoch 356/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2736 - val_loss: 5.4154\n",
      "Epoch 357/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3008 - val_loss: 5.4014\n",
      "Epoch 358/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2171 - val_loss: 5.3986\n",
      "Epoch 359/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1225 - val_loss: 5.3921\n",
      "Epoch 360/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1718 - val_loss: 5.4228\n",
      "Epoch 361/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3617 - val_loss: 5.4228\n",
      "Epoch 362/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1428 - val_loss: 5.4017\n",
      "Epoch 363/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1563 - val_loss: 5.4045\n",
      "Epoch 364/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4346 - val_loss: 5.3988\n",
      "Epoch 365/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1553 - val_loss: 5.4224\n",
      "Epoch 366/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9246 - val_loss: 5.4436\n",
      "Epoch 367/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8749 - val_loss: 5.4443\n",
      "Epoch 368/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2636 - val_loss: 5.4563\n",
      "Epoch 369/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0426 - val_loss: 5.4538\n",
      "Epoch 370/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0989 - val_loss: 5.4422\n",
      "Epoch 371/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0895 - val_loss: 5.4355\n",
      "Epoch 372/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1284 - val_loss: 5.4165\n",
      "Epoch 373/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1085 - val_loss: 5.4094\n",
      "Epoch 374/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8739 - val_loss: 5.4172\n",
      "Epoch 375/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9800 - val_loss: 5.4186\n",
      "Epoch 376/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8856 - val_loss: 5.4281\n",
      "Epoch 377/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9547 - val_loss: 5.4242\n",
      "Epoch 378/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0638 - val_loss: 5.3971\n",
      "Epoch 379/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4310 - val_loss: 5.3763\n",
      "Epoch 380/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0246 - val_loss: 5.3738\n",
      "Epoch 381/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1274 - val_loss: 5.3757\n",
      "Epoch 382/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2822 - val_loss: 5.3546\n",
      "Epoch 383/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2756 - val_loss: 5.3377\n",
      "Epoch 384/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9610 - val_loss: 5.3272\n",
      "Epoch 385/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0331 - val_loss: 5.3139\n",
      "Epoch 386/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0562 - val_loss: 5.3017\n",
      "Epoch 387/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2151 - val_loss: 5.3107\n",
      "Epoch 388/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1991 - val_loss: 5.3233\n",
      "Epoch 389/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0229 - val_loss: 5.3393\n",
      "Epoch 390/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1549 - val_loss: 5.3383\n",
      "Epoch 391/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9067 - val_loss: 5.3501\n",
      "Epoch 392/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0366 - val_loss: 5.3741\n",
      "Epoch 393/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9116 - val_loss: 5.3935\n",
      "Epoch 394/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1361 - val_loss: 5.3738\n",
      "Epoch 395/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0623 - val_loss: 5.3076\n",
      "Epoch 396/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2892 - val_loss: 5.3014\n",
      "Epoch 397/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9887 - val_loss: 5.2883\n",
      "Epoch 398/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3800 - val_loss: 5.3305\n",
      "Epoch 399/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1695 - val_loss: 5.3612\n",
      "Epoch 400/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9123 - val_loss: 5.3891\n",
      "Epoch 401/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9253 - val_loss: 5.4307\n",
      "Epoch 402/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9542 - val_loss: 5.4570\n",
      "Epoch 403/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0868 - val_loss: 5.4465\n",
      "Epoch 404/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1196 - val_loss: 5.4518\n",
      "Epoch 405/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.0820 - val_loss: 5.4441\n",
      "Epoch 406/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1374 - val_loss: 5.4186\n",
      "Epoch 407/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.3401 - val_loss: 5.3739\n",
      "Epoch 408/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4767 - val_loss: 5.3319\n",
      "Epoch 409/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.0876 - val_loss: 5.3478\n",
      "Epoch 410/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2131 - val_loss: 5.3799\n",
      "Epoch 411/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8432 - val_loss: 5.3920\n",
      "Epoch 412/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1506 - val_loss: 5.3708\n",
      "Epoch 413/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0160 - val_loss: 5.3569\n",
      "Epoch 414/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9067 - val_loss: 5.3846\n",
      "Epoch 415/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1529 - val_loss: 5.3462\n",
      "Epoch 416/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1316 - val_loss: 5.3161\n",
      "Epoch 417/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9361 - val_loss: 5.3154\n",
      "Epoch 418/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4136 - val_loss: 5.3402\n",
      "Epoch 419/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2039 - val_loss: 5.3529\n",
      "Epoch 420/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3221 - val_loss: 5.3215\n",
      "Epoch 421/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9355 - val_loss: 5.3083\n",
      "Epoch 422/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9184 - val_loss: 5.3602\n",
      "Epoch 423/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0365 - val_loss: 5.4047\n",
      "Epoch 424/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8865 - val_loss: 5.4033\n",
      "Epoch 425/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0146 - val_loss: 5.3916\n",
      "Epoch 426/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0548 - val_loss: 5.3729\n",
      "Epoch 427/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1430 - val_loss: 5.3787\n",
      "Epoch 428/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1012 - val_loss: 5.3842\n",
      "Epoch 429/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2057 - val_loss: 5.3573\n",
      "Epoch 430/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9769 - val_loss: 5.3413\n",
      "Epoch 431/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1931 - val_loss: 5.3649\n",
      "Epoch 432/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0278 - val_loss: 5.3409\n",
      "Epoch 433/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0427 - val_loss: 5.3094\n",
      "Epoch 434/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9973 - val_loss: 5.2967\n",
      "Epoch 435/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0480 - val_loss: 5.2847\n",
      "Epoch 436/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2438 - val_loss: 5.2927\n",
      "Epoch 437/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3938 - val_loss: 5.3293\n",
      "Epoch 438/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0328 - val_loss: 5.3576\n",
      "Epoch 439/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0365 - val_loss: 5.4023\n",
      "Epoch 440/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0986 - val_loss: 5.4677\n",
      "Epoch 441/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0988 - val_loss: 5.4601\n",
      "Epoch 442/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0313 - val_loss: 5.4532\n",
      "Epoch 443/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4159 - val_loss: 5.4515\n",
      "Epoch 444/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9663 - val_loss: 5.4326\n",
      "Epoch 445/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9643 - val_loss: 5.4353\n",
      "Epoch 446/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7617 - val_loss: 5.4140\n",
      "Epoch 447/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9247 - val_loss: 5.3889\n",
      "Epoch 448/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1287 - val_loss: 5.3922\n",
      "Epoch 449/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9990 - val_loss: 5.3545\n",
      "Epoch 450/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9629 - val_loss: 5.3692\n",
      "Epoch 451/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9474 - val_loss: 5.3553\n",
      "Epoch 452/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0970 - val_loss: 5.3529\n",
      "Epoch 453/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9226 - val_loss: 5.3424\n",
      "Epoch 454/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1295 - val_loss: 5.3353\n",
      "Epoch 455/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8082 - val_loss: 5.2834\n",
      "Epoch 456/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8505 - val_loss: 5.2506\n",
      "Epoch 457/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1928 - val_loss: 5.2146\n",
      "Epoch 458/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9801 - val_loss: 5.2153\n",
      "Epoch 459/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0023 - val_loss: 5.2517\n",
      "Epoch 460/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0324 - val_loss: 5.2969\n",
      "Epoch 461/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0640 - val_loss: 5.3048\n",
      "Epoch 462/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2476 - val_loss: 5.2816\n",
      "Epoch 463/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8681 - val_loss: 5.2782\n",
      "Epoch 464/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8924 - val_loss: 5.3005\n",
      "Epoch 465/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0025 - val_loss: 5.3280\n",
      "Epoch 466/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8968 - val_loss: 5.2996\n",
      "Epoch 467/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2430 - val_loss: 5.2871\n",
      "Epoch 468/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0253 - val_loss: 5.3109\n",
      "Epoch 469/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7583 - val_loss: 5.3156\n",
      "Epoch 470/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8182 - val_loss: 5.2889\n",
      "Epoch 471/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1936 - val_loss: 5.2649\n",
      "Epoch 472/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7198 - val_loss: 5.2825\n",
      "Epoch 473/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2506 - val_loss: 5.2813\n",
      "Epoch 474/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7463 - val_loss: 5.2562\n",
      "Epoch 475/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1064 - val_loss: 5.2356\n",
      "Epoch 476/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8688 - val_loss: 5.2067\n",
      "Epoch 477/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0672 - val_loss: 5.1827\n",
      "Epoch 478/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0008 - val_loss: 5.1592\n",
      "Epoch 479/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1370 - val_loss: 5.1539\n",
      "Epoch 480/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0450 - val_loss: 5.1831\n",
      "Epoch 481/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0060 - val_loss: 5.2039\n",
      "Epoch 482/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8298 - val_loss: 5.2204\n",
      "Epoch 483/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9495 - val_loss: 5.2201\n",
      "Epoch 484/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8166 - val_loss: 5.1823\n",
      "Epoch 485/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0481 - val_loss: 5.1617\n",
      "Epoch 486/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4347 - val_loss: 5.1774\n",
      "Epoch 487/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8458 - val_loss: 5.1750\n",
      "Epoch 488/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2282 - val_loss: 5.1823\n",
      "Epoch 489/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0132 - val_loss: 5.1654\n",
      "Epoch 490/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7992 - val_loss: 5.1769\n",
      "Epoch 491/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1490 - val_loss: 5.2363\n",
      "Epoch 492/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0107 - val_loss: 5.2580\n",
      "Epoch 493/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8336 - val_loss: 5.2676\n",
      "Epoch 494/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1304 - val_loss: 5.2430\n",
      "Epoch 495/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7913 - val_loss: 5.2084\n",
      "Epoch 496/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9258 - val_loss: 5.1906\n",
      "Epoch 497/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0584 - val_loss: 5.1951\n",
      "Epoch 498/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7232 - val_loss: 5.2482\n",
      "Epoch 499/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0485 - val_loss: 5.2933\n",
      "Epoch 500/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1926 - val_loss: 5.2666\n",
      "Epoch 501/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0479 - val_loss: 5.2497\n",
      "Epoch 502/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8566 - val_loss: 5.2575\n",
      "Epoch 503/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8146 - val_loss: 5.2662\n",
      "Epoch 504/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1568 - val_loss: 5.2540\n",
      "Epoch 505/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9802 - val_loss: 5.2452\n",
      "Epoch 506/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9442 - val_loss: 5.2004\n",
      "Epoch 507/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.1081 - val_loss: 5.2246\n",
      "Epoch 508/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2423 - val_loss: 5.2209\n",
      "Epoch 509/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7143 - val_loss: 5.1736\n",
      "Epoch 510/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0752 - val_loss: 5.1638\n",
      "Epoch 511/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9451 - val_loss: 5.1751\n",
      "Epoch 512/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9674 - val_loss: 5.1699\n",
      "Epoch 513/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9985 - val_loss: 5.1877\n",
      "Epoch 514/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1834 - val_loss: 5.2144\n",
      "Epoch 515/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1001 - val_loss: 5.2287\n",
      "Epoch 516/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1462 - val_loss: 5.2384\n",
      "Epoch 517/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8477 - val_loss: 5.2645\n",
      "Epoch 518/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0824 - val_loss: 5.2595\n",
      "Epoch 519/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0436 - val_loss: 5.2605\n",
      "Epoch 520/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9516 - val_loss: 5.2370\n",
      "Epoch 521/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1494 - val_loss: 5.2147\n",
      "Epoch 522/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2785 - val_loss: 5.2112\n",
      "Epoch 523/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1738 - val_loss: 5.1923\n",
      "Epoch 524/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6599 - val_loss: 5.2068\n",
      "Epoch 525/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8267 - val_loss: 5.1984\n",
      "Epoch 526/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8979 - val_loss: 5.2244\n",
      "Epoch 527/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9214 - val_loss: 5.2704\n",
      "Epoch 528/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2287 - val_loss: 5.3050\n",
      "Epoch 529/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9035 - val_loss: 5.3265\n",
      "Epoch 530/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9272 - val_loss: 5.3453\n",
      "Epoch 531/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9680 - val_loss: 5.3349\n",
      "Epoch 532/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1168 - val_loss: 5.3383\n",
      "Epoch 533/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8214 - val_loss: 5.3193\n",
      "Epoch 534/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8941 - val_loss: 5.2914\n",
      "Epoch 535/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9500 - val_loss: 5.2390\n",
      "Epoch 536/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1208 - val_loss: 5.1516\n",
      "Epoch 537/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9249 - val_loss: 5.1011\n",
      "Epoch 538/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9591 - val_loss: 5.1115\n",
      "Epoch 539/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9377 - val_loss: 5.1457\n",
      "Epoch 540/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8328 - val_loss: 5.1558\n",
      "Epoch 541/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0275 - val_loss: 5.1979\n",
      "Epoch 542/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0401 - val_loss: 5.2171\n",
      "Epoch 543/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1592 - val_loss: 5.1701\n",
      "Epoch 544/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9686 - val_loss: 5.1013\n",
      "Epoch 545/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8255 - val_loss: 5.1133\n",
      "Epoch 546/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8573 - val_loss: 5.1074\n",
      "Epoch 547/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9297 - val_loss: 5.1195\n",
      "Epoch 548/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7767 - val_loss: 5.1432\n",
      "Epoch 549/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0575 - val_loss: 5.1663\n",
      "Epoch 550/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0528 - val_loss: 5.1645\n",
      "Epoch 551/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1491 - val_loss: 5.1715\n",
      "Epoch 552/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0380 - val_loss: 5.1773\n",
      "Epoch 553/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9098 - val_loss: 5.2141\n",
      "Epoch 554/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8625 - val_loss: 5.2179\n",
      "Epoch 555/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8289 - val_loss: 5.2102\n",
      "Epoch 556/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9714 - val_loss: 5.1992\n",
      "Epoch 557/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9319 - val_loss: 5.2115\n",
      "Epoch 558/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8775 - val_loss: 5.1865\n",
      "Epoch 559/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0423 - val_loss: 5.1735\n",
      "Epoch 560/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9332 - val_loss: 5.1448\n",
      "Epoch 561/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6286 - val_loss: 5.1242\n",
      "Epoch 562/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2266 - val_loss: 5.1121\n",
      "Epoch 563/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9400 - val_loss: 5.1062\n",
      "Epoch 564/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1072 - val_loss: 5.1297\n",
      "Epoch 565/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9227 - val_loss: 5.1625\n",
      "Epoch 566/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1229 - val_loss: 5.1894\n",
      "Epoch 567/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0172 - val_loss: 5.1817\n",
      "Epoch 568/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0799 - val_loss: 5.1910\n",
      "Epoch 569/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1570 - val_loss: 5.1868\n",
      "Epoch 570/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1250 - val_loss: 5.1655\n",
      "Epoch 571/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8613 - val_loss: 5.1272\n",
      "Epoch 572/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0483 - val_loss: 5.1195\n",
      "Epoch 573/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0523 - val_loss: 5.1048\n",
      "Epoch 574/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1042 - val_loss: 5.1245\n",
      "Epoch 575/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9587 - val_loss: 5.1232\n",
      "Epoch 576/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0430 - val_loss: 5.0956\n",
      "Epoch 577/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0750 - val_loss: 5.0930\n",
      "Epoch 578/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0410 - val_loss: 5.0645\n",
      "Epoch 579/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9990 - val_loss: 5.1033\n",
      "Epoch 580/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8261 - val_loss: 5.1118\n",
      "Epoch 581/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9894 - val_loss: 5.0924\n",
      "Epoch 582/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0094 - val_loss: 5.0745\n",
      "Epoch 583/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0195 - val_loss: 5.0278\n",
      "Epoch 584/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1059 - val_loss: 5.0332\n",
      "Epoch 585/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1038 - val_loss: 5.0479\n",
      "Epoch 586/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8061 - val_loss: 5.0287\n",
      "Epoch 587/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9772 - val_loss: 5.0176\n",
      "Epoch 588/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9976 - val_loss: 4.9971\n",
      "Epoch 589/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8918 - val_loss: 4.9868\n",
      "Epoch 590/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8529 - val_loss: 5.0182\n",
      "Epoch 591/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8020 - val_loss: 5.1005\n",
      "Epoch 592/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9780 - val_loss: 5.1528\n",
      "Epoch 593/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9131 - val_loss: 5.1567\n",
      "Epoch 594/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9289 - val_loss: 5.1152\n",
      "Epoch 595/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0469 - val_loss: 5.0647\n",
      "Epoch 596/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1084 - val_loss: 5.0603\n",
      "Epoch 597/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8273 - val_loss: 5.0623\n",
      "Epoch 598/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9586 - val_loss: 5.0629\n",
      "Epoch 599/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8520 - val_loss: 5.0918\n",
      "Epoch 600/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9056 - val_loss: 5.0645\n",
      "Epoch 601/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6957 - val_loss: 5.0301\n",
      "Epoch 602/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8744 - val_loss: 5.0247\n",
      "Epoch 603/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9120 - val_loss: 5.0613\n",
      "Epoch 604/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8408 - val_loss: 5.0784\n",
      "Epoch 605/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9383 - val_loss: 5.0517\n",
      "Epoch 606/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9943 - val_loss: 5.0487\n",
      "Epoch 607/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9867 - val_loss: 5.0366\n",
      "Epoch 608/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0585 - val_loss: 5.0309\n",
      "Epoch 609/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0354 - val_loss: 5.0370\n",
      "Epoch 610/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8423 - val_loss: 5.0585\n",
      "Epoch 611/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8260 - val_loss: 5.1017\n",
      "Epoch 612/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9497 - val_loss: 5.0697\n",
      "Epoch 613/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9308 - val_loss: 5.0470\n",
      "Epoch 614/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1110 - val_loss: 5.0706\n",
      "Epoch 615/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9782 - val_loss: 5.0822\n",
      "Epoch 616/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9553 - val_loss: 5.0973\n",
      "Epoch 617/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9147 - val_loss: 5.1146\n",
      "Epoch 618/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0234 - val_loss: 5.0835\n",
      "Epoch 619/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8374 - val_loss: 5.0722\n",
      "Epoch 620/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8337 - val_loss: 5.0257\n",
      "Epoch 621/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8169 - val_loss: 5.0338\n",
      "Epoch 622/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8859 - val_loss: 5.0750\n",
      "Epoch 623/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8340 - val_loss: 5.0625\n",
      "Epoch 624/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5088 - val_loss: 5.0268\n",
      "Epoch 625/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0637 - val_loss: 5.0238\n",
      "Epoch 626/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7643 - val_loss: 5.0123\n",
      "Epoch 627/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8508 - val_loss: 5.0357\n",
      "Epoch 628/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0387 - val_loss: 5.0320\n",
      "Epoch 629/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9963 - val_loss: 5.0173\n",
      "Epoch 630/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1021 - val_loss: 4.9996\n",
      "Epoch 631/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2172 - val_loss: 5.0590\n",
      "Epoch 632/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9333 - val_loss: 5.0857\n",
      "Epoch 633/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8406 - val_loss: 5.1000\n",
      "Epoch 634/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9769 - val_loss: 5.1284\n",
      "Epoch 635/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9213 - val_loss: 5.1263\n",
      "Epoch 636/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0516 - val_loss: 5.1077\n",
      "Epoch 637/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8649 - val_loss: 5.0491\n",
      "Epoch 638/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1552 - val_loss: 5.0394\n",
      "Epoch 639/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6709 - val_loss: 5.0223\n",
      "Epoch 640/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0975 - val_loss: 5.0274\n",
      "Epoch 641/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7941 - val_loss: 5.0503\n",
      "Epoch 642/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9608 - val_loss: 5.0606\n",
      "Epoch 643/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8425 - val_loss: 5.0466\n",
      "Epoch 644/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8245 - val_loss: 5.0231\n",
      "Epoch 645/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9228 - val_loss: 5.0205\n",
      "Epoch 646/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8338 - val_loss: 5.0296\n",
      "Epoch 647/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8828 - val_loss: 5.0614\n",
      "Epoch 648/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9230 - val_loss: 5.0849\n",
      "Epoch 649/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8474 - val_loss: 5.1063\n",
      "Epoch 650/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6870 - val_loss: 5.0869\n",
      "Epoch 651/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8027 - val_loss: 5.0752\n",
      "Epoch 652/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8963 - val_loss: 5.0661\n",
      "Epoch 653/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7538 - val_loss: 5.0792\n",
      "Epoch 654/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7915 - val_loss: 5.0884\n",
      "Epoch 655/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0074 - val_loss: 5.0720\n",
      "Epoch 656/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0824 - val_loss: 5.0534\n",
      "Epoch 657/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9230 - val_loss: 4.9860\n",
      "Epoch 658/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7268 - val_loss: 4.9903\n",
      "Epoch 659/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6272 - val_loss: 5.0062\n",
      "Epoch 660/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7985 - val_loss: 5.0166\n",
      "Epoch 661/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8588 - val_loss: 5.0324\n",
      "Epoch 662/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7992 - val_loss: 5.0402\n",
      "Epoch 663/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9386 - val_loss: 5.0393\n",
      "Epoch 664/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7044 - val_loss: 5.0675\n",
      "Epoch 665/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0124 - val_loss: 5.0602\n",
      "Epoch 666/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0912 - val_loss: 5.0350\n",
      "Epoch 667/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7737 - val_loss: 5.0411\n",
      "Epoch 668/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1253 - val_loss: 5.0455\n",
      "Epoch 669/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9340 - val_loss: 4.9860\n",
      "Epoch 670/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7990 - val_loss: 4.9401\n",
      "Epoch 671/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8741 - val_loss: 4.9947\n",
      "Epoch 672/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9729 - val_loss: 5.0147\n",
      "Epoch 673/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0407 - val_loss: 5.0277\n",
      "Epoch 674/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8342 - val_loss: 5.0105\n",
      "Epoch 675/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8218 - val_loss: 4.9778\n",
      "Epoch 676/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1052 - val_loss: 4.9492\n",
      "Epoch 677/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7996 - val_loss: 4.9283\n",
      "Epoch 678/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9288 - val_loss: 4.9202\n",
      "Epoch 679/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8299 - val_loss: 4.9403\n",
      "Epoch 680/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9469 - val_loss: 4.9640\n",
      "Epoch 681/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9918 - val_loss: 4.9586\n",
      "Epoch 682/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7389 - val_loss: 4.9388\n",
      "Epoch 683/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9331 - val_loss: 4.9324\n",
      "Epoch 684/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8800 - val_loss: 4.9596\n",
      "Epoch 685/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7238 - val_loss: 5.0069\n",
      "Epoch 686/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9396 - val_loss: 5.0414\n",
      "Epoch 687/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8304 - val_loss: 5.0517\n",
      "Epoch 688/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6138 - val_loss: 5.0200\n",
      "Epoch 689/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8086 - val_loss: 4.9936\n",
      "Epoch 690/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9066 - val_loss: 5.0047\n",
      "Epoch 691/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7941 - val_loss: 5.0311\n",
      "Epoch 692/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7703 - val_loss: 5.0377\n",
      "Epoch 693/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5653 - val_loss: 5.0463\n",
      "Epoch 694/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7095 - val_loss: 4.9982\n",
      "Epoch 695/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7878 - val_loss: 4.9524\n",
      "Epoch 696/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6407 - val_loss: 4.9166\n",
      "Epoch 697/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9224 - val_loss: 4.9187\n",
      "Epoch 698/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7814 - val_loss: 4.9407\n",
      "Epoch 699/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9799 - val_loss: 4.9646\n",
      "Epoch 700/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9972 - val_loss: 4.9676\n",
      "Epoch 701/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2843 - val_loss: 4.9579\n",
      "Epoch 702/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8186 - val_loss: 4.9968\n",
      "Epoch 703/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9031 - val_loss: 5.0063\n",
      "Epoch 704/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8999 - val_loss: 4.9517\n",
      "Epoch 705/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7717 - val_loss: 4.9434\n",
      "Epoch 706/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6939 - val_loss: 4.9771\n",
      "Epoch 707/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7395 - val_loss: 4.9563\n",
      "Epoch 708/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7984 - val_loss: 4.9404\n",
      "Epoch 709/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8527 - val_loss: 4.9401\n",
      "Epoch 710/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6251 - val_loss: 4.9271\n",
      "Epoch 711/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9397 - val_loss: 4.9280\n",
      "Epoch 712/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8338 - val_loss: 4.9225\n",
      "Epoch 713/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6945 - val_loss: 4.9612\n",
      "Epoch 714/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8028 - val_loss: 4.9632\n",
      "Epoch 715/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2289 - val_loss: 4.9250\n",
      "Epoch 716/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9195 - val_loss: 4.9768\n",
      "Epoch 717/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8889 - val_loss: 4.9828\n",
      "Epoch 718/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6074 - val_loss: 5.0068\n",
      "Epoch 719/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8032 - val_loss: 4.9976\n",
      "Epoch 720/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7183 - val_loss: 4.9686\n",
      "Epoch 721/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8649 - val_loss: 4.9378\n",
      "Epoch 722/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8464 - val_loss: 4.9218\n",
      "Epoch 723/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0355 - val_loss: 4.9402\n",
      "Epoch 724/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8875 - val_loss: 4.9503\n",
      "Epoch 725/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6188 - val_loss: 4.9408\n",
      "Epoch 726/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0714 - val_loss: 4.9370\n",
      "Epoch 727/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6657 - val_loss: 4.9015\n",
      "Epoch 728/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6076 - val_loss: 4.8914\n",
      "Epoch 729/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9695 - val_loss: 4.8986\n",
      "Epoch 730/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7807 - val_loss: 4.8865\n",
      "Epoch 731/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9166 - val_loss: 4.8717\n",
      "Epoch 732/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8611 - val_loss: 4.8296\n",
      "Epoch 733/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8796 - val_loss: 4.8273\n",
      "Epoch 734/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8068 - val_loss: 4.8828\n",
      "Epoch 735/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6031 - val_loss: 4.9188\n",
      "Epoch 736/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6063 - val_loss: 4.9377\n",
      "Epoch 737/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5082 - val_loss: 4.9205\n",
      "Epoch 738/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7776 - val_loss: 4.9301\n",
      "Epoch 739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9963 - val_loss: 4.9304\n",
      "Epoch 740/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0259 - val_loss: 4.8774\n",
      "Epoch 741/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9166 - val_loss: 4.8081\n",
      "Epoch 742/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7009 - val_loss: 4.7660\n",
      "Epoch 743/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0380 - val_loss: 4.7631\n",
      "Epoch 744/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8140 - val_loss: 4.8139\n",
      "Epoch 745/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7569 - val_loss: 4.8719\n",
      "Epoch 746/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9320 - val_loss: 4.8789\n",
      "Epoch 747/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6304 - val_loss: 4.8883\n",
      "Epoch 748/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7371 - val_loss: 4.9574\n",
      "Epoch 749/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8353 - val_loss: 4.9298\n",
      "Epoch 750/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8516 - val_loss: 4.9025\n",
      "Epoch 751/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7193 - val_loss: 4.8858\n",
      "Epoch 752/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6653 - val_loss: 4.8664\n",
      "Epoch 753/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9208 - val_loss: 4.8446\n",
      "Epoch 754/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0165 - val_loss: 4.8302\n",
      "Epoch 755/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9185 - val_loss: 4.8358\n",
      "Epoch 756/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7800 - val_loss: 4.8369\n",
      "Epoch 757/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8795 - val_loss: 4.8305\n",
      "Epoch 758/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8708 - val_loss: 4.8003\n",
      "Epoch 759/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7836 - val_loss: 4.7908\n",
      "Epoch 760/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7257 - val_loss: 4.8616\n",
      "Epoch 761/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8041 - val_loss: 4.8840\n",
      "Epoch 762/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6974 - val_loss: 4.8722\n",
      "Epoch 763/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7791 - val_loss: 4.8846\n",
      "Epoch 764/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8732 - val_loss: 4.8814\n",
      "Epoch 765/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7199 - val_loss: 4.8890\n",
      "Epoch 766/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8188 - val_loss: 4.8866\n",
      "Epoch 767/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8035 - val_loss: 4.8500\n",
      "Epoch 768/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9826 - val_loss: 4.8387\n",
      "Epoch 769/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7622 - val_loss: 4.7969\n",
      "Epoch 770/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9290 - val_loss: 4.8193\n",
      "Epoch 771/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7069 - val_loss: 4.8207\n",
      "Epoch 772/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8515 - val_loss: 4.8167\n",
      "Epoch 773/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5491 - val_loss: 4.8022\n",
      "Epoch 774/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6515 - val_loss: 4.7808\n",
      "Epoch 775/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6225 - val_loss: 4.7897\n",
      "Epoch 776/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8826 - val_loss: 4.7965\n",
      "Epoch 777/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7167 - val_loss: 4.8130\n",
      "Epoch 778/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7519 - val_loss: 4.7834\n",
      "Epoch 779/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7643 - val_loss: 4.8164\n",
      "Epoch 780/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7499 - val_loss: 4.8567\n",
      "Epoch 781/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6944 - val_loss: 4.8753\n",
      "Epoch 782/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9357 - val_loss: 4.9079\n",
      "Epoch 783/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4640 - val_loss: 4.8933\n",
      "Epoch 784/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6943 - val_loss: 4.9131\n",
      "Epoch 785/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6812 - val_loss: 4.9363\n",
      "Epoch 786/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8705 - val_loss: 4.9344\n",
      "Epoch 787/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5223 - val_loss: 4.8894\n",
      "Epoch 788/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7189 - val_loss: 4.8646\n",
      "Epoch 789/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6082 - val_loss: 4.8289\n",
      "Epoch 790/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6978 - val_loss: 4.8476\n",
      "Epoch 791/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5853 - val_loss: 4.8153\n",
      "Epoch 792/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6488 - val_loss: 4.7907\n",
      "Epoch 793/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8052 - val_loss: 4.7965\n",
      "Epoch 794/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6533 - val_loss: 4.8100\n",
      "Epoch 795/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7901 - val_loss: 4.7727\n",
      "Epoch 796/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7437 - val_loss: 4.7592\n",
      "Epoch 797/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7279 - val_loss: 4.7541\n",
      "Epoch 798/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5687 - val_loss: 4.7590\n",
      "Epoch 799/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7642 - val_loss: 4.7559\n",
      "Epoch 800/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9561 - val_loss: 4.7538\n",
      "Epoch 801/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6398 - val_loss: 4.7826\n",
      "Epoch 802/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4421 - val_loss: 4.7912\n",
      "Epoch 803/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5271 - val_loss: 4.8043\n",
      "Epoch 804/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8840 - val_loss: 4.8008\n",
      "Epoch 805/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8365 - val_loss: 4.8238\n",
      "Epoch 806/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9210 - val_loss: 4.8215\n",
      "Epoch 807/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8522 - val_loss: 4.8200\n",
      "Epoch 808/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7266 - val_loss: 4.8305\n",
      "Epoch 809/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9202 - val_loss: 4.8040\n",
      "Epoch 810/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8880 - val_loss: 4.7810\n",
      "Epoch 811/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9205 - val_loss: 4.8291\n",
      "Epoch 812/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6492 - val_loss: 4.7992\n",
      "Epoch 813/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8437 - val_loss: 4.7622\n",
      "Epoch 814/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9257 - val_loss: 4.7588\n",
      "Epoch 815/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6684 - val_loss: 4.8027\n",
      "Epoch 816/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6251 - val_loss: 4.8150\n",
      "Epoch 817/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6657 - val_loss: 4.8148\n",
      "Epoch 818/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8000 - val_loss: 4.7989\n",
      "Epoch 819/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9021 - val_loss: 4.7658\n",
      "Epoch 820/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7062 - val_loss: 4.7901\n",
      "Epoch 821/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7366 - val_loss: 4.8333\n",
      "Epoch 822/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7932 - val_loss: 4.8951\n",
      "Epoch 823/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8768 - val_loss: 4.9079\n",
      "Epoch 824/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7908 - val_loss: 4.8567\n",
      "Epoch 825/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6367 - val_loss: 4.7577\n",
      "Epoch 826/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9836 - val_loss: 4.7336\n",
      "Epoch 827/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6274 - val_loss: 4.7349\n",
      "Epoch 828/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7344 - val_loss: 4.7841\n",
      "Epoch 829/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9717 - val_loss: 4.8383\n",
      "Epoch 830/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4699 - val_loss: 4.8710\n",
      "Epoch 831/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9014 - val_loss: 4.8813\n",
      "Epoch 832/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6843 - val_loss: 4.8521\n",
      "Epoch 833/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5740 - val_loss: 4.8367\n",
      "Epoch 834/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6003 - val_loss: 4.7899\n",
      "Epoch 835/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5024 - val_loss: 4.7606\n",
      "Epoch 836/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8910 - val_loss: 4.7858\n",
      "Epoch 837/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7237 - val_loss: 4.8179\n",
      "Epoch 838/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6874 - val_loss: 4.7722\n",
      "Epoch 839/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6250 - val_loss: 4.7596\n",
      "Epoch 840/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6300 - val_loss: 4.7270\n",
      "Epoch 841/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9284 - val_loss: 4.7139\n",
      "Epoch 842/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5072 - val_loss: 4.7312\n",
      "Epoch 843/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5554 - val_loss: 4.7792\n",
      "Epoch 844/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4947 - val_loss: 4.8072\n",
      "Epoch 845/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7196 - val_loss: 4.8271\n",
      "Epoch 846/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8103 - val_loss: 4.7975\n",
      "Epoch 847/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8684 - val_loss: 4.7517\n",
      "Epoch 848/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8924 - val_loss: 4.7031\n",
      "Epoch 849/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5852 - val_loss: 4.6584\n",
      "Epoch 850/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9636 - val_loss: 4.6824\n",
      "Epoch 851/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7205 - val_loss: 4.7540\n",
      "Epoch 852/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7204 - val_loss: 4.7853\n",
      "Epoch 853/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7211 - val_loss: 4.7597\n",
      "Epoch 854/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7080 - val_loss: 4.7693\n",
      "Epoch 855/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6326 - val_loss: 4.7885\n",
      "Epoch 856/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9843 - val_loss: 4.8418\n",
      "Epoch 857/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6054 - val_loss: 4.8284\n",
      "Epoch 858/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9007 - val_loss: 4.7645\n",
      "Epoch 859/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6254 - val_loss: 4.7638\n",
      "Epoch 860/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6537 - val_loss: 4.7312\n",
      "Epoch 861/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4730 - val_loss: 4.7383\n",
      "Epoch 862/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6470 - val_loss: 4.7526\n",
      "Epoch 863/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7915 - val_loss: 4.7713\n",
      "Epoch 864/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8542 - val_loss: 4.7763\n",
      "Epoch 865/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6669 - val_loss: 4.7842\n",
      "Epoch 866/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9188 - val_loss: 4.7660\n",
      "Epoch 867/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8548 - val_loss: 4.7382\n",
      "Epoch 868/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7743 - val_loss: 4.7590\n",
      "Epoch 869/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3895 - val_loss: 4.8135\n",
      "Epoch 870/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9413 - val_loss: 4.8362\n",
      "Epoch 871/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8398 - val_loss: 4.8013\n",
      "Epoch 872/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6174 - val_loss: 4.7696\n",
      "Epoch 873/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6262 - val_loss: 4.7739\n",
      "Epoch 874/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7431 - val_loss: 4.7166\n",
      "Epoch 875/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7081 - val_loss: 4.6754\n",
      "Epoch 876/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6581 - val_loss: 4.6925\n",
      "Epoch 877/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6810 - val_loss: 4.7266\n",
      "Epoch 878/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7140 - val_loss: 4.7929\n",
      "Epoch 879/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5385 - val_loss: 4.7822\n",
      "Epoch 880/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.7488 - val_loss: 4.7017\n",
      "Epoch 881/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7090 - val_loss: 4.6840\n",
      "Epoch 882/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9472 - val_loss: 4.7152\n",
      "Epoch 883/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6489 - val_loss: 4.7326\n",
      "Epoch 884/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8803 - val_loss: 4.7648\n",
      "Epoch 885/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3791 - val_loss: 4.7469\n",
      "Epoch 886/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7795 - val_loss: 4.7260\n",
      "Epoch 887/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7445 - val_loss: 4.6755\n",
      "Epoch 888/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8298 - val_loss: 4.7018\n",
      "Epoch 889/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6405 - val_loss: 4.7462\n",
      "Epoch 890/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0017 - val_loss: 4.6784\n",
      "Epoch 891/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6874 - val_loss: 4.7427\n",
      "Epoch 892/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5571 - val_loss: 4.7903\n",
      "Epoch 893/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6743 - val_loss: 4.7902\n",
      "Epoch 894/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9984 - val_loss: 4.7659\n",
      "Epoch 895/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0600 - val_loss: 4.7341\n",
      "Epoch 896/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5452 - val_loss: 4.7182\n",
      "Epoch 897/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9942 - val_loss: 4.7001\n",
      "Epoch 898/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6232 - val_loss: 4.6715\n",
      "Epoch 899/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8967 - val_loss: 4.7054\n",
      "Epoch 900/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6338 - val_loss: 4.6780\n",
      "Epoch 901/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5442 - val_loss: 4.6640\n",
      "Epoch 902/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6699 - val_loss: 4.6577\n",
      "Epoch 903/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7316 - val_loss: 4.6392\n",
      "Epoch 904/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6489 - val_loss: 4.5920\n",
      "Epoch 905/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8231 - val_loss: 4.5657\n",
      "Epoch 906/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7831 - val_loss: 4.6078\n",
      "Epoch 907/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2996 - val_loss: 4.6560\n",
      "Epoch 908/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6286 - val_loss: 4.6552\n",
      "Epoch 909/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6238 - val_loss: 4.6599\n",
      "Epoch 910/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6613 - val_loss: 4.6548\n",
      "Epoch 911/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5621 - val_loss: 4.6388\n",
      "Epoch 912/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7209 - val_loss: 4.6264\n",
      "Epoch 913/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4856 - val_loss: 4.6902\n",
      "Epoch 914/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4941 - val_loss: 4.6959\n",
      "Epoch 915/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7250 - val_loss: 4.7367\n",
      "Epoch 916/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6072 - val_loss: 4.7163\n",
      "Epoch 917/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4610 - val_loss: 4.7078\n",
      "Epoch 918/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6332 - val_loss: 4.7114\n",
      "Epoch 919/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8287 - val_loss: 4.7135\n",
      "Epoch 920/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4203 - val_loss: 4.6935\n",
      "Epoch 921/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6882 - val_loss: 4.7112\n",
      "Epoch 922/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6647 - val_loss: 4.7138\n",
      "Epoch 923/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5693 - val_loss: 4.6652\n",
      "Epoch 924/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7210 - val_loss: 4.7061\n",
      "Epoch 925/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7397 - val_loss: 4.6925\n",
      "Epoch 926/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6232 - val_loss: 4.7270\n",
      "Epoch 927/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5013 - val_loss: 4.6931\n",
      "Epoch 928/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6244 - val_loss: 4.5934\n",
      "Epoch 929/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7095 - val_loss: 4.5639\n",
      "Epoch 930/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5577 - val_loss: 4.6370\n",
      "Epoch 931/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7202 - val_loss: 4.6938\n",
      "Epoch 932/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6220 - val_loss: 4.6170\n",
      "Epoch 933/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8090 - val_loss: 4.6176\n",
      "Epoch 934/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6175 - val_loss: 4.6427\n",
      "Epoch 935/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9240 - val_loss: 4.6049\n",
      "Epoch 936/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7746 - val_loss: 4.5572\n",
      "Epoch 937/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5625 - val_loss: 4.5712\n",
      "Epoch 938/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6305 - val_loss: 4.5698\n",
      "Epoch 939/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4526 - val_loss: 4.5597\n",
      "Epoch 940/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4964 - val_loss: 4.5873\n",
      "Epoch 941/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7792 - val_loss: 4.5962\n",
      "Epoch 942/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7905 - val_loss: 4.7083\n",
      "Epoch 943/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6555 - val_loss: 4.7269\n",
      "Epoch 944/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7241 - val_loss: 4.6497\n",
      "Epoch 945/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6834 - val_loss: 4.5797\n",
      "Epoch 946/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5840 - val_loss: 4.5524\n",
      "Epoch 947/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6575 - val_loss: 4.5656\n",
      "Epoch 948/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7752 - val_loss: 4.5446\n",
      "Epoch 949/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6416 - val_loss: 4.5337\n",
      "Epoch 950/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3534 - val_loss: 4.5675\n",
      "Epoch 951/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7420 - val_loss: 4.6060\n",
      "Epoch 952/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7712 - val_loss: 4.5921\n",
      "Epoch 953/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6256 - val_loss: 4.5674\n",
      "Epoch 954/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6622 - val_loss: 4.5694\n",
      "Epoch 955/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6313 - val_loss: 4.5488\n",
      "Epoch 956/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7033 - val_loss: 4.5071\n",
      "Epoch 957/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8386 - val_loss: 4.5086\n",
      "Epoch 958/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5832 - val_loss: 4.5665\n",
      "Epoch 959/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6022 - val_loss: 4.5525\n",
      "Epoch 960/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4734 - val_loss: 4.5732\n",
      "Epoch 961/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4584 - val_loss: 4.5499\n",
      "Epoch 962/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6441 - val_loss: 4.5601\n",
      "Epoch 963/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8132 - val_loss: 4.5464\n",
      "Epoch 964/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6718 - val_loss: 4.5575\n",
      "Epoch 965/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5968 - val_loss: 4.5569\n",
      "Epoch 966/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6746 - val_loss: 4.5036\n",
      "Epoch 967/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7628 - val_loss: 4.4991\n",
      "Epoch 968/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6072 - val_loss: 4.5274\n",
      "Epoch 969/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5522 - val_loss: 4.5320\n",
      "Epoch 970/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7142 - val_loss: 4.5879\n",
      "Epoch 971/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7418 - val_loss: 4.6475\n",
      "Epoch 972/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6546 - val_loss: 4.6350\n",
      "Epoch 973/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6984 - val_loss: 4.5848\n",
      "Epoch 974/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4988 - val_loss: 4.5657\n",
      "Epoch 975/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7933 - val_loss: 4.5509\n",
      "Epoch 976/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8361 - val_loss: 4.5689\n",
      "Epoch 977/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3505 - val_loss: 4.5736\n",
      "Epoch 978/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4992 - val_loss: 4.5892\n",
      "Epoch 979/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7428 - val_loss: 4.5550\n",
      "Epoch 980/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5836 - val_loss: 4.6177\n",
      "Epoch 981/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3311 - val_loss: 4.6687\n",
      "Epoch 982/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7311 - val_loss: 4.6732\n",
      "Epoch 983/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5391 - val_loss: 4.6302\n",
      "Epoch 984/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7733 - val_loss: 4.5936\n",
      "Epoch 985/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8212 - val_loss: 4.5729\n",
      "Epoch 986/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5740 - val_loss: 4.5217\n",
      "Epoch 987/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5820 - val_loss: 4.5317\n",
      "Epoch 988/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8790 - val_loss: 4.5052\n",
      "Epoch 989/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6565 - val_loss: 4.4637\n",
      "Epoch 990/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6601 - val_loss: 4.4785\n",
      "Epoch 991/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3574 - val_loss: 4.5516\n",
      "Epoch 992/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3040 - val_loss: 4.5918\n",
      "Epoch 993/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5614 - val_loss: 4.5716\n",
      "Epoch 994/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6246 - val_loss: 4.5694\n",
      "Epoch 995/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5105 - val_loss: 4.5952\n",
      "Epoch 996/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4885 - val_loss: 4.5218\n",
      "Epoch 997/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4960 - val_loss: 4.4874\n",
      "Epoch 998/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7759 - val_loss: 4.5072\n",
      "Epoch 999/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7327 - val_loss: 4.5272\n",
      "Epoch 1000/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7937 - val_loss: 4.6082\n",
      "Epoch 1001/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7551 - val_loss: 4.6690\n",
      "Epoch 1002/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7882 - val_loss: 4.6380\n",
      "Epoch 1003/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6131 - val_loss: 4.6219\n",
      "Epoch 1004/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7698 - val_loss: 4.6435\n",
      "Epoch 1005/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6753 - val_loss: 4.6160\n",
      "Epoch 1006/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5066 - val_loss: 4.5683\n",
      "Epoch 1007/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5781 - val_loss: 4.5128\n",
      "Epoch 1008/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5330 - val_loss: 4.4653\n",
      "Epoch 1009/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8816 - val_loss: 4.4552\n",
      "Epoch 1010/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6951 - val_loss: 4.4995\n",
      "Epoch 1011/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6661 - val_loss: 4.4690\n",
      "Epoch 1012/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6769 - val_loss: 4.4513\n",
      "Epoch 1013/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7375 - val_loss: 4.4941\n",
      "Epoch 1014/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6109 - val_loss: 4.4764\n",
      "Epoch 1015/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6551 - val_loss: 4.4497\n",
      "Epoch 1016/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6711 - val_loss: 4.4466\n",
      "Epoch 1017/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3427 - val_loss: 4.4301\n",
      "Epoch 1018/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8144 - val_loss: 4.4573\n",
      "Epoch 1019/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6316 - val_loss: 4.4966\n",
      "Epoch 1020/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5521 - val_loss: 4.4732\n",
      "Epoch 1021/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5725 - val_loss: 4.4701\n",
      "Epoch 1022/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7590 - val_loss: 4.5094\n",
      "Epoch 1023/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6771 - val_loss: 4.5040\n",
      "Epoch 1024/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4259 - val_loss: 4.4444\n",
      "Epoch 1025/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6185 - val_loss: 4.5253\n",
      "Epoch 1026/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6611 - val_loss: 4.4983\n",
      "Epoch 1027/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3769 - val_loss: 4.4857\n",
      "Epoch 1028/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6307 - val_loss: 4.4906\n",
      "Epoch 1029/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5446 - val_loss: 4.4890\n",
      "Epoch 1030/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7377 - val_loss: 4.4862\n",
      "Epoch 1031/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9032 - val_loss: 4.4941\n",
      "Epoch 1032/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4134 - val_loss: 4.5438\n",
      "Epoch 1033/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6969 - val_loss: 4.5658\n",
      "Epoch 1034/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5853 - val_loss: 4.5342\n",
      "Epoch 1035/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6947 - val_loss: 4.4868\n",
      "Epoch 1036/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6293 - val_loss: 4.4393\n",
      "Epoch 1037/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4984 - val_loss: 4.4274\n",
      "Epoch 1038/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6164 - val_loss: 4.4401\n",
      "Epoch 1039/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7120 - val_loss: 4.4854\n",
      "Epoch 1040/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3848 - val_loss: 4.5327\n",
      "Epoch 1041/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5962 - val_loss: 4.5483\n",
      "Epoch 1042/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6835 - val_loss: 4.4871\n",
      "Epoch 1043/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6347 - val_loss: 4.4182\n",
      "Epoch 1044/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6407 - val_loss: 4.4267\n",
      "Epoch 1045/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3632 - val_loss: 4.4200\n",
      "Epoch 1046/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4243 - val_loss: 4.5002\n",
      "Epoch 1047/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7060 - val_loss: 4.5599\n",
      "Epoch 1048/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8813 - val_loss: 4.5544\n",
      "Epoch 1049/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4882 - val_loss: 4.5133\n",
      "Epoch 1050/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4833 - val_loss: 4.4446\n",
      "Epoch 1051/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6631 - val_loss: 4.3639\n",
      "Epoch 1052/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5807 - val_loss: 4.3618\n",
      "Epoch 1053/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5310 - val_loss: 4.3393\n",
      "Epoch 1054/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5968 - val_loss: 4.4179\n",
      "Epoch 1055/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7856 - val_loss: 4.4657\n",
      "Epoch 1056/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5083 - val_loss: 4.4377\n",
      "Epoch 1057/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7298 - val_loss: 4.4626\n",
      "Epoch 1058/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6781 - val_loss: 4.4692\n",
      "Epoch 1059/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4662 - val_loss: 4.4658\n",
      "Epoch 1060/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7209 - val_loss: 4.4184\n",
      "Epoch 1061/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5419 - val_loss: 4.4525\n",
      "Epoch 1062/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6347 - val_loss: 4.3880\n",
      "Epoch 1063/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4187 - val_loss: 4.3459\n",
      "Epoch 1064/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6942 - val_loss: 4.3775\n",
      "Epoch 1065/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7015 - val_loss: 4.3440\n",
      "Epoch 1066/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4245 - val_loss: 4.3505\n",
      "Epoch 1067/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3487 - val_loss: 4.3271\n",
      "Epoch 1068/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5603 - val_loss: 4.3413\n",
      "Epoch 1069/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4584 - val_loss: 4.3538\n",
      "Epoch 1070/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3160 - val_loss: 4.3218\n",
      "Epoch 1071/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7618 - val_loss: 4.3601\n",
      "Epoch 1072/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5611 - val_loss: 4.4185\n",
      "Epoch 1073/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6518 - val_loss: 4.4049\n",
      "Epoch 1074/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5990 - val_loss: 4.4298\n",
      "Epoch 1075/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9072 - val_loss: 4.4215\n",
      "Epoch 1076/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5851 - val_loss: 4.4056\n",
      "Epoch 1077/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5268 - val_loss: 4.4057\n",
      "Epoch 1078/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6956 - val_loss: 4.3966\n",
      "Epoch 1079/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7320 - val_loss: 4.4403\n",
      "Epoch 1080/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5042 - val_loss: 4.4564\n",
      "Epoch 1081/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6154 - val_loss: 4.4508\n",
      "Epoch 1082/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7243 - val_loss: 4.4631\n",
      "Epoch 1083/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7002 - val_loss: 4.4305\n",
      "Epoch 1084/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7692 - val_loss: 4.4478\n",
      "Epoch 1085/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6174 - val_loss: 4.4265\n",
      "Epoch 1086/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5565 - val_loss: 4.4039\n",
      "Epoch 1087/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5135 - val_loss: 4.4088\n",
      "Epoch 1088/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3975 - val_loss: 4.4078\n",
      "Epoch 1089/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5178 - val_loss: 4.4298\n",
      "Epoch 1090/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2287 - val_loss: 4.4766\n",
      "Epoch 1091/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6275 - val_loss: 4.5271\n",
      "Epoch 1092/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7789 - val_loss: 4.5015\n",
      "Epoch 1093/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6337 - val_loss: 4.4267\n",
      "Epoch 1094/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6398 - val_loss: 4.4050\n",
      "Epoch 1095/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3518 - val_loss: 4.4278\n",
      "Epoch 1096/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5131 - val_loss: 4.4524\n",
      "Epoch 1097/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6083 - val_loss: 4.4595\n",
      "Epoch 1098/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8580 - val_loss: 4.4537\n",
      "Epoch 1099/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5518 - val_loss: 4.4491\n",
      "Epoch 1100/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2669 - val_loss: 4.4268\n",
      "Epoch 1101/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6111 - val_loss: 4.4347\n",
      "Epoch 1102/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5205 - val_loss: 4.4141\n",
      "Epoch 1103/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5885 - val_loss: 4.3622\n",
      "Epoch 1104/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7100 - val_loss: 4.3572\n",
      "Epoch 1105/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4369 - val_loss: 4.3965\n",
      "Epoch 1106/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7348 - val_loss: 4.4478\n",
      "Epoch 1107/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4804 - val_loss: 4.5420\n",
      "Epoch 1108/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6829 - val_loss: 4.4910\n",
      "Epoch 1109/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4508 - val_loss: 4.4100\n",
      "Epoch 1110/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6163 - val_loss: 4.4006\n",
      "Epoch 1111/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5090 - val_loss: 4.4516\n",
      "Epoch 1112/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4814 - val_loss: 4.4770\n",
      "Epoch 1113/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5052 - val_loss: 4.5509\n",
      "Epoch 1114/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6912 - val_loss: 4.5611\n",
      "Epoch 1115/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4649 - val_loss: 4.5160\n",
      "Epoch 1116/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6326 - val_loss: 4.4990\n",
      "Epoch 1117/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6021 - val_loss: 4.4611\n",
      "Epoch 1118/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4191 - val_loss: 4.4460\n",
      "Epoch 1119/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6724 - val_loss: 4.4411\n",
      "Epoch 1120/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6687 - val_loss: 4.4238\n",
      "Epoch 1121/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6691 - val_loss: 4.3972\n",
      "Epoch 1122/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6159 - val_loss: 4.3751\n",
      "Epoch 1123/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4078 - val_loss: 4.3532\n",
      "Epoch 1124/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4930 - val_loss: 4.3248\n",
      "Epoch 1125/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4300 - val_loss: 4.2718\n",
      "Epoch 1126/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4924 - val_loss: 4.2681\n",
      "Epoch 1127/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5195 - val_loss: 4.3174\n",
      "Epoch 1128/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4615 - val_loss: 4.3513\n",
      "Epoch 1129/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7899 - val_loss: 4.3870\n",
      "Epoch 1130/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5535 - val_loss: 4.3877\n",
      "Epoch 1131/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4117 - val_loss: 4.3647\n",
      "Epoch 1132/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5531 - val_loss: 4.3245\n",
      "Epoch 1133/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4227 - val_loss: 4.3179\n",
      "Epoch 1134/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5799 - val_loss: 4.3563\n",
      "Epoch 1135/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7229 - val_loss: 4.4021\n",
      "Epoch 1136/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6022 - val_loss: 4.4561\n",
      "Epoch 1137/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4466 - val_loss: 4.4697\n",
      "Epoch 1138/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3471 - val_loss: 4.5578\n",
      "Epoch 1139/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6065 - val_loss: 4.4619\n",
      "Epoch 1140/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6827 - val_loss: 4.3693\n",
      "Epoch 1141/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5915 - val_loss: 4.3033\n",
      "Epoch 1142/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2555 - val_loss: 4.2711\n",
      "Epoch 1143/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3688 - val_loss: 4.2317\n",
      "Epoch 1144/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4849 - val_loss: 4.1920\n",
      "Epoch 1145/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1987 - val_loss: 4.2218\n",
      "Epoch 1146/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4879 - val_loss: 4.2400\n",
      "Epoch 1147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5858 - val_loss: 4.2550\n",
      "Epoch 1148/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5005 - val_loss: 4.2875\n",
      "Epoch 1149/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7445 - val_loss: 4.3037\n",
      "Epoch 1150/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7155 - val_loss: 4.3135\n",
      "Epoch 1151/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7142 - val_loss: 4.3242\n",
      "Epoch 1152/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8509 - val_loss: 4.3349\n",
      "Epoch 1153/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3605 - val_loss: 4.3473\n",
      "Epoch 1154/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3528 - val_loss: 4.3235\n",
      "Epoch 1155/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5745 - val_loss: 4.2732\n",
      "Epoch 1156/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5624 - val_loss: 4.2064\n",
      "Epoch 1157/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6995 - val_loss: 4.2308\n",
      "Epoch 1158/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5275 - val_loss: 4.2917\n",
      "Epoch 1159/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6756 - val_loss: 4.2866\n",
      "Epoch 1160/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3615 - val_loss: 4.2852\n",
      "Epoch 1161/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4135 - val_loss: 4.3233\n",
      "Epoch 1162/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6540 - val_loss: 4.3643\n",
      "Epoch 1163/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6649 - val_loss: 4.4302\n",
      "Epoch 1164/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7193 - val_loss: 4.4549\n",
      "Epoch 1165/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9004 - val_loss: 4.4384\n",
      "Epoch 1166/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4845 - val_loss: 4.4424\n",
      "Epoch 1167/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7256 - val_loss: 4.5024\n",
      "Epoch 1168/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6016 - val_loss: 4.4765\n",
      "Epoch 1169/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3814 - val_loss: 4.4191\n",
      "Epoch 1170/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3889 - val_loss: 4.3713\n",
      "Epoch 1171/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4850 - val_loss: 4.3755\n",
      "Epoch 1172/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3139 - val_loss: 4.2809\n",
      "Epoch 1173/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4991 - val_loss: 4.2312\n",
      "Epoch 1174/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3858 - val_loss: 4.2095\n",
      "Epoch 1175/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6076 - val_loss: 4.2197\n",
      "Epoch 1176/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5728 - val_loss: 4.2655\n",
      "Epoch 1177/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7842 - val_loss: 4.3234\n",
      "Epoch 1178/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6055 - val_loss: 4.3008\n",
      "Epoch 1179/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3264 - val_loss: 4.3072\n",
      "Epoch 1180/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3862 - val_loss: 4.2756\n",
      "Epoch 1181/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4015 - val_loss: 4.2817\n",
      "Epoch 1182/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4941 - val_loss: 4.2684\n",
      "Epoch 1183/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4988 - val_loss: 4.3207\n",
      "Epoch 1184/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4112 - val_loss: 4.3244\n",
      "Epoch 1185/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6110 - val_loss: 4.3041\n",
      "Epoch 1186/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3479 - val_loss: 4.2937\n",
      "Epoch 1187/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3189 - val_loss: 4.2987\n",
      "Epoch 1188/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4720 - val_loss: 4.3025\n",
      "Epoch 1189/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7716 - val_loss: 4.3006\n",
      "Epoch 1190/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4723 - val_loss: 4.2913\n",
      "Epoch 1191/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3946 - val_loss: 4.3141\n",
      "Epoch 1192/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6223 - val_loss: 4.3422\n",
      "Epoch 1193/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3281 - val_loss: 4.3286\n",
      "Epoch 1194/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6049 - val_loss: 4.3076\n",
      "Epoch 1195/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4793 - val_loss: 4.3136\n",
      "Epoch 1196/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5096 - val_loss: 4.3110\n",
      "Epoch 1197/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5845 - val_loss: 4.2960\n",
      "Epoch 1198/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5080 - val_loss: 4.3447\n",
      "Epoch 1199/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4086 - val_loss: 4.3872\n",
      "Epoch 1200/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5785 - val_loss: 4.3553\n",
      "Epoch 1201/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5788 - val_loss: 4.3433\n",
      "Epoch 1202/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5284 - val_loss: 4.3333\n",
      "Epoch 1203/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5085 - val_loss: 4.3500\n",
      "Epoch 1204/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5749 - val_loss: 4.3619\n",
      "Epoch 1205/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4855 - val_loss: 4.3700\n",
      "Epoch 1206/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3503 - val_loss: 4.3604\n",
      "Epoch 1207/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4408 - val_loss: 4.3555\n",
      "Epoch 1208/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6388 - val_loss: 4.2788\n",
      "Epoch 1209/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3134 - val_loss: 4.2480\n",
      "Epoch 1210/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1254 - val_loss: 4.3679\n",
      "Epoch 1211/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5158 - val_loss: 4.3499\n",
      "Epoch 1212/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4513 - val_loss: 4.3289\n",
      "Epoch 1213/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4181 - val_loss: 4.3572\n",
      "Epoch 1214/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2173 - val_loss: 4.3561\n",
      "Epoch 1215/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3744 - val_loss: 4.2932\n",
      "Epoch 1216/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6456 - val_loss: 4.2380\n",
      "Epoch 1217/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6395 - val_loss: 4.2366\n",
      "Epoch 1218/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3885 - val_loss: 4.2426\n",
      "Epoch 1219/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4554 - val_loss: 4.2663\n",
      "Epoch 1220/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5895 - val_loss: 4.2886\n",
      "Epoch 1221/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4905 - val_loss: 4.3146\n",
      "Epoch 1222/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3934 - val_loss: 4.3408\n",
      "Epoch 1223/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3611 - val_loss: 4.3283\n",
      "Epoch 1224/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6938 - val_loss: 4.3464\n",
      "Epoch 1225/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6965 - val_loss: 4.3442\n",
      "Epoch 1226/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6476 - val_loss: 4.3538\n",
      "Epoch 1227/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5907 - val_loss: 4.3651\n",
      "Epoch 1228/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4290 - val_loss: 4.3916\n",
      "Epoch 1229/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3775 - val_loss: 4.3642\n",
      "Epoch 1230/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2664 - val_loss: 4.3336\n",
      "Epoch 1231/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3326 - val_loss: 4.3821\n",
      "Epoch 1232/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4225 - val_loss: 4.3723\n",
      "Epoch 1233/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3179 - val_loss: 4.3344\n",
      "Epoch 1234/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5051 - val_loss: 4.3286\n",
      "Epoch 1235/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4011 - val_loss: 4.3410\n",
      "Epoch 1236/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3391 - val_loss: 4.3243\n",
      "Epoch 1237/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4296 - val_loss: 4.2702\n",
      "Epoch 1238/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4073 - val_loss: 4.2249\n",
      "Epoch 1239/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3417 - val_loss: 4.1826\n",
      "Epoch 1240/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6591 - val_loss: 4.1557\n",
      "Epoch 1241/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3388 - val_loss: 4.1833\n",
      "Epoch 1242/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2649 - val_loss: 4.2401\n",
      "Epoch 1243/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2982 - val_loss: 4.2572\n",
      "Epoch 1244/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8182 - val_loss: 4.2408\n",
      "Epoch 1245/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7993 - val_loss: 4.2535\n",
      "Epoch 1246/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6076 - val_loss: 4.2135\n",
      "Epoch 1247/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3722 - val_loss: 4.2087\n",
      "Epoch 1248/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5365 - val_loss: 4.1979\n",
      "Epoch 1249/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2680 - val_loss: 4.2124\n",
      "Epoch 1250/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6684 - val_loss: 4.1924\n",
      "Epoch 1251/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3295 - val_loss: 4.2926\n",
      "Epoch 1252/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4894 - val_loss: 4.2759\n",
      "Epoch 1253/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2647 - val_loss: 4.1796\n",
      "Epoch 1254/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3925 - val_loss: 4.1860\n",
      "Epoch 1255/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5173 - val_loss: 4.1868\n",
      "Epoch 1256/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3668 - val_loss: 4.1917\n",
      "Epoch 1257/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4303 - val_loss: 4.2126\n",
      "Epoch 1258/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4388 - val_loss: 4.2678\n",
      "Epoch 1259/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3912 - val_loss: 4.2781\n",
      "Epoch 1260/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4780 - val_loss: 4.2325\n",
      "Epoch 1261/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6308 - val_loss: 4.2263\n",
      "Epoch 1262/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2801 - val_loss: 4.2156\n",
      "Epoch 1263/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5276 - val_loss: 4.2100\n",
      "Epoch 1264/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4840 - val_loss: 4.2459\n",
      "Epoch 1265/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4788 - val_loss: 4.2278\n",
      "Epoch 1266/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2581 - val_loss: 4.1935\n",
      "Epoch 1267/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4830 - val_loss: 4.2277\n",
      "Epoch 1268/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3746 - val_loss: 4.2087\n",
      "Epoch 1269/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6212 - val_loss: 4.2332\n",
      "Epoch 1270/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2410 - val_loss: 4.2428\n",
      "Epoch 1271/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3632 - val_loss: 4.2665\n",
      "Epoch 1272/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2883 - val_loss: 4.2584\n",
      "Epoch 1273/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3909 - val_loss: 4.1884\n",
      "Epoch 1274/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3281 - val_loss: 4.1592\n",
      "Epoch 1275/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4806 - val_loss: 4.1069\n",
      "Epoch 1276/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2681 - val_loss: 4.1754\n",
      "Epoch 1277/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3898 - val_loss: 4.3240\n",
      "Epoch 1278/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4286 - val_loss: 4.2480\n",
      "Epoch 1279/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4412 - val_loss: 4.2455\n",
      "Epoch 1280/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3106 - val_loss: 4.2680\n",
      "Epoch 1281/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3352 - val_loss: 4.2178\n",
      "Epoch 1282/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2769 - val_loss: 4.1983\n",
      "Epoch 1283/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3973 - val_loss: 4.1498\n",
      "Epoch 1284/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4135 - val_loss: 4.1724\n",
      "Epoch 1285/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4549 - val_loss: 4.2093\n",
      "Epoch 1286/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1827 - val_loss: 4.2556\n",
      "Epoch 1287/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3721 - val_loss: 4.2419\n",
      "Epoch 1288/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9837 - val_loss: 4.2158\n",
      "Epoch 1289/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2319 - val_loss: 4.1872\n",
      "Epoch 1290/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3790 - val_loss: 4.1758\n",
      "Epoch 1291/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1232 - val_loss: 4.1713\n",
      "Epoch 1292/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4679 - val_loss: 4.1842\n",
      "Epoch 1293/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3109 - val_loss: 4.1197\n",
      "Epoch 1294/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5307 - val_loss: 4.1295\n",
      "Epoch 1295/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1479 - val_loss: 4.1081\n",
      "Epoch 1296/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3399 - val_loss: 4.0725\n",
      "Epoch 1297/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4280 - val_loss: 4.0927\n",
      "Epoch 1298/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4376 - val_loss: 4.1626\n",
      "Epoch 1299/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5575 - val_loss: 4.1878\n",
      "Epoch 1300/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1414 - val_loss: 4.1703\n",
      "Epoch 1301/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4301 - val_loss: 4.1494\n",
      "Epoch 1302/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2959 - val_loss: 4.1820\n",
      "Epoch 1303/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3882 - val_loss: 4.1709\n",
      "Epoch 1304/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4156 - val_loss: 4.1782\n",
      "Epoch 1305/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3130 - val_loss: 4.1856\n",
      "Epoch 1306/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0714 - val_loss: 4.1425\n",
      "Epoch 1307/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1681 - val_loss: 4.0960\n",
      "Epoch 1308/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3013 - val_loss: 4.1053\n",
      "Epoch 1309/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3594 - val_loss: 4.1239\n",
      "Epoch 1310/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5531 - val_loss: 4.0991\n",
      "Epoch 1311/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3742 - val_loss: 4.2145\n",
      "Epoch 1312/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3164 - val_loss: 4.2375\n",
      "Epoch 1313/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4378 - val_loss: 4.1042\n",
      "Epoch 1314/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3054 - val_loss: 4.0650\n",
      "Epoch 1315/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5991 - val_loss: 4.0568\n",
      "Epoch 1316/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3190 - val_loss: 4.1185\n",
      "Epoch 1317/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5288 - val_loss: 4.2796\n",
      "Epoch 1318/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3775 - val_loss: 4.2774\n",
      "Epoch 1319/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3094 - val_loss: 4.1877\n",
      "Epoch 1320/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3695 - val_loss: 4.2229\n",
      "Epoch 1321/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4650 - val_loss: 4.2076\n",
      "Epoch 1322/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3871 - val_loss: 4.2099\n",
      "Epoch 1323/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5811 - val_loss: 4.1591\n",
      "Epoch 1324/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3578 - val_loss: 4.1280\n",
      "Epoch 1325/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2376 - val_loss: 4.1413\n",
      "Epoch 1326/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5429 - val_loss: 4.1833\n",
      "Epoch 1327/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6036 - val_loss: 4.1355\n",
      "Epoch 1328/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2682 - val_loss: 4.1585\n",
      "Epoch 1329/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7476 - val_loss: 4.1960\n",
      "Epoch 1330/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3670 - val_loss: 4.2005\n",
      "Epoch 1331/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2716 - val_loss: 4.2975\n",
      "Epoch 1332/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2942 - val_loss: 4.2291\n",
      "Epoch 1333/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4728 - val_loss: 4.2096\n",
      "Epoch 1334/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7320 - val_loss: 4.1552\n",
      "Epoch 1335/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1630 - val_loss: 4.0818\n",
      "Epoch 1336/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1585 - val_loss: 4.0741\n",
      "Epoch 1337/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4003 - val_loss: 4.0672\n",
      "Epoch 1338/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1462 - val_loss: 4.1405\n",
      "Epoch 1339/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1608 - val_loss: 4.2035\n",
      "Epoch 1340/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3450 - val_loss: 4.2269\n",
      "Epoch 1341/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4180 - val_loss: 4.1786\n",
      "Epoch 1342/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1208 - val_loss: 4.0636\n",
      "Epoch 1343/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2136 - val_loss: 3.9608\n",
      "Epoch 1344/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5436 - val_loss: 3.9437\n",
      "Epoch 1345/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3717 - val_loss: 3.9937\n",
      "Epoch 1346/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4758 - val_loss: 4.0700\n",
      "Epoch 1347/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1450 - val_loss: 4.1313\n",
      "Epoch 1348/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2814 - val_loss: 4.0794\n",
      "Epoch 1349/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2193 - val_loss: 4.0795\n",
      "Epoch 1350/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3065 - val_loss: 4.0806\n",
      "Epoch 1351/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0677 - val_loss: 4.0212\n",
      "Epoch 1352/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5391 - val_loss: 3.9898\n",
      "Epoch 1353/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2978 - val_loss: 3.9933\n",
      "Epoch 1354/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4375 - val_loss: 3.9585\n",
      "Epoch 1355/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2833 - val_loss: 3.9584\n",
      "Epoch 1356/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3917 - val_loss: 4.0020\n",
      "Epoch 1357/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3008 - val_loss: 4.0164\n",
      "Epoch 1358/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4099 - val_loss: 4.1006\n",
      "Epoch 1359/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2318 - val_loss: 4.0936\n",
      "Epoch 1360/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2775 - val_loss: 4.1211\n",
      "Epoch 1361/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2123 - val_loss: 4.1304\n",
      "Epoch 1362/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2229 - val_loss: 4.0910\n",
      "Epoch 1363/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3172 - val_loss: 4.0461\n",
      "Epoch 1364/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3550 - val_loss: 4.0117\n",
      "Epoch 1365/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3485 - val_loss: 3.9880\n",
      "Epoch 1366/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2569 - val_loss: 4.0397\n",
      "Epoch 1367/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1668 - val_loss: 4.0700\n",
      "Epoch 1368/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2466 - val_loss: 4.0529\n",
      "Epoch 1369/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4112 - val_loss: 4.1354\n",
      "Epoch 1370/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4412 - val_loss: 4.0969\n",
      "Epoch 1371/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1119 - val_loss: 4.0527\n",
      "Epoch 1372/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3550 - val_loss: 4.0645\n",
      "Epoch 1373/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2509 - val_loss: 4.1376\n",
      "Epoch 1374/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3251 - val_loss: 4.0741\n",
      "Epoch 1375/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4035 - val_loss: 4.1136\n",
      "Epoch 1376/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2204 - val_loss: 4.1775\n",
      "Epoch 1377/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0241 - val_loss: 4.1639\n",
      "Epoch 1378/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0262 - val_loss: 4.1650\n",
      "Epoch 1379/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4119 - val_loss: 4.1690\n",
      "Epoch 1380/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2536 - val_loss: 4.2073\n",
      "Epoch 1381/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4180 - val_loss: 4.1900\n",
      "Epoch 1382/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4544 - val_loss: 4.2202\n",
      "Epoch 1383/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0905 - val_loss: 4.1970\n",
      "Epoch 1384/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3227 - val_loss: 4.0992\n",
      "Epoch 1385/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1733 - val_loss: 4.0588\n",
      "Epoch 1386/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2369 - val_loss: 4.0254\n",
      "Epoch 1387/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1928 - val_loss: 4.0208\n",
      "Epoch 1388/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1829 - val_loss: 4.0251\n",
      "Epoch 1389/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5511 - val_loss: 4.1023\n",
      "Epoch 1390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3444 - val_loss: 4.0966\n",
      "Epoch 1391/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1573 - val_loss: 4.1098\n",
      "Epoch 1392/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1476 - val_loss: 4.1512\n",
      "Epoch 1393/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3988 - val_loss: 4.1190\n",
      "Epoch 1394/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2655 - val_loss: 4.0699\n",
      "Epoch 1395/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1798 - val_loss: 4.0699\n",
      "Epoch 1396/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4688 - val_loss: 4.0589\n",
      "Epoch 1397/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4049 - val_loss: 4.0822\n",
      "Epoch 1398/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0727 - val_loss: 4.1119\n",
      "Epoch 1399/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1369 - val_loss: 4.1040\n",
      "Epoch 1400/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2561 - val_loss: 4.1216\n",
      "Epoch 1401/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2384 - val_loss: 4.0887\n",
      "Epoch 1402/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3715 - val_loss: 4.0883\n",
      "Epoch 1403/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2555 - val_loss: 4.0747\n",
      "Epoch 1404/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4828 - val_loss: 4.0562\n",
      "Epoch 1405/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4605 - val_loss: 4.1066\n",
      "Epoch 1406/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3479 - val_loss: 4.0964\n",
      "Epoch 1407/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1260 - val_loss: 4.1240\n",
      "Epoch 1408/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4138 - val_loss: 4.1086\n",
      "Epoch 1409/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5033 - val_loss: 4.0505\n",
      "Epoch 1410/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3379 - val_loss: 4.0307\n",
      "Epoch 1411/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3624 - val_loss: 4.1144\n",
      "Epoch 1412/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0107 - val_loss: 4.1041\n",
      "Epoch 1413/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2220 - val_loss: 4.1024\n",
      "Epoch 1414/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1567 - val_loss: 4.0853\n",
      "Epoch 1415/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2528 - val_loss: 4.0683\n",
      "Epoch 1416/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0502 - val_loss: 4.0212\n",
      "Epoch 1417/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2043 - val_loss: 3.9895\n",
      "Epoch 1418/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2710 - val_loss: 3.9635\n",
      "Epoch 1419/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3025 - val_loss: 3.9830\n",
      "Epoch 1420/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4518 - val_loss: 3.9817\n",
      "Epoch 1421/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3498 - val_loss: 3.9453\n",
      "Epoch 1422/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5358 - val_loss: 4.0383\n",
      "Epoch 1423/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1910 - val_loss: 4.0645\n",
      "Epoch 1424/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3742 - val_loss: 4.0806\n",
      "Epoch 1425/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6171 - val_loss: 4.0324\n",
      "Epoch 1426/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4051 - val_loss: 4.0469\n",
      "Epoch 1427/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2842 - val_loss: 4.0210\n",
      "Epoch 1428/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0811 - val_loss: 4.0191\n",
      "Epoch 1429/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4241 - val_loss: 4.0447\n",
      "Epoch 1430/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3373 - val_loss: 4.1004\n",
      "Epoch 1431/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5769 - val_loss: 4.0701\n",
      "Epoch 1432/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3440 - val_loss: 4.0480\n",
      "Epoch 1433/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5160 - val_loss: 4.0875\n",
      "Epoch 1434/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3019 - val_loss: 4.0361\n",
      "Epoch 1435/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2048 - val_loss: 4.0662\n",
      "Epoch 1436/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3998 - val_loss: 4.0322\n",
      "Epoch 1437/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1853 - val_loss: 4.0036\n",
      "Epoch 1438/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0464 - val_loss: 4.0694\n",
      "Epoch 1439/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1039 - val_loss: 4.1119\n",
      "Epoch 1440/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4745 - val_loss: 4.1251\n",
      "Epoch 1441/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5058 - val_loss: 4.0686\n",
      "Epoch 1442/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2801 - val_loss: 4.0321\n",
      "Epoch 1443/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2218 - val_loss: 4.0236\n",
      "Epoch 1444/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1675 - val_loss: 3.9930\n",
      "Epoch 1445/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3400 - val_loss: 4.0261\n",
      "Epoch 1446/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3467 - val_loss: 4.0409\n",
      "Epoch 1447/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3822 - val_loss: 4.0045\n",
      "Epoch 1448/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3135 - val_loss: 3.9269\n",
      "Epoch 1449/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1351 - val_loss: 3.8940\n",
      "Epoch 1450/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0335 - val_loss: 3.8642\n",
      "Epoch 1451/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2953 - val_loss: 3.9145\n",
      "Epoch 1452/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2354 - val_loss: 3.9632\n",
      "Epoch 1453/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6229 - val_loss: 4.0017\n",
      "Epoch 1454/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3889 - val_loss: 3.9388\n",
      "Epoch 1455/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1695 - val_loss: 3.9475\n",
      "Epoch 1456/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1570 - val_loss: 3.9448\n",
      "Epoch 1457/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3492 - val_loss: 4.0859\n",
      "Epoch 1458/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2035 - val_loss: 4.1030\n",
      "Epoch 1459/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2453 - val_loss: 4.0152\n",
      "Epoch 1460/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2359 - val_loss: 3.9348\n",
      "Epoch 1461/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1644 - val_loss: 3.9925\n",
      "Epoch 1462/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3973 - val_loss: 4.0138\n",
      "Epoch 1463/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1686 - val_loss: 4.0151\n",
      "Epoch 1464/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3428 - val_loss: 4.0583\n",
      "Epoch 1465/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3677 - val_loss: 4.0797\n",
      "Epoch 1466/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2973 - val_loss: 4.1566\n",
      "Epoch 1467/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1020 - val_loss: 4.1462\n",
      "Epoch 1468/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1708 - val_loss: 4.0891\n",
      "Epoch 1469/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2837 - val_loss: 4.0469\n",
      "Epoch 1470/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2081 - val_loss: 4.0200\n",
      "Epoch 1471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4741 - val_loss: 4.0205\n",
      "Epoch 1472/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3189 - val_loss: 4.0247\n",
      "Epoch 1473/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4390 - val_loss: 4.0646\n",
      "Epoch 1474/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2476 - val_loss: 4.1228\n",
      "Epoch 1475/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5061 - val_loss: 4.1469\n",
      "Epoch 1476/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3206 - val_loss: 4.1962\n",
      "Epoch 1477/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3160 - val_loss: 4.1540\n",
      "Epoch 1478/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3277 - val_loss: 4.0788\n",
      "Epoch 1479/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0776 - val_loss: 4.0791\n",
      "Epoch 1480/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3196 - val_loss: 3.9891\n",
      "Epoch 1481/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5006 - val_loss: 3.9126\n",
      "Epoch 1482/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1792 - val_loss: 3.8950\n",
      "Epoch 1483/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3840 - val_loss: 3.9123\n",
      "Epoch 1484/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4153 - val_loss: 3.9453\n",
      "Epoch 1485/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0976 - val_loss: 4.0149\n",
      "Epoch 1486/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8863 - val_loss: 4.0911\n",
      "Epoch 1487/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3276 - val_loss: 4.0956\n",
      "Epoch 1488/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1078 - val_loss: 4.0740\n",
      "Epoch 1489/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2855 - val_loss: 4.0424\n",
      "Epoch 1490/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3810 - val_loss: 4.0095\n",
      "Epoch 1491/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3381 - val_loss: 3.9676\n",
      "Epoch 1492/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2419 - val_loss: 3.9657\n",
      "Epoch 1493/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3136 - val_loss: 4.1307\n",
      "Epoch 1494/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3003 - val_loss: 4.2031\n",
      "Epoch 1495/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4203 - val_loss: 4.0574\n",
      "Epoch 1496/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0901 - val_loss: 3.9866\n",
      "Epoch 1497/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1233 - val_loss: 3.9973\n",
      "Epoch 1498/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4413 - val_loss: 4.0434\n",
      "Epoch 1499/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1298 - val_loss: 4.1438\n",
      "Epoch 1500/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3369 - val_loss: 4.1221\n",
      "Epoch 1501/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2960 - val_loss: 4.0263\n",
      "Epoch 1502/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1369 - val_loss: 4.0084\n",
      "Epoch 1503/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4417 - val_loss: 3.9997\n",
      "Epoch 1504/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7399 - val_loss: 4.0063\n",
      "Epoch 1505/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3377 - val_loss: 4.0360\n",
      "Epoch 1506/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3495 - val_loss: 4.0239\n",
      "Epoch 1507/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2976 - val_loss: 4.0286\n",
      "Epoch 1508/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0385 - val_loss: 4.0264\n",
      "Epoch 1509/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2839 - val_loss: 3.9691\n",
      "Epoch 1510/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3295 - val_loss: 3.9518\n",
      "Epoch 1511/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4383 - val_loss: 3.9433\n",
      "Epoch 1512/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1444 - val_loss: 3.8618\n",
      "Epoch 1513/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2443 - val_loss: 3.7855\n",
      "Epoch 1514/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2694 - val_loss: 3.7094\n",
      "Epoch 1515/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1629 - val_loss: 3.6787\n",
      "Epoch 1516/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4435 - val_loss: 3.7039\n",
      "Epoch 1517/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3370 - val_loss: 3.7116\n",
      "Epoch 1518/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2854 - val_loss: 3.7445\n",
      "Epoch 1519/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3323 - val_loss: 3.7718\n",
      "Epoch 1520/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1726 - val_loss: 3.8706\n",
      "Epoch 1521/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0536 - val_loss: 3.9265\n",
      "Epoch 1522/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2260 - val_loss: 3.9666\n",
      "Epoch 1523/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9756 - val_loss: 4.0067\n",
      "Epoch 1524/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8862 - val_loss: 3.9798\n",
      "Epoch 1525/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3417 - val_loss: 3.9538\n",
      "Epoch 1526/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2553 - val_loss: 3.8908\n",
      "Epoch 1527/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1970 - val_loss: 3.9541\n",
      "Epoch 1528/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4173 - val_loss: 4.0215\n",
      "Epoch 1529/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2344 - val_loss: 3.9035\n",
      "Epoch 1530/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1307 - val_loss: 3.8495\n",
      "Epoch 1531/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1355 - val_loss: 3.8475\n",
      "Epoch 1532/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1989 - val_loss: 3.9016\n",
      "Epoch 1533/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2176 - val_loss: 3.9625\n",
      "Epoch 1534/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1137 - val_loss: 3.8782\n",
      "Epoch 1535/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3476 - val_loss: 3.8602\n",
      "Epoch 1536/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1513 - val_loss: 3.8287\n",
      "Epoch 1537/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9956 - val_loss: 3.8048\n",
      "Epoch 1538/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0848 - val_loss: 3.7990\n",
      "Epoch 1539/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4281 - val_loss: 3.8302\n",
      "Epoch 1540/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0665 - val_loss: 3.8963\n",
      "Epoch 1541/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3165 - val_loss: 3.9313\n",
      "Epoch 1542/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4367 - val_loss: 3.8985\n",
      "Epoch 1543/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3785 - val_loss: 3.9375\n",
      "Epoch 1544/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0418 - val_loss: 3.9753\n",
      "Epoch 1545/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1759 - val_loss: 3.9488\n",
      "Epoch 1546/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1303 - val_loss: 3.9356\n",
      "Epoch 1547/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1279 - val_loss: 3.9141\n",
      "Epoch 1548/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0113 - val_loss: 3.8817\n",
      "Epoch 1549/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0736 - val_loss: 3.8679\n",
      "Epoch 1550/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1313 - val_loss: 3.8768\n",
      "Epoch 1551/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3625 - val_loss: 3.9239\n",
      "Epoch 1552/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2042 - val_loss: 3.9419\n",
      "Epoch 1553/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2936 - val_loss: 3.9527\n",
      "Epoch 1554/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8831 - val_loss: 3.9702\n",
      "Epoch 1555/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0527 - val_loss: 3.9501\n",
      "Epoch 1556/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0322 - val_loss: 3.9851\n",
      "Epoch 1557/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4435 - val_loss: 3.9851\n",
      "Epoch 1558/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2679 - val_loss: 3.9641\n",
      "Epoch 1559/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1835 - val_loss: 4.1190\n",
      "Epoch 1560/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3697 - val_loss: 3.9946\n",
      "Epoch 1561/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2104 - val_loss: 3.8614\n",
      "Epoch 1562/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2329 - val_loss: 3.9297\n",
      "Epoch 1563/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1599 - val_loss: 3.9910\n",
      "Epoch 1564/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0761 - val_loss: 4.0213\n",
      "Epoch 1565/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1339 - val_loss: 3.9308\n",
      "Epoch 1566/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1214 - val_loss: 3.8650\n",
      "Epoch 1567/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2744 - val_loss: 3.9117\n",
      "Epoch 1568/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1324 - val_loss: 3.9074\n",
      "Epoch 1569/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3910 - val_loss: 3.8922\n",
      "Epoch 1570/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0614 - val_loss: 3.8190\n",
      "Epoch 1571/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2024 - val_loss: 3.7740\n",
      "Epoch 1572/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0024 - val_loss: 3.7567\n",
      "Epoch 1573/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1322 - val_loss: 3.7453\n",
      "Epoch 1574/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3527 - val_loss: 3.8442\n",
      "Epoch 1575/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1065 - val_loss: 3.9666\n",
      "Epoch 1576/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3813 - val_loss: 3.9110\n",
      "Epoch 1577/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0612 - val_loss: 3.8974\n",
      "Epoch 1578/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1129 - val_loss: 3.9504\n",
      "Epoch 1579/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3787 - val_loss: 4.0172\n",
      "Epoch 1580/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1116 - val_loss: 3.9522\n",
      "Epoch 1581/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2730 - val_loss: 3.8631\n",
      "Epoch 1582/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2476 - val_loss: 3.8428\n",
      "Epoch 1583/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6762 - val_loss: 3.8687\n",
      "Epoch 1584/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1951 - val_loss: 3.8823\n",
      "Epoch 1585/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1057 - val_loss: 3.9156\n",
      "Epoch 1586/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2859 - val_loss: 3.9701\n",
      "Epoch 1587/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2170 - val_loss: 3.9654\n",
      "Epoch 1588/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1722 - val_loss: 4.0005\n",
      "Epoch 1589/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3535 - val_loss: 3.9279\n",
      "Epoch 1590/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1965 - val_loss: 3.9018\n",
      "Epoch 1591/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1776 - val_loss: 3.7929\n",
      "Epoch 1592/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1757 - val_loss: 3.7317\n",
      "Epoch 1593/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1999 - val_loss: 3.7190\n",
      "Epoch 1594/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1811 - val_loss: 3.8036\n",
      "Epoch 1595/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1688 - val_loss: 3.9048\n",
      "Epoch 1596/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0961 - val_loss: 3.9984\n",
      "Epoch 1597/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2940 - val_loss: 3.9832\n",
      "Epoch 1598/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0445 - val_loss: 3.9679\n",
      "Epoch 1599/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0917 - val_loss: 3.9689\n",
      "Epoch 1600/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9420 - val_loss: 3.9864\n",
      "Epoch 1601/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4615 - val_loss: 3.8964\n",
      "Epoch 1602/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9441 - val_loss: 3.7242\n",
      "Epoch 1603/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4201 - val_loss: 3.7388\n",
      "Epoch 1604/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1692 - val_loss: 3.7599\n",
      "Epoch 1605/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1653 - val_loss: 3.8672\n",
      "Epoch 1606/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0057 - val_loss: 3.9245\n",
      "Epoch 1607/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2292 - val_loss: 3.7806\n",
      "Epoch 1608/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1315 - val_loss: 3.9078\n",
      "Epoch 1609/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4481 - val_loss: 3.9074\n",
      "Epoch 1610/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3056 - val_loss: 3.9351\n",
      "Epoch 1611/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0510 - val_loss: 3.9870\n",
      "Epoch 1612/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1680 - val_loss: 3.9618\n",
      "Epoch 1613/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1423 - val_loss: 3.9170\n",
      "Epoch 1614/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0654 - val_loss: 3.8843\n",
      "Epoch 1615/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0882 - val_loss: 3.8507\n",
      "Epoch 1616/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2415 - val_loss: 3.9168\n",
      "Epoch 1617/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0756 - val_loss: 3.9872\n",
      "Epoch 1618/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1944 - val_loss: 3.9125\n",
      "Epoch 1619/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3090 - val_loss: 3.9082\n",
      "Epoch 1620/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1212 - val_loss: 3.8859\n",
      "Epoch 1621/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0842 - val_loss: 3.8398\n",
      "Epoch 1622/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1949 - val_loss: 3.8952\n",
      "Epoch 1623/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2030 - val_loss: 3.8488\n",
      "Epoch 1624/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9684 - val_loss: 3.8174\n",
      "Epoch 1625/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0222 - val_loss: 3.8129\n",
      "Epoch 1626/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1600 - val_loss: 3.8076\n",
      "Epoch 1627/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9667 - val_loss: 3.7972\n",
      "Epoch 1628/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2554 - val_loss: 3.8923\n",
      "Epoch 1629/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1299 - val_loss: 3.8437\n",
      "Epoch 1630/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2353 - val_loss: 3.7979\n",
      "Epoch 1631/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2246 - val_loss: 3.8288\n",
      "Epoch 1632/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2380 - val_loss: 3.8619\n",
      "Epoch 1633/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2942 - val_loss: 3.8340\n",
      "Epoch 1634/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2062 - val_loss: 3.8316\n",
      "Epoch 1635/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0680 - val_loss: 3.8493\n",
      "Epoch 1636/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1806 - val_loss: 3.8535\n",
      "Epoch 1637/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9746 - val_loss: 3.8604\n",
      "Epoch 1638/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2705 - val_loss: 3.8497\n",
      "Epoch 1639/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9686 - val_loss: 3.7521\n",
      "Epoch 1640/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3101 - val_loss: 3.6949\n",
      "Epoch 1641/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1003 - val_loss: 3.7793\n",
      "Epoch 1642/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2513 - val_loss: 3.8024\n",
      "Epoch 1643/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1903 - val_loss: 3.8200\n",
      "Epoch 1644/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1819 - val_loss: 3.8236\n",
      "Epoch 1645/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3622 - val_loss: 3.7999\n",
      "Epoch 1646/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1727 - val_loss: 3.8133\n",
      "Epoch 1647/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0948 - val_loss: 3.7271\n",
      "Epoch 1648/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1238 - val_loss: 3.7267\n",
      "Epoch 1649/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1555 - val_loss: 3.7289\n",
      "Epoch 1650/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0049 - val_loss: 3.7939\n",
      "Epoch 1651/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3114 - val_loss: 3.8157\n",
      "Epoch 1652/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3321 - val_loss: 3.7775\n",
      "Epoch 1653/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2189 - val_loss: 3.7295\n",
      "Epoch 1654/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3439 - val_loss: 3.7506\n",
      "Epoch 1655/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1764 - val_loss: 3.8077\n",
      "Epoch 1656/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2588 - val_loss: 3.7958\n",
      "Epoch 1657/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1631 - val_loss: 3.7244\n",
      "Epoch 1658/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3782 - val_loss: 3.6989\n",
      "Epoch 1659/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0467 - val_loss: 3.7154\n",
      "Epoch 1660/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2557 - val_loss: 3.6780\n",
      "Epoch 1661/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9801 - val_loss: 3.7263\n",
      "Epoch 1662/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1715 - val_loss: 3.7148\n",
      "Epoch 1663/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1341 - val_loss: 3.7939\n",
      "Epoch 1664/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2466 - val_loss: 3.8385\n",
      "Epoch 1665/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2077 - val_loss: 3.7445\n",
      "Epoch 1666/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1743 - val_loss: 3.6360\n",
      "Epoch 1667/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1102 - val_loss: 3.6261\n",
      "Epoch 1668/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1912 - val_loss: 3.7150\n",
      "Epoch 1669/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2969 - val_loss: 3.8402\n",
      "Epoch 1670/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2296 - val_loss: 3.7884\n",
      "Epoch 1671/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2074 - val_loss: 3.7136\n",
      "Epoch 1672/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0228 - val_loss: 3.6780\n",
      "Epoch 1673/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3383 - val_loss: 3.8059\n",
      "Epoch 1674/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9983 - val_loss: 3.8496\n",
      "Epoch 1675/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4253 - val_loss: 3.7145\n",
      "Epoch 1676/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1719 - val_loss: 3.5916\n",
      "Epoch 1677/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2894 - val_loss: 3.6344\n",
      "Epoch 1678/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6446 - val_loss: 3.6167\n",
      "Epoch 1679/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0421 - val_loss: 3.7770\n",
      "Epoch 1680/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0305 - val_loss: 3.8655\n",
      "Epoch 1681/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1806 - val_loss: 3.8151\n",
      "Epoch 1682/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1962 - val_loss: 3.7540\n",
      "Epoch 1683/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0436 - val_loss: 3.6872\n",
      "Epoch 1684/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0862 - val_loss: 3.6776\n",
      "Epoch 1685/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0867 - val_loss: 3.6620\n",
      "Epoch 1686/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1502 - val_loss: 3.6704\n",
      "Epoch 1687/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4467 - val_loss: 3.7565\n",
      "Epoch 1688/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0852 - val_loss: 3.7877\n",
      "Epoch 1689/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0682 - val_loss: 3.7637\n",
      "Epoch 1690/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0167 - val_loss: 3.6505\n",
      "Epoch 1691/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1661 - val_loss: 3.6345\n",
      "Epoch 1692/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1481 - val_loss: 3.6938\n",
      "Epoch 1693/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1200 - val_loss: 3.7339\n",
      "Epoch 1694/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2380 - val_loss: 3.7509\n",
      "Epoch 1695/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2932 - val_loss: 3.6491\n",
      "Epoch 1696/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2447 - val_loss: 3.6370\n",
      "Epoch 1697/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9669 - val_loss: 3.6909\n",
      "Epoch 1698/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9422 - val_loss: 3.6840\n",
      "Epoch 1699/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1252 - val_loss: 3.6277\n",
      "Epoch 1700/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9799 - val_loss: 3.6119\n",
      "Epoch 1701/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0887 - val_loss: 3.6483\n",
      "Epoch 1702/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3451 - val_loss: 3.6729\n",
      "Epoch 1703/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1672 - val_loss: 3.7839\n",
      "Epoch 1704/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1204 - val_loss: 3.7580\n",
      "Epoch 1705/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0520 - val_loss: 3.6607\n",
      "Epoch 1706/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1966 - val_loss: 3.6597\n",
      "Epoch 1707/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0476 - val_loss: 3.7402\n",
      "Epoch 1708/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0665 - val_loss: 3.8296\n",
      "Epoch 1709/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2738 - val_loss: 3.8427\n",
      "Epoch 1710/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4277 - val_loss: 3.7736\n",
      "Epoch 1711/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2260 - val_loss: 3.6653\n",
      "Epoch 1712/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9455 - val_loss: 3.7130\n",
      "Epoch 1713/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1610 - val_loss: 3.6522\n",
      "Epoch 1714/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0800 - val_loss: 3.6670\n",
      "Epoch 1715/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8268 - val_loss: 3.7054\n",
      "Epoch 1716/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0722 - val_loss: 3.7771\n",
      "Epoch 1717/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1982 - val_loss: 3.7066\n",
      "Epoch 1718/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0474 - val_loss: 3.7337\n",
      "Epoch 1719/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0963 - val_loss: 3.8192\n",
      "Epoch 1720/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3109 - val_loss: 3.8581\n",
      "Epoch 1721/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9718 - val_loss: 3.7618\n",
      "Epoch 1722/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9725 - val_loss: 3.6971\n",
      "Epoch 1723/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1110 - val_loss: 3.6276\n",
      "Epoch 1724/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1396 - val_loss: 3.6412\n",
      "Epoch 1725/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0814 - val_loss: 3.6714\n",
      "Epoch 1726/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1559 - val_loss: 3.6593\n",
      "Epoch 1727/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2269 - val_loss: 3.7382\n",
      "Epoch 1728/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1445 - val_loss: 3.8002\n",
      "Epoch 1729/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0940 - val_loss: 3.7674\n",
      "Epoch 1730/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3771 - val_loss: 3.7209\n",
      "Epoch 1731/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2208 - val_loss: 3.6531\n",
      "Epoch 1732/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3077 - val_loss: 3.6187\n",
      "Epoch 1733/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1250 - val_loss: 3.5838\n",
      "Epoch 1734/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0839 - val_loss: 3.6343\n",
      "Epoch 1735/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1147 - val_loss: 3.7565\n",
      "Epoch 1736/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1804 - val_loss: 3.8843\n",
      "Epoch 1737/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0950 - val_loss: 3.6924\n",
      "Epoch 1738/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1546 - val_loss: 3.6100\n",
      "Epoch 1739/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2353 - val_loss: 3.6563\n",
      "Epoch 1740/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9728 - val_loss: 3.9061\n",
      "Epoch 1741/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1712 - val_loss: 3.8001\n",
      "Epoch 1742/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2641 - val_loss: 3.5897\n",
      "Epoch 1743/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2474 - val_loss: 3.5371\n",
      "Epoch 1744/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2922 - val_loss: 3.5215\n",
      "Epoch 1745/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0948 - val_loss: 3.5246\n",
      "Epoch 1746/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1722 - val_loss: 3.5543\n",
      "Epoch 1747/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1034 - val_loss: 3.5268\n",
      "Epoch 1748/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0051 - val_loss: 3.5298\n",
      "Epoch 1749/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1065 - val_loss: 3.6087\n",
      "Epoch 1750/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9776 - val_loss: 3.6603\n",
      "Epoch 1751/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9466 - val_loss: 3.6868\n",
      "Epoch 1752/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2489 - val_loss: 3.7919\n",
      "Epoch 1753/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2946 - val_loss: 3.7164\n",
      "Epoch 1754/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1062 - val_loss: 3.5184\n",
      "Epoch 1755/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1241 - val_loss: 3.5046\n",
      "Epoch 1756/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4992 - val_loss: 3.4875\n",
      "Epoch 1757/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1941 - val_loss: 3.6341\n",
      "Epoch 1758/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0354 - val_loss: 3.7720\n",
      "Epoch 1759/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1625 - val_loss: 3.7960\n",
      "Epoch 1760/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1819 - val_loss: 3.7399\n",
      "Epoch 1761/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1155 - val_loss: 3.7202\n",
      "Epoch 1762/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2315 - val_loss: 3.7168\n",
      "Epoch 1763/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2211 - val_loss: 3.6818\n",
      "Epoch 1764/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0559 - val_loss: 3.6531\n",
      "Epoch 1765/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8879 - val_loss: 3.5395\n",
      "Epoch 1766/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0054 - val_loss: 3.5849\n",
      "Epoch 1767/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9603 - val_loss: 3.6806\n",
      "Epoch 1768/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9918 - val_loss: 3.7134\n",
      "Epoch 1769/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0816 - val_loss: 3.7299\n",
      "Epoch 1770/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1061 - val_loss: 3.7023\n",
      "Epoch 1771/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0450 - val_loss: 3.7286\n",
      "Epoch 1772/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1810 - val_loss: 3.7224\n",
      "Epoch 1773/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1779 - val_loss: 3.7923\n",
      "Epoch 1774/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1303 - val_loss: 3.8081\n",
      "Epoch 1775/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0637 - val_loss: 3.8538\n",
      "Epoch 1776/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0854 - val_loss: 3.8444\n",
      "Epoch 1777/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9808 - val_loss: 3.7425\n",
      "Epoch 1778/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8210 - val_loss: 3.6515\n",
      "Epoch 1779/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3623 - val_loss: 3.6753\n",
      "Epoch 1780/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0098 - val_loss: 3.6329\n",
      "Epoch 1781/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9383 - val_loss: 3.5788\n",
      "Epoch 1782/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1014 - val_loss: 3.6821\n",
      "Epoch 1783/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1671 - val_loss: 3.5960\n",
      "Epoch 1784/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0525 - val_loss: 3.6082\n",
      "Epoch 1785/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1397 - val_loss: 3.6487\n",
      "Epoch 1786/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1744 - val_loss: 3.7752\n",
      "Epoch 1787/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0787 - val_loss: 3.6812\n",
      "Epoch 1788/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0153 - val_loss: 3.6733\n",
      "Epoch 1789/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2807 - val_loss: 3.6811\n",
      "Epoch 1790/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0392 - val_loss: 3.8062\n",
      "Epoch 1791/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1815 - val_loss: 3.7645\n",
      "Epoch 1792/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9825 - val_loss: 3.7334\n",
      "Epoch 1793/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2936 - val_loss: 3.7377\n",
      "Epoch 1794/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2863 - val_loss: 3.7904\n",
      "Epoch 1795/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2842 - val_loss: 3.9201\n",
      "Epoch 1796/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2377 - val_loss: 3.7968\n",
      "Epoch 1797/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9809 - val_loss: 3.6320\n",
      "Epoch 1798/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8454 - val_loss: 3.4755\n",
      "Epoch 1799/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1111 - val_loss: 3.5448\n",
      "Epoch 1800/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1183 - val_loss: 3.7687\n",
      "Epoch 1801/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2908 - val_loss: 3.8396\n",
      "Epoch 1802/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1654 - val_loss: 3.8066\n",
      "Epoch 1803/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0694 - val_loss: 3.8212\n",
      "Epoch 1804/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3521 - val_loss: 3.8043\n",
      "Epoch 1805/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1445 - val_loss: 3.7626\n",
      "Epoch 1806/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9861 - val_loss: 3.7711\n",
      "Epoch 1807/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0773 - val_loss: 3.7885\n",
      "Epoch 1808/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1659 - val_loss: 3.8600\n",
      "Epoch 1809/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0768 - val_loss: 3.7712\n",
      "Epoch 1810/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0273 - val_loss: 3.7245\n",
      "Epoch 1811/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8221 - val_loss: 3.7465\n",
      "Epoch 1812/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1955 - val_loss: 3.7468\n",
      "Epoch 1813/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0226 - val_loss: 3.6265\n",
      "Epoch 1814/2000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.1246 - val_loss: 3.6399\n",
      "Epoch 1815/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9637 - val_loss: 3.6659\n",
      "Epoch 1816/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0221 - val_loss: 3.6862\n",
      "Epoch 1817/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9013 - val_loss: 3.7282\n",
      "Epoch 1818/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2351 - val_loss: 3.7439\n",
      "Epoch 1819/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1129 - val_loss: 3.7182\n",
      "Epoch 1820/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9575 - val_loss: 3.5818\n",
      "Epoch 1821/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1744 - val_loss: 3.5721\n",
      "Epoch 1822/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0878 - val_loss: 3.5811\n",
      "Epoch 1823/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0487 - val_loss: 3.6113\n",
      "Epoch 1824/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8619 - val_loss: 3.6129\n",
      "Epoch 1825/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0582 - val_loss: 3.5874\n",
      "Epoch 1826/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8648 - val_loss: 3.5825\n",
      "Epoch 1827/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0578 - val_loss: 3.7006\n",
      "Epoch 1828/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9980 - val_loss: 3.8064\n",
      "Epoch 1829/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8703 - val_loss: 3.7691\n",
      "Epoch 1830/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1789 - val_loss: 3.7337\n",
      "Epoch 1831/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9521 - val_loss: 3.6619\n",
      "Epoch 1832/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2182 - val_loss: 3.6057\n",
      "Epoch 1833/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2009 - val_loss: 3.6326\n",
      "Epoch 1834/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2084 - val_loss: 3.6210\n",
      "Epoch 1835/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9142 - val_loss: 3.6407\n",
      "Epoch 1836/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1456 - val_loss: 3.7757\n",
      "Epoch 1837/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0496 - val_loss: 3.8174\n",
      "Epoch 1838/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0769 - val_loss: 3.7319\n",
      "Epoch 1839/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1639 - val_loss: 3.5891\n",
      "Epoch 1840/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0299 - val_loss: 3.5940\n",
      "Epoch 1841/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0070 - val_loss: 3.6673\n",
      "Epoch 1842/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0565 - val_loss: 3.7953\n",
      "Epoch 1843/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1599 - val_loss: 3.7819\n",
      "Epoch 1844/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2140 - val_loss: 3.7339\n",
      "Epoch 1845/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8281 - val_loss: 3.6464\n",
      "Epoch 1846/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1521 - val_loss: 3.6175\n",
      "Epoch 1847/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1376 - val_loss: 3.5723\n",
      "Epoch 1848/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1226 - val_loss: 3.5512\n",
      "Epoch 1849/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0858 - val_loss: 3.5796\n",
      "Epoch 1850/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9135 - val_loss: 3.7256\n",
      "Epoch 1851/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0264 - val_loss: 3.7904\n",
      "Epoch 1852/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2019 - val_loss: 3.6381\n",
      "Epoch 1853/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0508 - val_loss: 3.5476\n",
      "Epoch 1854/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3459 - val_loss: 3.5706\n",
      "Epoch 1855/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0776 - val_loss: 3.6127\n",
      "Epoch 1856/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0739 - val_loss: 3.6817\n",
      "Epoch 1857/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3239 - val_loss: 3.6424\n",
      "Epoch 1858/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1551 - val_loss: 3.6897\n",
      "Epoch 1859/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0631 - val_loss: 3.6143\n",
      "Epoch 1860/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1913 - val_loss: 3.5425\n",
      "Epoch 1861/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9758 - val_loss: 3.6744\n",
      "Epoch 1862/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0418 - val_loss: 3.7128\n",
      "Epoch 1863/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9591 - val_loss: 3.5806\n",
      "Epoch 1864/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2820 - val_loss: 3.5380\n",
      "Epoch 1865/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1942 - val_loss: 3.6570\n",
      "Epoch 1866/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8288 - val_loss: 3.6528\n",
      "Epoch 1867/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0108 - val_loss: 3.6920\n",
      "Epoch 1868/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9047 - val_loss: 3.6895\n",
      "Epoch 1869/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9697 - val_loss: 3.6755\n",
      "Epoch 1870/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9271 - val_loss: 3.5142\n",
      "Epoch 1871/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8507 - val_loss: 3.5358\n",
      "Epoch 1872/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1648 - val_loss: 3.5614\n",
      "Epoch 1873/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8967 - val_loss: 3.6868\n",
      "Epoch 1874/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9573 - val_loss: 3.6885\n",
      "Epoch 1875/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0306 - val_loss: 3.6661\n",
      "Epoch 1876/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3171 - val_loss: 3.6691\n",
      "Epoch 1877/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0280 - val_loss: 3.8036\n",
      "Epoch 1878/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2225 - val_loss: 3.8804\n",
      "Epoch 1879/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0552 - val_loss: 3.8201\n",
      "Epoch 1880/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0275 - val_loss: 3.7892\n",
      "Epoch 1881/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9781 - val_loss: 3.8172\n",
      "Epoch 1882/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3762 - val_loss: 3.8538\n",
      "Epoch 1883/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8937 - val_loss: 3.6878\n",
      "Epoch 1884/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1702 - val_loss: 3.6222\n",
      "Epoch 1885/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0787 - val_loss: 3.6155\n",
      "Epoch 1886/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9129 - val_loss: 3.6606\n",
      "Epoch 1887/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0254 - val_loss: 3.7856\n",
      "Epoch 1888/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9358 - val_loss: 3.6922\n",
      "Epoch 1889/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0187 - val_loss: 3.5558\n",
      "Epoch 1890/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9501 - val_loss: 3.5793\n",
      "Epoch 1891/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9517 - val_loss: 3.8020\n",
      "Epoch 1892/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1509 - val_loss: 3.7661\n",
      "Epoch 1893/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9962 - val_loss: 3.6164\n",
      "Epoch 1894/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4352 - val_loss: 3.5572\n",
      "Epoch 1895/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1467 - val_loss: 3.5852\n",
      "Epoch 1896/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3730 - val_loss: 3.8575\n",
      "Epoch 1897/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9541 - val_loss: 3.8931\n",
      "Epoch 1898/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9279 - val_loss: 3.6635\n",
      "Epoch 1899/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9479 - val_loss: 3.5613\n",
      "Epoch 1900/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2103 - val_loss: 3.5564\n",
      "Epoch 1901/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9954 - val_loss: 3.9247\n",
      "Epoch 1902/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0650 - val_loss: 3.9109\n",
      "Epoch 1903/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2413 - val_loss: 3.6814\n",
      "Epoch 1904/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3004 - val_loss: 3.5350\n",
      "Epoch 1905/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1543 - val_loss: 3.5172\n",
      "Epoch 1906/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1569 - val_loss: 3.7209\n",
      "Epoch 1907/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2150 - val_loss: 3.8098\n",
      "Epoch 1908/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2547 - val_loss: 3.8116\n",
      "Epoch 1909/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9284 - val_loss: 3.6483\n",
      "Epoch 1910/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1607 - val_loss: 3.5816\n",
      "Epoch 1911/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0261 - val_loss: 3.4233\n",
      "Epoch 1912/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9303 - val_loss: 3.4283\n",
      "Epoch 1913/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7961 - val_loss: 3.4248\n",
      "Epoch 1914/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9533 - val_loss: 3.5902\n",
      "Epoch 1915/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0139 - val_loss: 3.7742\n",
      "Epoch 1916/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1152 - val_loss: 3.7285\n",
      "Epoch 1917/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1157 - val_loss: 3.7996\n",
      "Epoch 1918/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8568 - val_loss: 3.7783\n",
      "Epoch 1919/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0013 - val_loss: 3.6208\n",
      "Epoch 1920/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9303 - val_loss: 3.6067\n",
      "Epoch 1921/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3733 - val_loss: 3.6553\n",
      "Epoch 1922/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0780 - val_loss: 3.6686\n",
      "Epoch 1923/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0882 - val_loss: 3.7176\n",
      "Epoch 1924/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9360 - val_loss: 3.7586\n",
      "Epoch 1925/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8751 - val_loss: 3.7628\n",
      "Epoch 1926/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0777 - val_loss: 3.7995\n",
      "Epoch 1927/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2469 - val_loss: 3.5775\n",
      "Epoch 1928/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1027 - val_loss: 3.6164\n",
      "Epoch 1929/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9185 - val_loss: 3.8361\n",
      "Epoch 1930/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8869 - val_loss: 4.0205\n",
      "Epoch 1931/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0625 - val_loss: 3.6828\n",
      "Epoch 1932/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9516 - val_loss: 3.4297\n",
      "Epoch 1933/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1376 - val_loss: 3.4102\n",
      "Epoch 1934/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1394 - val_loss: 3.6375\n",
      "Epoch 1935/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2278 - val_loss: 3.7298\n",
      "Epoch 1936/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3015 - val_loss: 3.6067\n",
      "Epoch 1937/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1053 - val_loss: 3.7268\n",
      "Epoch 1938/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0051 - val_loss: 3.6219\n",
      "Epoch 1939/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9372 - val_loss: 3.5777\n",
      "Epoch 1940/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8773 - val_loss: 3.5812\n",
      "Epoch 1941/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1297 - val_loss: 3.6793\n",
      "Epoch 1942/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0243 - val_loss: 3.8604\n",
      "Epoch 1943/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0078 - val_loss: 3.7815\n",
      "Epoch 1944/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9878 - val_loss: 3.5190\n",
      "Epoch 1945/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1153 - val_loss: 3.5060\n",
      "Epoch 1946/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2584 - val_loss: 3.6106\n",
      "Epoch 1947/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1194 - val_loss: 3.6809\n",
      "Epoch 1948/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0679 - val_loss: 3.6918\n",
      "Epoch 1949/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0539 - val_loss: 3.6147\n",
      "Epoch 1950/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0026 - val_loss: 3.5394\n",
      "Epoch 1951/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9287 - val_loss: 3.5420\n",
      "Epoch 1952/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0188 - val_loss: 3.5777\n",
      "Epoch 1953/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1491 - val_loss: 3.7990\n",
      "Epoch 1954/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0192 - val_loss: 3.6334\n",
      "Epoch 1955/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2893 - val_loss: 3.4572\n",
      "Epoch 1956/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1774 - val_loss: 3.3709\n",
      "Epoch 1957/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0072 - val_loss: 3.4107\n",
      "Epoch 1958/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9818 - val_loss: 3.3769\n",
      "Epoch 1959/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1854 - val_loss: 3.4101\n",
      "Epoch 1960/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2035 - val_loss: 3.4821\n",
      "Epoch 1961/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0666 - val_loss: 3.5111\n",
      "Epoch 1962/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1498 - val_loss: 3.4948\n",
      "Epoch 1963/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2074 - val_loss: 3.6205\n",
      "Epoch 1964/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2671 - val_loss: 3.6240\n",
      "Epoch 1965/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9601 - val_loss: 3.5466\n",
      "Epoch 1966/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0193 - val_loss: 3.5202\n",
      "Epoch 1967/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9487 - val_loss: 3.5356\n",
      "Epoch 1968/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0429 - val_loss: 3.5768\n",
      "Epoch 1969/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2161 - val_loss: 3.5473\n",
      "Epoch 1970/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8928 - val_loss: 3.5227\n",
      "Epoch 1971/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9649 - val_loss: 3.5943\n",
      "Epoch 1972/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0170 - val_loss: 3.6109\n",
      "Epoch 1973/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0377 - val_loss: 3.5698\n",
      "Epoch 1974/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9664 - val_loss: 3.6840\n",
      "Epoch 1975/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9479 - val_loss: 3.6611\n",
      "Epoch 1976/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8552 - val_loss: 3.3852\n",
      "Epoch 1977/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0430 - val_loss: 3.3528\n",
      "Epoch 1978/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0908 - val_loss: 3.5004\n",
      "Epoch 1979/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1446 - val_loss: 3.5961\n",
      "Epoch 1980/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1418 - val_loss: 3.5721\n",
      "Epoch 1981/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1847 - val_loss: 3.6176\n",
      "Epoch 1982/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9944 - val_loss: 3.5886\n",
      "Epoch 1983/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1257 - val_loss: 3.5859\n",
      "Epoch 1984/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0147 - val_loss: 3.4270\n",
      "Epoch 1985/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1533 - val_loss: 3.4117\n",
      "Epoch 1986/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9099 - val_loss: 3.4433\n",
      "Epoch 1987/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8407 - val_loss: 3.5370\n",
      "Epoch 1988/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1601 - val_loss: 3.5767\n",
      "Epoch 1989/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2809 - val_loss: 3.6785\n",
      "Epoch 1990/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0235 - val_loss: 3.6265\n",
      "Epoch 1991/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8767 - val_loss: 3.5054\n",
      "Epoch 1992/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0019 - val_loss: 3.4876\n",
      "Epoch 1993/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8743 - val_loss: 3.5100\n",
      "Epoch 1994/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9490 - val_loss: 3.5181\n",
      "Epoch 1995/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2926 - val_loss: 3.5340\n",
      "Epoch 1996/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8734 - val_loss: 3.4541\n",
      "Epoch 1997/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9609 - val_loss: 3.3249\n",
      "Epoch 1998/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2161 - val_loss: 3.3686\n",
      "Epoch 1999/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0717 - val_loss: 3.5539\n",
      "Epoch 2000/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8859 - val_loss: 3.6139\n",
      "Train: 2.341, Test: 3.614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(64, input_dim=9, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(16, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(8, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            epochs=2000, verbose=1)\n",
    "y_pred=reg_model.predict(X_test)\n",
    "train_mae = reg_model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_mae = reg_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mae, test_mae))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean absolute Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6ef0b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=r2_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "355814c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738408272865578"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train)\n",
    "p = len(X[1])\n",
    "adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29783097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8abf346",
   "metadata": {},
   "source": [
    "# AutoEncoder - standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b34d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\n",
    "# X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9659aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32b80c9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 65ms/step - loss: 0.1822 - val_loss: 0.1735\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1807 - val_loss: 0.1722\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1793 - val_loss: 0.1709\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1780 - val_loss: 0.1697\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1767 - val_loss: 0.1685\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1754 - val_loss: 0.1673\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1741 - val_loss: 0.1662\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1729 - val_loss: 0.1650\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1716 - val_loss: 0.1639\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1704 - val_loss: 0.1627\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1691 - val_loss: 0.1615\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1679 - val_loss: 0.1605\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1667 - val_loss: 0.1594\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1656 - val_loss: 0.1583\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1645 - val_loss: 0.1573\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1634 - val_loss: 0.1562\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1624 - val_loss: 0.1552\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1614 - val_loss: 0.1542\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1603 - val_loss: 0.1532\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1593 - val_loss: 0.1522\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1582 - val_loss: 0.1511\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1572 - val_loss: 0.1502\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1563 - val_loss: 0.1492\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1554 - val_loss: 0.1482\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1545 - val_loss: 0.1473\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1536 - val_loss: 0.1465\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1528 - val_loss: 0.1457\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1520 - val_loss: 0.1448\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1512 - val_loss: 0.1441\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1504 - val_loss: 0.1433\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1497 - val_loss: 0.1426\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1490 - val_loss: 0.1419\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1483 - val_loss: 0.1412\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1476 - val_loss: 0.1406\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1470 - val_loss: 0.1400\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1464 - val_loss: 0.1394\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1458 - val_loss: 0.1388\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1452 - val_loss: 0.1382\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1447 - val_loss: 0.1377\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1442 - val_loss: 0.1372\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1437 - val_loss: 0.1367\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1432 - val_loss: 0.1363\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1427 - val_loss: 0.1358\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1423 - val_loss: 0.1354\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1418 - val_loss: 0.1349\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1414 - val_loss: 0.1345\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1410 - val_loss: 0.1341\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1337\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1402 - val_loss: 0.1333\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1399 - val_loss: 0.1330\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1395 - val_loss: 0.1326\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1392 - val_loss: 0.1323\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1388 - val_loss: 0.1320\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1385 - val_loss: 0.1316\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1382 - val_loss: 0.1313\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1379 - val_loss: 0.1310\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1376 - val_loss: 0.1307\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1373 - val_loss: 0.1305\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1370 - val_loss: 0.1302\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1368 - val_loss: 0.1299\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1365 - val_loss: 0.1297\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1363 - val_loss: 0.1294\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1360 - val_loss: 0.1292\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1358 - val_loss: 0.1289\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1356 - val_loss: 0.1287\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1353 - val_loss: 0.1285\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1351 - val_loss: 0.1283\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1349 - val_loss: 0.1281\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1347 - val_loss: 0.1278\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1345 - val_loss: 0.1276\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1343 - val_loss: 0.1275\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1341 - val_loss: 0.1273\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1339 - val_loss: 0.1271\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1338 - val_loss: 0.1269\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1336 - val_loss: 0.1267\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1334 - val_loss: 0.1266\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1333 - val_loss: 0.1264\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1331 - val_loss: 0.1262\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1329 - val_loss: 0.1261\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1328 - val_loss: 0.1259\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1326 - val_loss: 0.1258\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1325 - val_loss: 0.1256\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1324 - val_loss: 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1322 - val_loss: 0.1253\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1321 - val_loss: 0.1252\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1319 - val_loss: 0.1251\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1318 - val_loss: 0.1249\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1317 - val_loss: 0.1248\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1315 - val_loss: 0.1247\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1314 - val_loss: 0.1245\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1313 - val_loss: 0.1244\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1312 - val_loss: 0.1243\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1311 - val_loss: 0.1242\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1309 - val_loss: 0.1240\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1308 - val_loss: 0.1239\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1307 - val_loss: 0.1238\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1306 - val_loss: 0.1237\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1305 - val_loss: 0.1236\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1304 - val_loss: 0.1235\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1303 - val_loss: 0.1234\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "encoded = Dense(5, activation='relu')(input_layer)\n",
    "decoded = Dense(X.shape[1], activation='relu')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X1, X2, Y1, Y2 = train_test_split(X, X, test_size=0.3, random_state=101)\n",
    "\n",
    "autoencoder.fit(X1, Y1,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose = 1,\n",
    "                validation_data=(X2, Y2))\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_ae = autoencoder.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63eacad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40151087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ae, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f145a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 65ms/step - loss: 10.8166 - val_loss: 13.4875\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.7882 - val_loss: 13.3525\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.5842 - val_loss: 13.1071\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.2828 - val_loss: 12.8432\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.9651 - val_loss: 12.5598\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.6803 - val_loss: 12.2813\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.4431 - val_loss: 12.0159\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2638 - val_loss: 11.7403\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0983 - val_loss: 11.4425\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9116 - val_loss: 11.1530\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7882 - val_loss: 10.8017\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6537 - val_loss: 10.5187\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5701 - val_loss: 10.3238\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7057 - val_loss: 10.2399\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6582 - val_loss: 10.2624\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5965 - val_loss: 10.2444\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6785 - val_loss: 10.3779\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5673 - val_loss: 10.4249\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5973 - val_loss: 10.4547\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4811 - val_loss: 10.3856\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6736 - val_loss: 10.2932\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5627 - val_loss: 10.2028\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6682 - val_loss: 10.2165\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4912 - val_loss: 10.2012\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4568 - val_loss: 10.0978\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8309 - val_loss: 10.1235\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6799 - val_loss: 10.2702\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5916 - val_loss: 10.3118\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4949 - val_loss: 10.2341\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6303 - val_loss: 10.1878\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5419 - val_loss: 10.1331\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6288 - val_loss: 10.0673\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5831 - val_loss: 10.1676\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5597 - val_loss: 10.1965\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5893 - val_loss: 10.2576\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2841 - val_loss: 10.1612\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6546 - val_loss: 10.0726\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4989 - val_loss: 10.0496\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5276 - val_loss: 10.0132\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5260 - val_loss: 10.1045\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6252 - val_loss: 10.2042\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4026 - val_loss: 10.1759\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6811 - val_loss: 10.2037\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5141 - val_loss: 10.2765\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5814 - val_loss: 10.2634\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4914 - val_loss: 10.2729\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5029 - val_loss: 10.1848\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2983 - val_loss: 10.1467\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5996 - val_loss: 10.1042\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4851 - val_loss: 10.1406\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4260 - val_loss: 10.1290\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5368 - val_loss: 10.1139\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5737 - val_loss: 10.1093\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3251 - val_loss: 10.0629\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5346 - val_loss: 10.1100\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5115 - val_loss: 10.1967\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.4569 - val_loss: 10.2159\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5285 - val_loss: 10.2689\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4139 - val_loss: 10.1576\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4687 - val_loss: 10.0660\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3609 - val_loss: 10.1402\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4902 - val_loss: 10.2106\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4050 - val_loss: 10.0520\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3509 - val_loss: 10.0332\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4364 - val_loss: 10.1230\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3788 - val_loss: 10.0137\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3698 - val_loss: 10.0299\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4346 - val_loss: 10.1190\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4238 - val_loss: 10.2158\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1939 - val_loss: 10.0410\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1528 - val_loss: 9.9214\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2568 - val_loss: 9.9758\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1864 - val_loss: 10.1893\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1384 - val_loss: 9.9451\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9947 - val_loss: 9.8353\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9490 - val_loss: 9.7651\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9911 - val_loss: 9.6950\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7538 - val_loss: 9.6904\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9886 - val_loss: 9.5798\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9522 - val_loss: 9.6522\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0392 - val_loss: 9.9715\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9132 - val_loss: 9.3150\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7042 - val_loss: 9.7784\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6560 - val_loss: 9.3018\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6006 - val_loss: 9.3167\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8951 - val_loss: 9.4552\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4615 - val_loss: 9.1452\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8502 - val_loss: 9.2413\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3274 - val_loss: 8.9869\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4917 - val_loss: 9.5533\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.1799 - val_loss: 9.0268\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3275 - val_loss: 8.9560\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4361 - val_loss: 8.9886\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2645 - val_loss: 9.2297\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.0722 - val_loss: 8.6530\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4017 - val_loss: 8.7403\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8779 - val_loss: 8.8078\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1263 - val_loss: 8.5269\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9582 - val_loss: 8.6195\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.1739 - val_loss: 9.0538\n",
      "Train: 7.072, Test: 9.054\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABHF0lEQVR4nO3dd3hVVdbA4d9KJ50USgi9k1CEgBRR6aCo2BAVy9i7M6OOOvPp6Dg6juM4llFH7BULFrCD9I6AlNBDD4EUICG97u+PfQMJJCQkN7m5yXqfJ4/Jueees06C6+y7zi5ijEEppZT78XB1AEoppWpGE7hSSrkpTeBKKeWmNIErpZSb0gSulFJuShO4Ukq5KU3gSrkZEXlCRD5ydRzK9TSBNzIiskdERrvw/NtFpFsF2xeIiBGRvidt/8ax/fz6irHMuW8Wka0ikikiySLyvYgE1XccziQi54tIiYhknfQ1xNWxKefTBK6cRkQ6Ax7GmO2V7LIduL7M/uHAYCC1HsIrR0TOA54BrjbGBAE9gc9dEIdXHRw2yRgTeNLX8grOLSLicdK2M4qnjuJX1aQJvIkQEV8ReVFEkhxfL4qIr+O1CBH5TkTSReSIiCwu/R9bRB4WkQOOVuo2ERl1mtNcCPxwmtc/Bq4SEU/Hz1cDXwMFZeL0EJFHRGSniBwWkc9FJKzM61+IyCERyRCRRSISU+a190TkVUdLOlNEVjpuKhUZCCw3xvwGYIw5Yox53xiT6ThWuIjMEpFjIrJKRJ4SkSWO1zo4PjUcT16OTxi3OL7vLCLzHPGnicjHIhJaZt89jt/rBiBbRLxEZLCILHP8DdaX/UQiIh1FZKHjmuYAEaf5HZ+WI86nRWQpkAN0clzL3SKyA9jh2O9WEUlw/HuYJSJRZY5xyv7KNTSBNx1/wbZ2+wF9gUHA/zleewBIBCKBlsCfASMi3YF7gIGOVuo4YM9pznEB8P1pXk8CNgNjHT9fD3xw0j73AZOA84Ao4CjwapnXfwS6Ai2AtdibQllXA08CzYEE4OlKYlkJjBORJ0VkWOnNrIxXgTygNXCT46u6BPiHI/6eQFvgiQrivBAIxf7Ovwf+DoQBDwJfikikY99PgDXYxP0UcMMZxFKR64DbgCBgr2PbJOBsoJeIjHTEPxl7/XuBT086xvH9axmLqg1jjH41oi9sgh1dwfadwAVlfh4H7HF8/zdgJtDlpPd0AVKA0YB3Fef1Bw4DfpW8vgC4BZgKTAe6A9sdryUC5zu+3wKMKvO+1kAh4FXBMUMBA4Q4fn4PeKvM6xcAW08T8wTgWyAdyAJeADwdX4VAjzL7PgMscXzfwXFer5Ovr5LzTAJ+O+lvdFOZnx8GPjzpPT9jE3U7oAgIKPPaJ8BHlZzrfKDEcU1lvwLKxPm3k95jgJFlfn4beK7Mz4GO30eHivbXL9d9aQu86YjiRGsLx/elH4v/hW2tzhaRXSLyCIAxJgH4Pbb1mCIin5b9KH2SUcAyY0xeFXF8BYwE7gU+rOD19sDXjlJCOjahFwMtRcRTRJ51lFeOceLTQNmSwqEy3+dgk0+FjDE/GmMuwrZ6LwFuxN5kIgEvYH+Z3feecoBKiEgLx+/qgCPOjzi17FH22O2BK0uv2XHd52BvXlHAUWNM9hnEkmSMCT3pq+z791fwnrLbyv1bMcZkYW/Obao4hqpnmsCbjiRsoijVzrENY0ymMeYBY0wn4CLgj6W1bmPMJ8aYcxzvNcA/Kzl+VeUTHMfLwZZB7qTiBL4fmHBS8vEzxhwArsEm2tFACLYlDLZkUWPGmBJjzFxgHhCLfahahC19lGpX5vvSZOhfZlurMt//A/u76mOMCcZ+6jg5xrLTgO7HtsDLXnOAMeZZ4CDQXEQCKomlJiqagrTstnL/VhznDgcOVHEMVc80gTdO3iLiV+bLC1u2+D8RiRSRCOBxbMsQEZkoIl1ERIBj2BZvsYh0F5GRjvpwHpDreK0iEzj9A8yy/gycZ4zZU8Fr/wOeFpH2jtgiReQSx2tBQD62NeiPLWvUiIhcIiJTRKS5WIOwdfcVxphi7CeFJ0TEX0R6UabubIxJxSazqY5PBTcBZR+WBmFLMuki0gZ4qIpwPgIuEpFxjuP5ie0OGG2M2QusBp4UER8ROQd7k61LnwC/E5F+jr/9M8DKSv5eyoU0gTdOP2CTbenXE9gHZKuBDcBG7APAvzv27wr8gk06y4HXjDELAF/gWSANW5pogU2+5YhILJBljNlXneCMMUnGmCWVvPwSMAtbzskEVmAfloF94LkXmzw3O16rqaPArdheFKVljn8ZY0ofit6DLb8cwtbW3z3p/bdiE/NhIAZYVua1J4H+QAb2U8lXpwvEGLMf+8niz9jW/37HsUv//7wG+zs4AvyVUx/8nixKTu0HfnkV7ykbz1zgMeBL7CeAzsCU6r5f1R8xRj8JqdoRkT8BEcaYP7k6lroiIjdiH1Ke4+pYlCqlnfCVM+zB9uZQStUjTeCq1owx9T6CUSmlJRSllHJb+hBTKaXcVL2WUCIiIkyHDh3q85RKKeX21qxZk2aMiTx5e70m8A4dOrB69er6PKVSSrk9Ealw9K2WUJRSyk1pAldKKTelCVwppdyU9gNXSjVohYWFJCYmkpdX1USX7s/Pz4/o6Gi8vb2rtb8mcKVUg5aYmEhQUBAdOnTAzrfWOBljOHz4MImJiXTs2LFa79ESilKqQcvLyyM8PLxRJ28AESE8PPyMPmloAldKNXiNPXmXOtPrdI8Evv9XWPIfV0ehlFINinsk8I1fwC9PwNYqF3xRSimnS09P57XXXjvj911wwQWkp6c7PyAH90jgY5+C1v3g6zvhyG5XR6OUamIqS+DFxZUtUGX98MMPhIaG1lFU7pLAvXxh8vt2VcEvboDCxt+dSCnVcDzyyCPs3LmTfv36MXDgQEaMGME111xD7969AZg0aRIDBgwgJiaGadOmHX9fhw4dSEtLY8+ePfTs2ZNbb72VmJgYxo4dS25ubq3jcp9uhM07wKT/wadXw8+PwkStiSvV1Dz57SY2Jx1z6jF7RQXz14tiTrvPs88+S3x8POvWrWPBggVceOGFxMfHH+/u98477xAWFkZubi4DBw7k8ssvJzw8vNwxduzYwfTp03nzzTeZPHkyX375JVOnTq1V7O7RAi/V4wIYfBesfgfSdrg6GqVUEzVo0KByfbVffvll+vbty+DBg9m/fz87dpyanzp27Ei/fv0AGDBgAHv27Kl1HO7TAi91zh9g1Zvw61sw4Z+ujkYpVY+qainXl4CAgOPfL1iwgF9++YXly5fj7+/P+eefX2Ffbl9f3+Pfe3p6OqWE4l4tcIDAFhAzCdZ9AvlZro5GKdUEBAUFkZmZWeFrGRkZNG/eHH9/f7Zu3cqKFSvqLS73S+AAA2+F/GOwUZdiVErVvfDwcIYNG0ZsbCwPPfRQudfGjx9PUVERffr04bHHHmPw4MH1Fle9rokZFxdnnLKggzHwxnAoKYE7l0ITGaWlVFO0ZcsWevbs6eow6k1F1ysia4wxcSfv654tcBHbCk/ZBHuXuToapZRyCfdM4AC9rwS/EPj1TVdHopRSLuG+CdzHH866DrZ8C5nJro5GKaXqXZUJXETeEZEUEYkvs+0pEdkgIutEZLaIRNVtmJUYcCOUFMH66S45vVJKuVJ1WuDvAeNP2vYvY0wfY0w/4DvgcSfHVT0RXaHdUFj7gX2wqZRSTUiVCdwYswg4ctK2smNZAwDXZc/+18GRnfowUynV5NS4Bi4iT4vIfuBaTtMCF5HbRGS1iKxOTU2t6ekq1+sS8A22rXCllKoDNZ1OFuDFF18kJyfHyRFZNU7gxpi/GGPaAh8D95xmv2nGmDhjTFxkZGRNT1c5nwDofQVsngm56c4/vlKqyWuoCdwZc6F8AnwP/NUJx6qZs66zE1zFz4CBt7gsDKVU41R2OtkxY8bQokULPv/8c/Lz87n00kt58sknyc7OZvLkySQmJlJcXMxjjz1GcnIySUlJjBgxgoiICObPn+/UuGqUwEWkqzGmdLqti4GtzgupBqLOgpa9bRlFE7hSjdePj8Chjc49ZqveMOHZ0+5SdjrZ2bNnM2PGDFatWoUxhosvvphFixaRmppKVFQU339vVw7LyMggJCSEF154gfnz5xMREeHcuKleN8LpwHKgu4gkisjNwLMiEi8iG4CxwP1Oj+xMiNiHmQfXO/+Pq5RSZcyePZvZs2dz1lln0b9/f7Zu3cqOHTvo3bs3v/zyCw8//DCLFy8mJCSkzmOpsgVujLm6gs1v10EstRN7Bfz8Z1j/qb2jKqUanypayvXBGMOjjz7K7bfffspra9as4YcffuDRRx9l7NixPP543fawdt+RmCcLCIeuY2HjDCg5/Tp1Sil1JspOJztu3DjeeecdsrLsdNYHDhwgJSWFpKQk/P39mTp1Kg8++CBr16495b3O5n4LOpxOn6tg2w+wawF0GeXqaJRSjUTZ6WQnTJjANddcw5AhQwAIDAzko48+IiEhgYceeggPDw+8vb15/fXXAbjtttuYMGECrVu3dvpDTPecTrYyhXnwfDfoPh4um1b1/kqpBk+nk21s08lWxtvPrtaz5VtdrUcp1eg1rgQO0HcKFObA1u9cHYlSStWpxpfA2w6G0Ha2N4pSqlGoz1KvK53pdTa+BO7hYR9m7l4Ixw66OhqlVC35+flx+PDhRp/EjTEcPnwYPz+/ar+ncfVCKdVnCiz6F2z8Aobd5+polFK1EB0dTWJiInUyGV4D4+fnR3R0dLX3b5wJPKILRA+0Cz0MvVcXPVbKjXl7e9OxY0dXh9EgNb4SSqm+UyBlMxza4OpIlFKqTjTeBB5zGXj6wDpdbk0p1Tg13gTuHwbdxts6eHGhq6NRSimna7wJHKDfNZCTBglzXR2JUko5XeNO4F1Gg38ErP/E1ZEopZTTNe4E7ukNva+EbT9C7lFXR6OUUk7VuBM4QL+robjATjOrlFKNSONP4K372gUefvvQ1ZEopZRTNf4EDnDW9Xa5tYPrXR2JUko5TdNI4H2uBE9fWKutcKVU49E0Eniz5tDrYtj4ORTmujoapZRyiqaRwAHOug7yMmCLzhOulGocqkzgIvKOiKSISHyZbf8Ska0iskFEvhaR0DqN0hk6DIfQ9vDbB66ORCmlnKI6LfD3gPEnbZsDxBpj+gDbgUedHJfzeXjYVvjuRXBkt6ujUUqpWqsygRtjFgFHTto22xhT5PhxBVD9CWxdqd81gMA6HZmplHJ/zqiB3wT8WNmLInKbiKwWkdUun5A9pA10HmGXWyspcW0sSilVS7VK4CLyF6AI+LiyfYwx04wxccaYuMjIyNqczjn6XgMZ+2DvEldHopRStVLjBC4iNwATgWuNOy1W1+NC8A3WecKVUm6vRglcRMYDDwMXG2NynBtSHfPxh5hJsHkm5Ge5OhqllKqx6nQjnA4sB7qLSKKI3Az8FwgC5ojIOhH5Xx3H6Vz9roXCbNgyy9WRKKVUjVW5qLEx5uoKNr9dB7HUn7ZnQ1gn2xul3zWujkYppWqk6YzELEvEPszcsxiO7nV1NEopVSNNM4ED9L3K/nfD566NQymlaqjpJvDQdtBuKMR/6epIlFKqRppuAgeIvQxSt0DyZldHopRSZ6xpJ/Bek0A8IV6XW1NKuZ+mncADI6HTebaM4kZjkZRSCpp6AgeIvRyO7oEDa10diVJKnRFN4D0mgqePPsxUSrkdTeDNQqHLGNj0FZQUuzoapZSqNk3gYHujZB6EfctdHYlSSlWbJnCA7hPA2x82fuHqSJRSqto0gQP4BED3C+wMhUUFro5GKaWqRRN4qT6TIfcoJPzi6kiUUqpaNIGX6jwS/MNho86NopRyD5rAS3l6Q8ylsO1HyDvm6miUUqpKmsDL6j0ZivJg63eujkQppaqkCbystoMgtL32RlFKuQVN4GWJQO8rYdcCyEx2dTRKKXVamsBP1mcymBI7MlMppRowTeAni+wOLWJg6/eujkQppU6rOqvSvyMiKSISX2bblSKySURKRCSubkN0gW5j7bD6vAxXR6KUUpWqTgv8PWD8SdvigcuARc4OqEHoOg5KimDnPFdHopRSlaoygRtjFgFHTtq2xRizrc6icrXogeAXCttnuzoSpZSqlNbAK+LpBV1GQ8IcKClxdTRKKVWhOk/gInKbiKwWkdWpqal1fTrn6TYOslMh6TdXR6KUUhWq8wRujJlmjIkzxsRFRkbW9emcp8toEA/Y8bOrI1FKqQppCaUy/mG2Fr5dE7hSqmGqTjfC6cByoLuIJIrIzSJyqYgkAkOA70WkcWa5rmPh4DrIPOTqSJRS6hReVe1gjLm6kpe+dnIslfr6t0TW78/g3G4RDO4Ujr9PlWE7R7dxMO8p2DEH+l9XP+dUSqlqqqdMWDu7U7P59Nd9vLdsDz6eHoyLbcWLV/XD00Pq9sQtYyG4DWz7QRO4UqrBcYsa+B/Hdmfd42P56Oazuax/G75dn8R3G5Lq/sQido7wHXMg50jV+yulVD1yiwQO4OftyTldI3jm0t50bxnES3N3UFxi6v7Efa6CkkKd3Eop1eC4TQIv5eEh3D+6K7tSs5m1/kDdn7BVb2jRC9Z/VvfnUkqpM+B2CRxgfEwrerQK4uW5CRQV1/FISRHbCk9cBYd31u25lFLqDLhlAvfwEH4/uhu707KZua4eauG9rwQENuiCx0qphsMtEzjAuJiW9GodzCvz6qEWHtIGOp4LGz4DUw91d6WUqga3TeAiwh3nd2bP4RxW7j5c9yfsOwWO7ob9q+r+XEopVQ1um8ABxvRsib+PJ9+uP1j3J+t5EXg1g/Wf1P25lFKqGtw6gTfz8WR0z5b8FH+Qwrp+mOkbBH2uhHXTISOxbs+llFLV4NYJHGBin9YczSlk2c56KKOc+yfAwIJna3+sogLYtRB+/gt8eKlOmqWUOmNun8DP6x5JkK8X366vh94ooW0h7mZY9zGk7ajZMY7uhR8fhuc6wQcXw6ppkLIVPpkM39wNuelODVkp1Xi5fQL39fJkbEwrft50iPyi4ro/4fAHbC183t/P7H2ZyTDjJnj5LPj1LehxAUyZDn/aDfevs8dd/wm8PhQSV9dJ6EqpxsXtEzjAxL6tycwrYvH2tLo/WWAkDLkbNn8DSeuq957iQvj8Otj6Awy5C+7fAJdNs0ncNxC8fGHU43DLL+DpDe9fpCUVpVSVGkUCP6dLBKH+3vUzwRXA0HugWXP4/o/Vm+RqzuOwfyVMeg3G/t32K69ImwFw8xyI6ArTr4bfPnJu3MWFsOVbOyBJ1/pUyu25xXSyVfH29GBCbCtmrUsir7AYP2/Puj2hXwhMfBG+uhXeHGFLIS172deMgZIi25IGiP8KVrwGZ98BsZdVfezAFnDj9/DZdTDzbsg8CMMftEP6ayo7DVa+AWs/gCzH4hQbPoNLp0FAeM2P6yrHkuyNKCACQttDYEvIPQpZKVCcD13GgJePq6O0igvhyC6I7O7qSFQj1CgSOMCFvaOYvmo/C7enMi6mVd2fMGaSnSv8s2vh7TEQdxOkbYfEX20yCetsk3rCXIgeBGOeqv6xfYPgms9h1j221p6+Hy58ATxr8OcqyocPLoHkTXaFobgX4dgB+OlR+N85cMU70H7ImR+3lDGwZRYs/BecNRUG31HzY1XH5pkw6z7IS698nw7D4aoP7ackVykpho0zYME/7ACw8f+s+9+NanIaTQI/u1MYof7e/BR/qH4SOEDbgXDbAvhsKix7GSK6Q7cJENQSUrfBwQ3gHw5XvnfmLUIvH7j0DQiJhsX/ti3xnhfD0T2Qvhd8gyG8i/1qP9TW0isy7ylIjoerP4XuE05sbxMHX9wA746HzqNsWajTiDNr6adugx//BLsWgF8o/PSwvXmd/0jNPzHkpsPhBGjVp/zvLCPRJsPfPoKo/nDxK3bR6fS9kJUMzcLsp5fUrfD9g/D2WHsTDOtYszjOlDF2srNDG+zve8t3kLbNzmbZ6Xz7u/EPgz6TT3+conxYP93ebIOjnBffroW2cTH8gdp9mlMNSqNJ4N6eHozp2ZKfNh2ioKgEH696Ku8HR8Etc6EwB3wCnHtsEftwM6StrbfvmA3iaWvoecdOtEIje8IN39oHrGXtXgTL/ms/HZRN3gBR/eD2xbYb48o3bF/0lr1h5F+g2/jK/yff/yts/9F+sji4DnxDYMK/YMAN8N0fYOGzkJcB454BjzP8GxzdYx/gpu8Dn0A7/0xQa3sdh3fYhD38QXuDKC1RlZauSrUbDOFd7Sejt0bBOX+A3pPtTbWuFGTD13fYTyIAHl72BnTl+/amW1wAH18B39xpy2/dxlV8nEMb4avbIWUTtBsCN/5w5r/Dimz6Gr681c5rH9apeqW8o3vgq9vgktcgokvtY1B1Qkw9Ts4UFxdnVq+uuy5yc7ckc/P7q3nvdwM5v3uLOjuPS6Tvt7X1kLYnSinZh2HPYps8wjraJB4QYV/LTYfXh4G3H9y+6PQ3l6J82PiFbekf2QVtB8PoJ8qXVoxjANPCZ+1NpO0g6DIK+t944sZRUgI//xlWvm6T5iX/tT1sqiMtwfaLL8iGMU/CwfX2JpGVAh2GQeeRtlUa0bX6x/vmTjsNsHhCl9H2JtN13InfX0E2JPxi69Qh0bYkFhwFHmfwDOVYEkyfYpPveQ/bG2Vkj1OvO++YvTmlboWrPoKuY068VlIMS1+C+c/Ysk+vS+DXN+HCf8PAW6ofS0XWfgjf3mfLeAXZkHsE7vm16sbGzHvgtw9hwI1w0Uu1i0HVmoisMcbEnbK9MSXw/KJiBjz1CxP7tObZy/vU2XkanF0L7UCgsM4w4lHb42X7zzYZ3zzb9m6pjuJC+z/tgn/ah539rrW9Zpo1h7l/gyUv2G3jnoFmoRUfwxhY/Lyt3bcfZpOVf9jpz5uy1SbvkmK4fia0ii1/vNp85E/dbksS6z+FzCQIjoazroUju2Hr91CYXX5/Tx9o3hHCO0NQK/D2t58GWvaC7heeSP7GwK758M1dkJ9pnyVU1rIulZ1mP+kkb4KLX7bPDDISbat77xLoNck+6/APs/sl/gp3rbADyMrKTbfPR0LawbinK/79GAPLXoE5j9mb31Uf25viu+Ph3Idg5P9VHmf6fni5n/0kIR7wxy2V/71VvahxAheRd4CJQIoxJtaxLQz4DOgA7AEmG2OOVhVEXSdwgPum/8aShDRW/XkUXp6Nopdk9exaAJ9cBUV5NglFD4SBN0Ps5Wd+rIIcm4SXvmRr2x2H24/hA26EC/9TvY/1G2fYFnBoO9uSjB5Ycatv3wrbgvX0sZ8g6qq3RnERbP/JDqLaNd+WMnpNsnO9+4fbB7sZibZ0cDjB1rNz0myrtTDHHiOkHQy+09bal71sE2JIO7h6evmbzunkZ8Ln18POeTaBb/nO3jgvfB76Xn0iGR/dA68NsTfBa784sT19P3x8pW3JY2Dw3acm8eIiW3P/9S3bmr/szROfCL68BTbPgrtXVv584IeHYPU7MPkD+PQaGPcPO35BuUxtEvi5QBbwQZkE/hxwxBjzrIg8AjQ3xjxcVRD1kcB/3HiQOz9eyye3ns3QzhF1eq4G5/BOm4iiB4J3s9of71A8zLoXktbCoNtgwnNn1hreu9wmgNwjtozRMsa2BntfaRPelm9tQgmJhqlfQvMOtY+5OrJSbAKvbnmnpNgm/2WvwL7ldlt4Fxh6L/SZYstUZ6KowP5eN3wKUWfB5W/bFv/JVrwOPz0CPSbav2lItJ07pzDH9rLZ9iOs/B+c/6h9LgC2VPPlLbDjZxh6H4x+svwN91gSvBJnny9cPf3Uv2dWCrzYG3pfAZe8ah8GZ6fCPWucU49XNVKrEoqIdAC+K5PAtwHnG2MOikhrYIExpsqmU30k8JyCIvo/NYfJcW352yXVbBWpypUU2/pu6741K2XkZcC+lbYWvW8F7F0Gptg+aDycANFxcPVn7tMf/cAaW8LoNKJ2Cc0YW+qK6l95D6WSYvj+AdgxB445ZsAMjrYt8pa97DOHWffYuXnaD7M376N77d/pgn9VXj9f+pIdXDb2adv7qKw5j9sb1T2r7U1l4wz48ma49kvoOrrm16tqxdkJPN0YE1rm9aPGmCo73dZHAge448M1rN13lBWPjsLDQ7tMNSjZabYcs+kbaN4eLngefPxdHVXDl3PEjjOI7F6+f3txEfz4kO0dFNEVIrrZh8ttB1V+rJIS24V0y7e2Jd/zIrv96F47F0+3cbamD/bTwn9i7CeFa528pGBWiu12qoOcquSyBC4itwG3AbRr127A3r17a3QBZ2LmugPc/+k6vrhjCAM7VPEATammqDAX3ptoH6he9ZF9LrDqTfvQ8rb50KLniX3nPQ2L/mVb5c7sUvjJFHv+P2x03jEbqcoSeE0/AyY7Sic4/ptS2Y7GmGnGmDhjTFxkZGRluznV6J4taebtyTe/HaiX8ynldryb2Rp4YCR8fLmd7qH3lXDPqvLJG+w4At8g+7A520kTxuUdg51zIWOffbCraqSmCXwWcIPj+xuAmc4JxzkCfL0YG9OS7zYcrJ8pZpVyR4EtYOpXMPgu211x0qu219DJglvbkbwZ++Gjy+xzjdraMdsOcIKaz62vqk7gIjIdWA50F5FEEbkZeBYYIyI7gDGOnxuUS89qQ0ZuIQu2pbo6FKUaroiuMP4fVdehOwyDyR/akscnU2z3ytrYPBM8Hb2A0rbX7lhNWJUJ3BhztTGmtTHG2xgTbYx52xhz2BgzyhjT1fHfasypWr/O6RJBRKAvX6/VMopSTtFtrJ3Hft9yeOM8SFxTs+MU5NgRsH2vsoOFNIHXWKPt2Onl6cHFfaOYtzWFjJxCV4ejVOMQezlc97Xti/72GDvitqjgzI6x0zF3UOzldtTryQn8yG47kEhVqdEmcLBllILiEn6IP+jqUJRqPDqPgDuXQZ+rbO+Ut0ZB8ubqv3/Lt7YrZPthtnRzcg18+at2YrRj9bRAixtr1Ak8tk0wnSMDtIyilLM1C4VLX4cpn9ipjqedB0tetA84i4sqf19RAWz7yTGvjLetwR/eWf49iasc/9W1YavSqBO4iHBZ/2hW7TnC/iM5rg5Hqcanx4W2B0u3cfDLX+HZdvBUOPy9pW1Fn7x03+5FkJ9xYvBQRDc7zW26Y3xIQY6dwgHggCbwqjTqBA4w6aw2eAh8smqfq0NRqnEKiLA9VK6dYYfnn/9nOw/66nfsXC6lgwULsu1Uwz5BdpELsAkcTtTBk36zUy14eNX8IWkT0mgWdKhMm9BmjO3Viumr9nHfyK4086nj9TKVaopE7BznpfOcGwMBkbDiVTs9btexdg3ZwzvtfO+lE4CFO0Z2pm23c6mXlk96TYJtP9jSSk2WEmwiGn0LHOB3wzqQnlPIN+u0Fq5UvRCxc8n3u9YuhffWaDt8/4ZZMOz+E/s1C7WLUpe2wPf/alcN6jbe9lRJ3eKS8N1Fk0jggzqG0at1MO8u3U19LmChVJPm4QEXvQz9r7dznd+51E5je7KIbrYnijF2EYvoQRDtWITEmQ8yv77DTsHbiDSJBC4i/G5YB7YnZ7Fs52FXh6NU0+HpZRegnvRq+VkUy4roahfITt8L2Sl2sfDmHe1CG856kJmVemJlpkakSSRwgIv6RhEe4MO7S3e7OhSlVFkR3ewC3aWt4+hBtgTTZoDzHmQmO3q2HFzvnOM1EE0mgft5e3Lt2e2YuzWFPWm1nMdBKeU8pQtV//YReAdAi1725zZxdum4vGOnvidxNbw21I7arI7SBH50t12Qo5FoMgkcYOrg9vh4evDCHJ17QakGo7QrYXI8tOl/otdJdBxg7JJ+ZeUehS9+Bymbql8SSd504vtDjWf+8SaVwFsE+3H7uZ2YtT6JNXsb3PxbSjVNwdHg5VjDNXrgie1tKniQaQzMvAcyk2ydfPM31TvHoXho3c9+34jKKE0qgQPccX5nWgX78eS3mykp0R4pSrmch8eJlX7KLgXXLNSunXqgTB181Zuw9TsY/QQMuduWWFK2nv74xYV2v07n2ZuFJnD35e/jxcMTurMhMYOvdcUepRqG0jJK2RY42DLKvhUw/xn48haY/RfoOg4G3+0Yji92bvHTSdtuh+u3jIXWfTSBu7tL+rahb9tQ/vnTVrLzTzPxjlKqfvS7BobcY4fll9VhOOQegYXPwf6Vds6VSa/bVntQK2g3pOoySmn9u2UstO5rE3ptF6RoIJpkAvfwEP56US9SMvN5ZV6Cq8NRSnUZDeOePnV736vh/g3wf8nw+412AeaA8BOvx0yClM2Q6uiYUFQAa963DzpLHdoInj62t0vrvoA5MWHW6RTmQX5Wba6qzjXJBA7Qv11zrhwQzVuLd7HtkC6qqlSD5OEBzduDl2/Fr/e8GFtG+cbOZPjpNfDtfbDwXyf2Sd5k5x339HYkcKpXRvnqVvjgktpeQZ1qsgkc4NELehLk58Wfv96oDzSVckfBraHdYNj4hV1wOeEXO0HWuo/t3Ctguye2jLXfB7W2k2xVlcCP7LYLTyT9BkX5dXsNtdCkE3hYgA9/ubAXa/Ye5bPV+10djlKqJnpNsnXtxNVwxTtw4Qt2ZOfmmXYIfVbyiQQuYlvhVSXwX98CjJ3aNnVbHV9AzTXpBA5wef82DO4UxrM/biUtq+HeaZVSleh9BXQeCVdPh9jL7IRZYZ1h9bsnRmC2jDmxf+u+dpbDwryKj1eQDb99CK362J/LDgJqYGqVwEXkfhGJF5FNIvJ7J8VUr0SEv0/qTU5BEc/9VEV/UqVUwxMQYRdaLp2LXATifgf7V8DGGXZbq94n9m/dF0qK7MPPimz4zC4NN/4f4OlrR3zWhjGnrkzkJDVO4CISC9wKDAL6AhNFpKuzAqtPXVoEcsOQDnyxJpGthyqYd0Ep5V76XmOT77qP7HzjZbsnnu5BpjGwcpptfbcfBi161L4FnrYdnusACXNrd5wK1KYF3hNYYYzJMcYUAQuBS50TVv27Z2QXgny9+McP2gpXyu0FhEMvRw+S0vp3qdD20CwMVr5x6ijOPYtteeXsO2xLvkVM7RP4vuW2Rd+8Q+2OU4HaJPB44FwRCRcRf+ACoO3JO4nIbSKyWkRWp6am1uJ0dSvU34d7R3Zl4fZUluxIc3U4SqnairvJ/rds/RtsYr5sGmSnwhvnwrL/woG1MPdv8M1ddh7y2MtPvDcrGbJrkRP2Lrc9X8I61fwYlahxAjfGbAH+CcwBfgLWA6cMazTGTDPGxBlj4iIjI2scaH24bkh72oQ245kftmi3QqXcXbvBMP7ZE4m8rK5j4K4VdgDR7L/AmyNgyYu2lXz5WyfW7CxN/rVphe9bZkeMitT8GJWo1UNMY8zbxpj+xphzgSPADueE5Rp+3p78aXx3Nh88xow1ia4ORylVGyIw+E4I61jx64GRMOVjuOpjOzz/oQS48Tvbo6VUaQKv7IFnVTIOQPo+aD+0Zu+vQq2WexaRFsaYFBFpB1wGDHFOWK5zUZ8oPlqxl8dnxdMrKpjYNiGuDkkpVVdEoOfEyl8PbGHLH8nVGHpfkX3L7X/bDa7Z+6tQ237gX4rIZuBb4G5jzNGq3tDQeXgIr107gDB/H255fzUpxyrpK9rAZeQUciS7wNVhKOX+WvSqeQll33LwCYSWvavetwZqW0IZbozpZYzpa4xxfh8ZF4kM8uXNG+LIyC3k1g9Wk1dY7OqQztg909dy0StLyMwrdHUoSrm3lrG2t0pJBXng0EZY857tfliRfSvsFLmetSp2VKrJj8SsTExUCP+5qh/rEzN49KuNmMr+QA1QVn4RK3Yd5kB6Ln//bourw1HKvbWMgaLc8utvFuXDvKdh2vnw7f3lF50olZtuW+51VP8GTeCnNT62FX8Y3Y2vfzvAJ6v2uTqcalux8zCFxYazO4bx2er9zNua7OqQlHJfLR2LLJeOyDy0Ed44DxY9Z7sbevnB+umnvm//SsDUWf0bNIFX6d6RXTi3WyRPztrMxsSMCvfZ4ui10lBKLYt3pNLM25O3bxxIj1ZBPPzlRo5qPVypmonsAeJhW9Nbf4C3x9qBOdfOsP3Je1wI8V/aucjL2rccPLyhTVydhaYJvAoeHsKLV/UjPNCHuz5ZQ0ZO+ZpySmYe17+zige/WM85/5zHf+ftID3n1GS5es8Rnpi1iWPVrEmXlBg+XbWPpPTcU15btz+9wnOUWrwjjcGdwgj09eLfk/tyNLuAh2ZsoKCobuZjqA9r9x3lgc/Xk1/UMG6SqgnxbmanqF37gZ1vPLIH3LbgxNwrfa+2C0jsmF3+fXuXQ1Q/8PGvs9A0gVdDWIAPr17bn4Ppedz+0erjybO4xHD/9HVk5hXy/JV9iW0TwvOztzP8ufm8t3Q3RcUlGGP4cPkepkxbwXvL9nDr+9V7KPrthiQe+Woj17y5gtTME7Mkfr56P5NeXcodH62psC6//0gOu9KyGd7VDpqKiQrhzxf05JctyVz/zspTbkCliksM+4/knLLdGLu9ps8Apr61khdmn9l0nEXFp95oXp2XwJdrE5m2cFeN4lCqVlrGQOZB6HUx3Pg9BLU88VqnERDQonwZpTAPktbWafkENIFXW/92zXn+yr6s2XuUS15dyvbkTF76ZTvLdx3m75N6c8WAaN773SB+vH84/dqG8sS3m5n4yhLu/3Qdj83cxPCuETx9aSyr9hzhnk9+O56k8gqL2ZSUUS5BFhSV8O/Z22kf7k/ysXyuf2cVGbmFfPPbAR7+cgNRIX6s2HWEn+IPnRLnYsc0AOd2OzHq9aZzOvLCZBv7Za8vZd/hUxP1o19tYPhz83ltQcLxWAqKSnjky40Mf24+F7y8hC/XJJ5RK37f4RyWJKTxyvwEVu85UuX+OQVFXP/OKia8tJjCMkk8LSufBdttWeiV+QnsPVy79QwTUrLIKdC1UNUZOPdPcPErcMV7p7aoPb2gz2TY/jPkOP6dx8+A4gJoV3cPMAGkPntXxMXFmdWrV9fb+erCmr1HuP3DteQUFJFbWMyVA6J57oq+5fYxxvBT/CGe+m4zSRl53DeqK78f1RUPD+GD5Xt4fOYmRvVogQGW7Uwjr7CEe0d24YGx3QGO7/Pu7wbiIcIt7/9Kh/AAdqZmcXbHcN68IY4rXl9GZl4Rcx84Dz9vz+PnvvOjNazfn87SR0YiJw3dXbHrMLd/uAZvT+H9mwYRE2UHKX2xej8PzdhAp4gAdqVlc1VcWx4c1517p69lxa4jXDkgmvWJ6WxPziIi0JfhXSPo3745vVoHsykpg/lbU1i95yhPX9abi/tGHT/fhyv28tg38YQH+BDSzJsf7h9eLtayMvMKuem9X/l1jx1K8OJV/Zh0VhsA3l6ym6e+28xHN5/NHR+tYUD75rz3u4GICD9vOsQXqxP50/judGsZVOXfLyUzj2HPziO2TQif3DKYZj4Vx1PqaHYBP8YfIirUj/O7t6jy+KqJOrgB3hgOFzxvf/7hIWh7Nlw/88Sw/FoQkTXGmFOK6ZrAa+BgRi53fbyW4hLDZ7cNqTQJ5BQUkZSeS5cW5RPLy3N38MKc7bQL82dkjxakZeXz3YaDPH1pLJP6teG8f82nc2Qgn942GBHhuw1J3Dv9Nwa2D+O9mwbi7+PF8p2HufrNFfxxTDfuG2Vn8S0qLuGsp+ZwQWxr/nlFnwpjSkjJ4rq3V5KVX8R7vxtEgK8nk15dylltm/PhzYN4ee4OXp6XgI+XBxj45xW9ufSsaIwxLN6Rxqe/7mPV7qPlFr9oH+5PVl4R3VoGMf22Ex8Zb/1gNVsOHuPZy/ow9e2V3H5uJx69oCcA6TkFpGbm4+khlBjDA19sYNOBDP5zVT9enrsDTw/hx/uHIyJc+PJiPD2EWfecw7tLd/Pkt5t56pIYVu4+wncbDiICgb5eTLsujiGdw0+55rLeW7qbJ77djAiM6tGC/00dgJfnqR9EV+w6zNtLdrNgWwqFxYZgPy9W/nl0ub91SmYe6/al0yc6lFYhFf9PWlJiSMnMr/R11UgYA68Pg4xEyM+A7hfY1YG8mznl8JUl8LrpXd7ItQ5pxld3DsUY+5CzMv4+Xqckb4D7RnXl2rPbERbgg4hQWFxCVn4Rj30Tz9wtKaRlFTDt+h7HW9AT+0TRq3UwUaHNjrdgh3QO54LerXhtQQJXDIgmKrQZ6xMzyMwrKlc+OVmXFoF8cccQpr61kqlvrSQ80IcgP29eurofXp4e/HFsd9qFB9hEeXEMcR3CALvwxbndIjm3W6SjLp7L5oMZdG8VTMeIAF6Ys53/zttBSmYeLYL8KCgqYfnOw1zcL4pzukZw9aC2vLl4F4XFhrX7jrI+Mb3c2AcfTw9eu7Y/Y2NakVdYzEMzNrBoRxotg33ZlHSMJy6yXbmuG9yeGWsSeWzmJnw8PXhwbDcm9onilg9Wc/07K3nm0t50bxVEUnoe6TkFXNwvCn+fE//Mv9twkO4tg5g6pD2PfRPP/30Tzz8u613u08rC7anc8v6vhPr7cOPQDnSKDOTRrzby7fokJg88MeHmQ19sYOF2O8NmVIgfQ7tEcNf5nekUGQjAoYw8HpqxnsU70nj+yr5cMSC60r9LWSUl5rT/rlQDJAL9rrETY/W/wS7rVkeDd8qdVlvgDUN2fhFTpq1g44EMxvZqybTrq+56tP9IDqNfWEiQnxcTYluTlV/EN+sO8NtjYwj19znte1My87j+7VVsT87k41sGV9lyrcr25EzG/mcRf7skhuuHdGDFrsNMmbaC/00dwPjYVhzLK2TCi4s5mJFLv7ahnNstks6RgZQYQ1GxoWfrYHpFBQO29n7uc/PpGBFA7+gQ3lmym1V/GU1YgL2mrYeOMW3hLu48vzNdHWWTjJxCbvtwNSt3l6+13z2iMw+N6wFAUnouQ5+dx4Nju3HPyK78e/Y2XpmXwKR+Ufz5gp60CPZjzd6jTH1rJR0iAvj0tsGENPPGGMO4Fxfh4+XBt/ecg4iwbn86k15dyo1DO9AuzJ81+44yf2sK+UUlTI6Lpl/bUJ75YSsFRSV0jAhgW3Imb90QxwhHGSanoIgF21IZ2aNFubJSQkoWU6YtZ1SPlvxtUgy+Xqcv8agGpLjIDuhpO8jpMw9qCcUNpGbm859ftnPneZ1pG1a9rkcrdh3mw+V7mbs1mbzCEvq2DWXm3cOq9d7sfFvi6VqN2nF1jP3PQkL9ffj89iE899NW3li0i98eH0OwnzfA8R4wIf7eVR7rzUW7ePqHLQT4eDK0SwRvVuOGll9UzE/xh2jm7UlUaDP+Oy+BxTtSWfzwSMICfI4fc8GD59MhIgBjDP+Zs53XF+7Ex9ODG4Z24OOV+wj19+aLO4bQIuhE2ePD5Xt4bOYmvrl7GP3ahnLze7+yZt9Rljw8kkBf29JKzczn1fkJfLxyL4XFhn5tQ/nPVf2ICPRhyrQV7ErN5sObB7Hl4DFemptAWlY+53aL5M3rB+Dr5UlmXiGXvLqU5Iw8sguKiWvfnP9dN4CIQN9TrnX5zsP4eHkwoH3zSn8few9ns25/OpFBvrQK9qNN82Z6Q3BTmsAbuez8IhbvSKVTZGC1HubVhZd+2cGLc7ez4tFR3Pz+rzTz9uSLO2r2FD4zr5Chz84jM6+I/03tz/jY1md8jO3JmYx7cRF3nteZP43vwSX/XUKxMXx37/By++1Jy+bpH7YwZ3MyLYN9mXHH0FNuoJl5hQx+Zi7jY1vzu2EdmPjKEh4Y0417R526iuD+Izms2XuUiX1aH6+vp2Tmcfnry9h/xPbrH9QxjCGdwnlp7g7G9mrJf6/pz92frGXe1hQ+vuVs0rLyeeDz9UQE+vLilH4MdJSyjDH8d14C/56zHYDxMa14ZEIPOkQEHD9/QVEJ/1u4k//OTyjXa6hdmD8//X54uZKScg9aA2/kAny9apTknOnCPq35zy/b+XD5XuIPHOOBMd1qfKwgP29uHd6Jz37dz4geNev90a1lEBf2bs37y/YwNqaVnddmQo9T9usQEcCb18exdt9RWgb70Sb01AdPQX7eXNq/DZ+vTuRgRi5Bfl7cMKxDhedtG+Z/yg2gRZAfH9x0Nv+Zs51L+7fh/G6RiAjN/b154tvNjH9xEbvSsnl8Yi8Gd7LlrHZh/tz+4Rqu/N9yRvVowb2juvLOkt3MWp/EpH5RdIoM5H8LdzJ3azLndYukRbAf4QE+/BR/iB0pWUzs05o7zuvMsbxCNicd4+/fb+HLtQe4bnD7Gv0+VcOjLXDlVONfXMSu1GwKikuYefcw+rYNrfGxjDFVPiiuyo7kTMa+uIgWQb4kH8tnycMjiG5es5FxWw8dY/yLiwH7IPqPtbhBlfXaggSe+2kbk/pF8Z+r+pV7oJpTUMS7S/fwxsKdHMsrQgQeGtedO8/rjIiQciyPl+buYPUe2zPoSE4BbUKb8dQlseVufMYYJr22jGO5hcz943n6kLSM7PwiPD2k0i6uDYG2wFW9mNinNc/P3k5zf+9aL4YhIrV+FtS1ZRAT+0Tx7fokzmoXWuPkDdCjVTCDOoSx+eAxbqqk9V0Td53fhXO7RtK9VdApfff9fby4e0QXpp7dng+W7yG2TUi5xNwi2I+nLz0x13RxiUE49aYnItw6vCP3fPIbc7emMKZXS5R1y/uradO8Gc9f2bfqnRsYHYmpnOrCPnYgzzldI/FsIK28+0d1wcfTg8v6V68b3+m8OKUfn90+uMpePmcqtk0I3hX0Ry8V4u/NvaO6VllO8vSQSlvX42Na0Sa0GW8trnw6goqmMWjsElKz2HromKvDqBFN4MqpOkYE8MRFvbhnRBdXh3JclxZBLH1kJNcOalfrY0WFNjs+gtXdeHl68LthHVi5+0iFM2u+s2Q3vf76M8//vM2tJz47EyUlhiPZBRxMd8+VtzSBK6e7cVhHurdyTU+YykQG+WrdF7hqYFuCfL1486RW+PvL9vC37zYTFeLHf+cnMOnVpWw7lOmiKOvP0ZwCiksMh7MLGsx00GdCa+BKNSFBft5cfXY7pi3axYH0XK4Z1I5jeYU8+e1mxvRqyavX9Gf+thT+/NVGLnplCVfGRXPbuZ1oHx5Q9cHdUFrWiWmZD2bk0THCva5TE7hSTcwfx3SjRZAvn6zcxwNfrAdgdM8WvHpNf3y8PBgX04q49s15fvZ2vlidyPRV+7igd2uevDiG8AoGFbmzsnP6JKXnagJXSjVsft6e3DK8Ezef0/F4Pfz6oe3tBGYO4YG+/OOy3vxhdFfeXrqbd5fuITOviHdvHNioSlEnJ3B3U6sauIj8QUQ2iUi8iEwXEZ1yTSk3ISIM7hTOred2qnSIfYtgPx6d0JPHLuzJwu2pvLdsT/0GWcfKLpaS5IYPMmucwEWkDXAfEGeMiQU8gSnOCkwp1XBMHdye0T1b8OyPW9mc5Jwud8t2pvHNbweccqyaSssqwNtTiAj0aXotcGwJppmIeAH+QFLtQ1JKNTQiwj8v70OIvzf3f/pbhSsa5RYUU1xS8cjusiO+jTG8u3Q3U99aye8/W8fMda5L4mlZ+YQH+NImtBlJGe6XwGtcAzfGHBCR54F9QC4w2xgz++T9ROQ24DaAdu1q3w9XKeUa4YG+vDC5L9e9vYpzn5vPdYM7cO3gduxMyeLjlfv4Mf4gNwzpwP9N7FXufde/s4qtB49xUd8oLuobxYw1+/loxT7G9mpJek4hf5qxgU4RgfSOrv/+9WlZ+UQE+dA6pBk7Utyv22SN50IRkebAl8BVQDrwBTDDGPNRZe/RuVCUcn8rdh3mjYU7mb8tFRG7GE2Qnxetgv04kJ7L8kdHEdLMThm8fn86l7y6lB6tgo7PkQNw+3mdeHhcD47kFHDJf5dSYgyz7jmHyKD67eUy8ZXFRAT60ikikE9/3cemJ8edMp1BQ1AXc6GMBnYbY1IdJ/gKGApUmsCVUu5vcKdwBncKJyElkxlrDtAxwp+L+kaxOy2bC19ewue/7ufWczsB8O7S3QT6evHFHUMoKYGfNx0iIsiHkT3sXCwRgb5Mu34Al7++jLs/WctnjmUEq2NXatbx1Y9qKi2zgB6tgokK9SOnoJiM3EKnT5NQl2pTA98HDBYRf7G/8VHAFueEpZRq6Lq0COKRCT24amA7/H28iIkKYVDHMN5fvofiEkPysTy+23CQK+OiCfLzJsTfm8kD2x5P3qViokJ4fGIMq3YfYd7WlGqde/7WFEb+eyG/7jlS9c6VMMZwODufiEBfohxTCLtbT5QaJ3BjzEpgBrAW2Og41jQnxaWUckM3DetA4tFc5mxO5sPleyk2hhuHdqjyfVfGRdM2rBkvz91Bdcq6M9YmArA0Ia3c9sy8Qi57bSlr9x2t8hjHcosoLDZEBPrQ2rHotLv1RKlVLxRjzF+NMT2MMbHGmOuMMflVv0sp1ViN6WVnPJy2aCcfr9zL6J4tqzUM39vTg7vO78L6xIzjC0VXJju/iLlbkgFOaYEv23mYtfvSmb0pucpzpjoG8UQG+R5fxOOgm/VE0cmslFJO4+kh3DC0PWv3pXM0p5Cbz+lY7fde3j+aqBC/Klvhczbb9V97twlh7d50CstMgVvaIt+UdOpsiycrHYUZEehLRKAv3p7CgaZSQlFKqYpcFdeOZt6e9GodzNkdw6r9Ph8vD+4c0YW1+9JZtvNwpfvNXHeAqBA/bju3E7mFxWwqM7BoiSOBbzyQUWUppmwC9/AQWoX4aQtcKdW0hfh78/aNcbw0pd8Zd8mbHBdNq2A//vXztnLzlJQ6ml3A4h1pXNQ36vjNYbWjjHIwI5ddqdl0igggPaeQA1XUs9MySxO47XXSOqRZ06qBK6VURYZ2jqBryzOfE97Xy5MHx3VnfWI6w56dx+Mz49l/JOf46z/EH6SoxHBxvyhaBPvRPtyfVbttAl+aYFvttzm6MMYfOP2Q/7SsAjw9hOaOboNtQps1nV4oSilVF64YEM0vfzyPSf3aMH3VPkY8v4DHvoknNTOfmeuS6BwZQK/WwQDEtQ9j9d6jGGNYmpBGeIAPl/Rrg6eHEH/g9HXwtKx8wgJ8js+u2DrEj0PH8iqdDqAh0gSulGpwOkcG8s8r+rD4TyOZMqgt01ft47x/zefXPUe4uG+b46WZQR2bcyS7gJ2pWSxNSGNolwia+XjStUUg8VU8yLTzoJwYtBMV2oziElNuhsKGThO4UqrBahXix98n9WbOH89jRI8WBPp6celZbY6/PrCDrYN/snI/KZn5nNMlHLCLRMdX8SAzNaug3ND9qFDbF7yq2nlDogs6KKUavI4RAbx6TX+MMeUejHaMCCAi0IePV+4FYFiXCABio4KZsSaR5GP5tAqpeJmCtMx8OpVZgSeqXF/w5nV0Jc6lLXCllNs4uVeLiBDXPoz8ohLah/sT3dwfsC1woFwd/Eh2wfE+48YYOxNh4IkSSuuQ0uH07tMC1wSulHJrAx3dCUtb3wC9ooIR4XgdPCk9l/Oem8+/Z28HICu/iPyiEiLKrPEZ7OdFoK+XW/VE0QSulHJr53SJQARG9WhxfJu/jxedIwOPt8D/OmsTmflFzFp3gJISc3w1+rIJXERoHeKnLXCllKov3VsFseyRkYzqWX6Ww9ioYOIPHOPnTYeYszmZ/u1CScrIY31i+olRmCfNPx4TFczShDSSj1XeCk9Kz+XnTYecfyE1oAlcKeX2SuvXZcW2CeHQsTz+8vVGerYO5q0bBuLtKfwYf+iUUZil/jCmG4Ulhqe/r3xm7Odnb+OOj9aQmVfo3IuoAU3gSqlGqfRB5uHsAp65NJawAB/O6RLB9xsOnpiJMLB8C7x9eAB3nNeZWeuTWLYz7ZRjFhWXMHdLCsbgtMWda0MTuFKqUYqJCsbP24PrB7fnrHa2W+CE3q05kJ7L/K0piEBYwKmr79x1fmeimzfjrzM3lZvpEGDVniNk5NqWd7wmcKWUqhtBft7Me+B8Hr8o5vi2sb1a4uUhLNieSnN/H7w8T02Bft6e/PWiGHakZPHe0j3lXpu9KRlfLw/CA3zYVMVQ/fqgCVwp1WhFhTbD0+NE3/FQfx+GdonAmFPr32WN7tmCEd0jeXnuDo5m2x4rxhjmbE5meNcIzmoXWuVQ/fqgCVwp1aRcENsKKN+F8GQiwqMX9CS7oIjXFiQAsCnpGAfScxnbqxUxUSEkpGSRU1BULzFXRhO4UqpJGRvTCk8POW0CB+jWMojL+kfz/vK9HEjPZfbmZDwERvVsQWybEEoMbDmYWeX5jmQXcPW0FWxITHfSFZygCVwp1aSEBfjw9KRYbqjGYst/GNMNgJd+2c7sTYeIax9GeKAvsW3sdLZll24rKTEkpGSdcoz3lu5mxe7D+Pt4OucCytAErpRqcqYMaseA9lVPWNUmtBnXD27PjDWJbD2UydgYO1ioVbAfEYE+bEw8kcA/XLGX0S8sZFGZRZkz8wp5b9kexvVqRZcWZ77ARVVqnMBFpLuIrCvzdUxEfu/E2JRSyuXuHtGFAB87ceuYXjaBiwgxUSHHuxIaY3h/2R4AHp8ZT15hMQAfr9zHsbwi7hrRuU5iq3ECN8ZsM8b0M8b0AwYAOcDXzgpMKaUaguYBPvzlwp5c3j+a9uEnpp+NbRPMjuRM8gqLWbbzMLvSsrliQDR7DufwxsJd5BUW89bi3QzvGkGf6NA6ic1Z84GPAnYaY/Y66XhKKdVgTBnUjimD2pXbFhsVQlGJYduhTD5cvpewAB/+PimW3MJiXl2QQGZeIWlZ+dw94qw6i8tZNfApwPSKXhCR20RktYisTk1NrWgXpZRyO6VD9X/ZksycLclMjmuLn7cnj0/shY+nB28t2c2A9s052zHdbV2odQIXER/gYuCLil43xkwzxsQZY+IiIyNrezqllGoQops3I6SZN28s2kWJMVx7tm2htwz244+O3iv3jOxyyiIUzuSMEsoEYK0xJtkJx1JKKbcgIsS2CWZpwmFG9mhB2zD/46/9blgHxsa0PL5CUF1xRgnlaiopnyilVGMWG2XLKNcNbl9uu4jUefKGWrbARcQfGAPc7pxwlFLKfUwe2BZvTw/O7eaa8nCtErgxJgcId1IsSinlVjpHBvLguO4uO7+OxFRKKTelCVwppdyUJnCllHJTmsCVUspNaQJXSik3pQlcKaXclCZwpZRyU5rAlVLKTYkxpv5OJpIK1HTK2QggzYnhuIumeN1N8ZqhaV53U7xmOPPrbm+MOWW4Z70m8NoQkdXGmDhXx1HfmuJ1N8VrhqZ53U3xmsF5160lFKWUclOawJVSyk25UwKf5uoAXKQpXndTvGZomtfdFK8ZnHTdblMDV0opVZ47tcCVUkqVoQlcKaXclFskcBEZLyLbRCRBRB5xdTx1QUTaish8EdkiIptE5H7H9jARmSMiOxz/be7qWJ1NRDxF5DcR+c7xc1O45lARmSEiWx1/8yGN/bpF5A+Of9vxIjJdRPwa4zWLyDsikiIi8WW2VXqdIvKoI7dtE5FxZ3KuBp/ARcQTeBW7eHIv4GoR6eXaqOpEEfCAMaYnMBi423GdjwBzjTFdgbmOnxub+4EtZX5uCtf8EvCTMaYH0Bd7/Y32ukWkDXAfEGeMiQU8gSk0zmt+Dxh/0rYKr9Px//gUIMbxntccOa9aGnwCBwYBCcaYXcaYAuBT4BIXx+R0xpiDxpi1ju8zsf9Dt8Fe6/uO3d4HJrkkwDoiItHAhcBbZTY39msOBs4F3gYwxhQYY9Jp5NeNXcKxmYh4Af5AEo3wmo0xi4AjJ22u7DovAT41xuQbY3YDCdicVy3ukMDbAPvL/Jzo2NZoiUgH4CxgJdDSGHMQbJIHWrgwtLrwIvAnoKTMtsZ+zZ2AVOBdR+noLREJoBFftzHmAPA8sA84CGQYY2bTiK/5JJVdZ63ymzskcKlgW6Pt+ygigcCXwO+NMcdcHU9dEpGJQIoxZo2rY6lnXkB/4HVjzFlANo2jdFApR833EqAjEAUEiMhU10bVINQqv7lDAk8E2pb5ORr70avRERFvbPL+2BjzlWNzsoi0drzeGkhxVXx1YBhwsYjswZbGRorIRzTuawb7bzrRGLPS8fMMbEJvzNc9GthtjEk1xhQCXwFDadzXXFZl11mr/OYOCfxXoKuIdBQRH2zBf5aLY3I6ERFsTXSLMeaFMi/NAm5wfH8DMLO+Y6srxphHjTHRxpgO2L/rPGPMVBrxNQMYYw4B+0Wku2PTKGAzjfu69wGDRcTf8W99FPY5T2O+5rIqu85ZwBQR8RWRjkBXYFW1j2qMafBfwAXAdmAn8BdXx1NH13gO9qPTBmCd4+sCIBz71HqH479hro61jq7/fOA7x/eN/pqBfsBqx9/7G6B5Y79u4ElgKxAPfAj4NsZrBqZj6/yF2Bb2zae7TuAvjty2DZhwJufSofRKKeWm3KGEopRSqgKawJVSyk1pAldKKTelCVwppdyUJnCllHJTmsCVUspNaQJXSik39f8fecSwtXLkbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(64, input_dim=10, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(16, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(8, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=1500, verbose=1)\n",
    "y_pred=reg_model.predict(X_test_std)\n",
    "train_mae = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mae = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mae, test_mae))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean absolute Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e4a56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=r2_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77eb195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1690856401389571"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= len(X_train)\n",
    "p = len(X[1])\n",
    "adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "adj_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99359c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1568aa2e",
   "metadata": {},
   "source": [
    "# Stacked AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8d228cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "batch_size = 32\n",
    "input_dim = X_train[0].shape[0] #num of predictor variables \n",
    "learning_rate = 1e-4\n",
    "input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "#Input Layer\n",
    "encoder = Dense (100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "#Encoder’s first dense layer\n",
    "encoder = Dense (50, activation=\"relu\",\n",
    "activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "#Encoder’s second dense layer\n",
    "encoder = Dense (25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Code layer\n",
    "encoder = Dense (8, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s first dense layer\n",
    "decoder = Dense(25, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s second dense layer\n",
    "decoder = Dense(50, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Decoder’s Third dense layer\n",
    "decoder = Dense(100, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Output Layer\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\", activity_regularizer=regularizers.l1(learning_rate))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f0cebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 1.2595 - accuracy: 0.1257\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2302 - accuracy: 0.2286\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1804 - accuracy: 0.2286\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1124 - accuracy: 0.2286\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0687 - accuracy: 0.2286\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.2286\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9987 - accuracy: 0.2457\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9568 - accuracy: 0.2686\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9226 - accuracy: 0.2971\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8977 - accuracy: 0.3657\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.3829\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.3943\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8680 - accuracy: 0.3314\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.3029\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8504 - accuracy: 0.3029\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8409 - accuracy: 0.3029\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.3200\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.3314\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.3714\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.4514\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7923 - accuracy: 0.4857\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7862 - accuracy: 0.4857\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.4914\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.4914\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.4971\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7732 - accuracy: 0.5029\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7714 - accuracy: 0.4971\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.4971\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.4971\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7675 - accuracy: 0.4914\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7664 - accuracy: 0.4914\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.4914\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7640 - accuracy: 0.4857\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7629 - accuracy: 0.4800\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7610 - accuracy: 0.4686\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7590 - accuracy: 0.4571\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.4457\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.4571\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.4457\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.4571\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.4743\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.4571\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.4686\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.4514\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.4171\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.4057\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.4114\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.4057\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.3943\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.3943\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7368 - accuracy: 0.3943\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7361 - accuracy: 0.3657\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7356 - accuracy: 0.4457\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7350 - accuracy: 0.4400\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.4571\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.4343\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.4400\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.4400\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.4400\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7318 - accuracy: 0.4400\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.4629\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.5314\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.5314\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.5371\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.5486\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.5600\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.5771\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.5486\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.5486\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.5257\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.5371\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.5429\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.5371\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.5429\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.5486\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7246 - accuracy: 0.5543\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.5771\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.5829\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.5886\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.7199 - accuracy: 0.5257\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.5600\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.5314\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.5429\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.5314\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.5371\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.5143\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.5257\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.5257\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.5143\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.4971\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.4971\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.4971\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.4971\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.4971\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.4971\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.4914\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.5086\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.4971\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.4971\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.4971\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.4971\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.4800\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.4743\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.4743\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4743\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.4743\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.4914\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.4743\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.4743\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.4914\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.4114\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.4000\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.4057\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.4229\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.4514\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.4514\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.4857\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.4629\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.4971\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.5143\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.4971\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5314\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.5200\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.5257\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.5143\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.5314\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.5257\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5257\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.5371\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5371\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.5314\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5429\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.5314\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.5257\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.5486\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5543\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.5600\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5257\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.5429\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.5486\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.5600\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7056 - accuracy: 0.5543\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.5429\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5600\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.5543\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.5371\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.5429\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.5486\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.5371\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.5371\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.5429\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5429\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5371\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.5429\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5429\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5371\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5371\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5429\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.5429\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5371\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.5371\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5429\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5543\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5429\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5429\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5600\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.5486\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.5429\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5657\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5886\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5486\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.5543\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5429\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5543\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5714\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5886\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5486\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5829\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.5886\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.5600\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5714\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.5771\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5829\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5543\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.6000\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5714\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5829\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.6000\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5829\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.6114\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5429\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.6229\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.6000\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.6229\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6000\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6000\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.6286\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.6229\n"
     ]
    }
   ],
   "source": [
    "autoencoder_1 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_1.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_1 = autoencoder_1.fit(X_train, X_train,epochs=200,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d6d72642",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2_input = autoencoder_1.predict(X_train)\n",
    "autoencoder_2_input = np.concatenate((autoencoder_2_input , X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c802fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.6371\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.7514\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.7200\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.7314\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.7057\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.7429\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.7371\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.7543\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.7600\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.7629\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.7800\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7686\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.7800\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.7914\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.7771\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.7657\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.7714\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.7743\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.7686\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.7771\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.7771\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.7686\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7800\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7743\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.7657\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.7714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.7771\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.7800\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.7743\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.7771\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.7743\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7771\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.7686\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.7714\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.7714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.7771\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.7629\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.7714\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.7571\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7657\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.7686\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.7571\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.7686\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7743\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.7686\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.7657\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.7686\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.7657\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.7657\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.7629\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7743\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7714\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.7629\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.7657\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7629\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7657\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7571\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7571\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7657\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7629\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7543\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7514\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7543\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7571\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7657\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7686\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7686\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.7514\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7600\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.7486\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.7629\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7429\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7600\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7657\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.7571\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7629\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7486\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7629\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.7486\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.7543\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7514\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7543\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.7571\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.7571\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.7457\n"
     ]
    }
   ],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_2.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a793d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)\n",
    "autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "57d2cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 1ms/step - loss: 0.1772 - accuracy: 0.8429\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8486\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8429\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.83 - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8400\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8514\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8386\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8400\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8357\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8286\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8300\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8429\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8443\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8443\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8514\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8371\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8200\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.8343\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8371\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8514\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8471\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8357\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8400\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8371\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8343\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8429\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8371\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8486\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8457\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8457\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8471\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8400\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8329\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8343\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8386\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8329\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8371\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8500\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8429\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8429\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8514\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.8500\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8443\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8543\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8443\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "autoencoder_3 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_3.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "22ff8a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = Model(input_layer, encoder)\n",
    "X_ae1 = encoded.predict(X)\n",
    "X_ae1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "95838d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318800</td>\n",
       "      <td>1.074501</td>\n",
       "      <td>0.925603</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.445664</td>\n",
       "      <td>1.522639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.319359</td>\n",
       "      <td>1.074960</td>\n",
       "      <td>0.925644</td>\n",
       "      <td>0.060706</td>\n",
       "      <td>0.445611</td>\n",
       "      <td>1.522937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.320340</td>\n",
       "      <td>1.075920</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>0.060442</td>\n",
       "      <td>0.445836</td>\n",
       "      <td>1.523598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.324142</td>\n",
       "      <td>1.079639</td>\n",
       "      <td>0.924848</td>\n",
       "      <td>0.059435</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.526168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.328306</td>\n",
       "      <td>1.083765</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.450805</td>\n",
       "      <td>1.529232</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6    7\n",
       "0  0.0  1.318800  1.074501  0.925603  0.060879  0.445664  1.522639  0.0\n",
       "1  0.0  1.319359  1.074960  0.925644  0.060706  0.445611  1.522937  0.0\n",
       "2  0.0  1.320340  1.075920  0.925472  0.060442  0.445836  1.523598  0.0\n",
       "3  0.0  1.324142  1.079639  0.924848  0.059435  0.446809  1.526168  0.0\n",
       "4  0.0  1.328306  1.083765  0.925408  0.058882  0.450805  1.529232  0.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AEC_df = pd.DataFrame(data = X_ae1)\n",
    "AEC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d3bdfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(AEC_df, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4b13aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.6264 - val_loss: 13.2338\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.5360 - val_loss: 13.1645\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.4580 - val_loss: 13.0987\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.3793 - val_loss: 13.0307\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.2989 - val_loss: 12.9637\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.2186 - val_loss: 12.8912\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.1326 - val_loss: 12.8123\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 10.0392 - val_loss: 12.7254\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.9429 - val_loss: 12.6371\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.8498 - val_loss: 12.5520\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.7631 - val_loss: 12.4627\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.6735 - val_loss: 12.3760\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.5893 - val_loss: 12.2789\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.5006 - val_loss: 12.1788\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.4137 - val_loss: 12.0560\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.3140 - val_loss: 11.9416\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.2207 - val_loss: 11.8141\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.1140 - val_loss: 11.6893\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.0202 - val_loss: 11.5697\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.9406 - val_loss: 11.4437\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8576 - val_loss: 11.3089\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.7886 - val_loss: 11.1799\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.7254 - val_loss: 11.0509\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.6724 - val_loss: 10.9309\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.6134 - val_loss: 10.8218\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.5674 - val_loss: 10.7090\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.5201 - val_loss: 10.6021\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4864 - val_loss: 10.5066\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4548 - val_loss: 10.4318\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.4373 - val_loss: 10.3717\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.4131 - val_loss: 10.3276\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3888 - val_loss: 10.2911\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3794 - val_loss: 10.2605\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3605 - val_loss: 10.2273\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3492 - val_loss: 10.1983\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3463 - val_loss: 10.1870\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3306 - val_loss: 10.1745\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.3247 - val_loss: 10.1827\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3163 - val_loss: 10.1721\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3073 - val_loss: 10.1740\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2978 - val_loss: 10.1459\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2851 - val_loss: 10.1134\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2710 - val_loss: 10.0873\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.2639 - val_loss: 10.0730\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.2525 - val_loss: 10.0697\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2436 - val_loss: 10.0708\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2350 - val_loss: 10.0771\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.2229 - val_loss: 10.0673\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.2138 - val_loss: 10.0111\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1999 - val_loss: 10.0046\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1957 - val_loss: 9.9787\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1793 - val_loss: 9.9640\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.1677 - val_loss: 9.9516\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1611 - val_loss: 9.9239\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1629 - val_loss: 9.8727\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1436 - val_loss: 9.8729\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1420 - val_loss: 9.8794\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1210 - val_loss: 9.8664\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1124 - val_loss: 9.8649\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0996 - val_loss: 9.8287\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0950 - val_loss: 9.8087\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0791 - val_loss: 9.8156\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0701 - val_loss: 9.8113\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0610 - val_loss: 9.7884\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.0490 - val_loss: 9.7712\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0472 - val_loss: 9.7660\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0368 - val_loss: 9.7605\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0203 - val_loss: 9.7643\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.0050 - val_loss: 9.7343\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9924 - val_loss: 9.7161\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9933 - val_loss: 9.7162\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9713 - val_loss: 9.6819\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9642 - val_loss: 9.6663\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9538 - val_loss: 9.6251\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.9321 - val_loss: 9.6028\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9331 - val_loss: 9.6365\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9219 - val_loss: 9.6052\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8919 - val_loss: 9.6186\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.8885 - val_loss: 9.5924\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.8674 - val_loss: 9.5659\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8508 - val_loss: 9.5211\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8382 - val_loss: 9.4912\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8237 - val_loss: 9.4973\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 7.8072 - val_loss: 9.4974\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7874 - val_loss: 9.5181\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7803 - val_loss: 9.5443\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7613 - val_loss: 9.5030\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7430 - val_loss: 9.4796\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.7341 - val_loss: 9.4576\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7170 - val_loss: 9.4270\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.7047 - val_loss: 9.4016\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6864 - val_loss: 9.3624\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6852 - val_loss: 9.3497\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6664 - val_loss: 9.3570\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.6365 - val_loss: 9.3511\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6246 - val_loss: 9.3762\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6181 - val_loss: 9.3971\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.6005 - val_loss: 9.3872\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5805 - val_loss: 9.3604\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5662 - val_loss: 9.3022\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5483 - val_loss: 9.3261\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5315 - val_loss: 9.2637\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.5275 - val_loss: 9.2356\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4901 - val_loss: 9.2093\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4724 - val_loss: 9.2429\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4602 - val_loss: 9.1950\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.4403 - val_loss: 9.1214\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.4252 - val_loss: 9.1440\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.4014 - val_loss: 9.1947\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3811 - val_loss: 9.1957\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3760 - val_loss: 9.1803\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3485 - val_loss: 9.1647\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.3219 - val_loss: 9.1456\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2959 - val_loss: 9.1437\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2883 - val_loss: 9.1915\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2635 - val_loss: 9.1214\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2403 - val_loss: 9.0926\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.2229 - val_loss: 9.0182\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1913 - val_loss: 9.0090\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1751 - val_loss: 9.0573\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.1494 - val_loss: 9.0618\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1571 - val_loss: 9.0729\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1151 - val_loss: 8.9945\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0941 - val_loss: 8.9730\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0722 - val_loss: 8.9152\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0556 - val_loss: 8.9467\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0559 - val_loss: 8.8926\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.0205 - val_loss: 8.9211\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9733 - val_loss: 8.9127\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9570 - val_loss: 8.9261\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.9516 - val_loss: 8.9025\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.9222 - val_loss: 8.8643\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8928 - val_loss: 8.8456\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8895 - val_loss: 8.8148\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8762 - val_loss: 8.8326\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8639 - val_loss: 8.7948\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8422 - val_loss: 8.8115\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8331 - val_loss: 8.8230\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8065 - val_loss: 8.7564\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.8094 - val_loss: 8.7796\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7933 - val_loss: 8.7976\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7815 - val_loss: 8.8116\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7659 - val_loss: 8.8328\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.7553 - val_loss: 8.8844\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7796 - val_loss: 8.8292\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.7454 - val_loss: 8.8243\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7360 - val_loss: 8.8330\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7236 - val_loss: 8.8201\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.7223 - val_loss: 8.8392\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7169 - val_loss: 8.8335\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7155 - val_loss: 8.8288\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7048 - val_loss: 8.7987\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.7237 - val_loss: 8.8018\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6820 - val_loss: 8.7947\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6924 - val_loss: 8.7992\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6739 - val_loss: 8.8151\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6668 - val_loss: 8.7956\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6819 - val_loss: 8.7983\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6547 - val_loss: 8.7836\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6626 - val_loss: 8.7825\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6872 - val_loss: 8.7799\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6513 - val_loss: 8.7967\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6460 - val_loss: 8.7866\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6288 - val_loss: 8.7600\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.6475 - val_loss: 8.7620\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6723 - val_loss: 8.7662\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 6.6022 - val_loss: 8.7593\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5995 - val_loss: 8.7607\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5958 - val_loss: 8.7645\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5825 - val_loss: 8.7629\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5866 - val_loss: 8.7656\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5981 - val_loss: 8.7535\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5891 - val_loss: 8.7364\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5753 - val_loss: 8.7253\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5519 - val_loss: 8.7179\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5596 - val_loss: 8.7204\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5379 - val_loss: 8.7234\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5308 - val_loss: 8.7150\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5359 - val_loss: 8.7289\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5304 - val_loss: 8.7091\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5237 - val_loss: 8.7054\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5353 - val_loss: 8.7685\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5238 - val_loss: 8.6937\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5097 - val_loss: 8.6888\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5144 - val_loss: 8.6944\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5086 - val_loss: 8.6935\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5059 - val_loss: 8.6826\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.5153 - val_loss: 8.6865\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4899 - val_loss: 8.6751\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4772 - val_loss: 8.6658\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.5272 - val_loss: 8.6501\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4806 - val_loss: 8.6263\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4664 - val_loss: 8.6320\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4637 - val_loss: 8.6200\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.4633 - val_loss: 8.6049\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4694 - val_loss: 8.6066\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4541 - val_loss: 8.5961\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4549 - val_loss: 8.6254\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4749 - val_loss: 8.5882\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6.4593 - val_loss: 8.5766\n",
      "Train: 6.411, Test: 8.577\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(64, input_dim=10, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(16, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(8, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=1500, verbose=1)\n",
    "y_pred=reg_model.predict(X_test_std)\n",
    "train_mae = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mae = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mae, test_mae))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean absolute Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "926bd5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,y_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dc281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac7b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda8c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88278f9f",
   "metadata": {},
   "source": [
    "# Independent component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3cc49f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=8)\n",
    "X_ica = ica.fit_transform(X)\n",
    "X_ica = pd.DataFrame(data = X_ica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b36b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.022781</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>-0.038583</td>\n",
       "      <td>-0.108172</td>\n",
       "      <td>-0.041023</td>\n",
       "      <td>-0.093598</td>\n",
       "      <td>-0.011073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020285</td>\n",
       "      <td>-0.022597</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.038582</td>\n",
       "      <td>-0.108187</td>\n",
       "      <td>-0.040975</td>\n",
       "      <td>-0.093622</td>\n",
       "      <td>-0.011098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020289</td>\n",
       "      <td>-0.022290</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>-0.038580</td>\n",
       "      <td>-0.108213</td>\n",
       "      <td>-0.040894</td>\n",
       "      <td>-0.093661</td>\n",
       "      <td>-0.011139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020303</td>\n",
       "      <td>-0.021062</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>-0.093819</td>\n",
       "      <td>-0.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020330</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>-0.038556</td>\n",
       "      <td>-0.108520</td>\n",
       "      <td>-0.039925</td>\n",
       "      <td>-0.094134</td>\n",
       "      <td>-0.011638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.020283 -0.022781  0.017370 -0.038583 -0.108172 -0.041023 -0.093598   \n",
       "1  0.020285 -0.022597  0.017342 -0.038582 -0.108187 -0.040975 -0.093622   \n",
       "2  0.020289 -0.022290  0.017297 -0.038580 -0.108213 -0.040894 -0.093661   \n",
       "3  0.020303 -0.021062  0.017116 -0.038572 -0.108315 -0.040571 -0.093819   \n",
       "4  0.020330 -0.018608  0.016753 -0.038556 -0.108520 -0.039925 -0.094134   \n",
       "\n",
       "          7  \n",
       "0 -0.011073  \n",
       "1 -0.011098  \n",
       "2 -0.011139  \n",
       "3 -0.011306  \n",
       "4 -0.011638  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fdb5280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ica, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66903e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 67ms/step - loss: 10.7883 - val_loss: 13.2048\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.3257 - val_loss: 12.7186\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.7685 - val_loss: 12.1164\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.3866 - val_loss: 11.5080\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.0628 - val_loss: 11.0104\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7313 - val_loss: 10.6259\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8943 - val_loss: 10.4057\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6909 - val_loss: 10.3392\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6909 - val_loss: 10.2952\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6639 - val_loss: 10.3796\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9928 - val_loss: 10.4413\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8727 - val_loss: 10.5398\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6551 - val_loss: 10.6020\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7700 - val_loss: 10.6096\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8639 - val_loss: 10.6014\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6125 - val_loss: 10.5293\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7584 - val_loss: 10.4557\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7457 - val_loss: 10.4195\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7851 - val_loss: 10.4504\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5019 - val_loss: 10.4530\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5948 - val_loss: 10.4126\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7233 - val_loss: 10.3380\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6719 - val_loss: 10.3072\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7041 - val_loss: 10.3357\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6037 - val_loss: 10.3203\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6144 - val_loss: 10.3656\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7326 - val_loss: 10.3732\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5844 - val_loss: 10.3579\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7178 - val_loss: 10.3159\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8855 - val_loss: 10.3875\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7429 - val_loss: 10.4902\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5938 - val_loss: 10.4514\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4886 - val_loss: 10.4143\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5731 - val_loss: 10.3279\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4549 - val_loss: 10.3113\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6077 - val_loss: 10.2388\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4541 - val_loss: 10.1932\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6369 - val_loss: 10.1739\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4764 - val_loss: 10.2003\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6445 - val_loss: 10.3281\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5480 - val_loss: 10.4363\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4947 - val_loss: 10.3879\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5015 - val_loss: 10.2863\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5103 - val_loss: 10.2751\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3548 - val_loss: 10.2129\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6073 - val_loss: 10.2820\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3583 - val_loss: 10.2607\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5734 - val_loss: 10.3270\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7579 - val_loss: 10.3744\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4321 - val_loss: 10.4388\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4694 - val_loss: 10.3405\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6774 - val_loss: 10.3709\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.6974 - val_loss: 10.3856\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5826 - val_loss: 10.4548\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3858 - val_loss: 10.4491\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4198 - val_loss: 10.3236\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3979 - val_loss: 10.1389\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4578 - val_loss: 10.1470\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3346 - val_loss: 10.0316\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2469 - val_loss: 10.0444\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7059 - val_loss: 10.3711\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4168 - val_loss: 10.5553\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5018 - val_loss: 10.1421\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5788 - val_loss: 10.2344\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3416 - val_loss: 10.4761\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3269 - val_loss: 10.2508\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4879 - val_loss: 10.1670\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2552 - val_loss: 10.1722\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0753 - val_loss: 9.9802\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4754 - val_loss: 10.0439\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2185 - val_loss: 10.1490\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2671 - val_loss: 10.3440\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2304 - val_loss: 10.2162\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2945 - val_loss: 9.9242\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2032 - val_loss: 10.0018\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1358 - val_loss: 9.9515\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0958 - val_loss: 10.0160\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0810 - val_loss: 9.9074\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9435 - val_loss: 9.9284\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0241 - val_loss: 10.0129\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2835 - val_loss: 10.0528\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3307 - val_loss: 9.9255\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9438 - val_loss: 9.9268\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0385 - val_loss: 9.8188\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8875 - val_loss: 9.8163\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7502 - val_loss: 9.8048\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8159 - val_loss: 10.0285\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8535 - val_loss: 9.7909\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8312 - val_loss: 9.8070\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5826 - val_loss: 10.0192\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9866 - val_loss: 9.8414\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9026 - val_loss: 9.7480\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5589 - val_loss: 10.0343\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.5681 - val_loss: 9.8253\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7547 - val_loss: 9.8153\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7376 - val_loss: 10.1266\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9734 - val_loss: 9.6866\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3262 - val_loss: 10.4230\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6991 - val_loss: 9.6902\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1556 - val_loss: 11.0494\n",
      "Train: 8.478, Test: 11.049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Dense(64, input_dim=10, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(16, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dropout(0.1))\n",
    "reg_model.add(Dense(8, activation='relu',kernel_regularizer='l2'))\n",
    "reg_model.add(Dense(1, activation='linear'))\n",
    "reg_model.compile(loss='mae', \n",
    "                optimizer='adam')\n",
    "\n",
    "\n",
    "history = reg_model.fit(X_train_std, Y_train, \n",
    "                            validation_data=(X_test_std, Y_test), \n",
    "                            epochs=1500, verbose=1)\n",
    "y_pred=reg_model.predict(X_test_std)\n",
    "train_mae = reg_model.evaluate(X_train_std, Y_train, verbose=0)\n",
    "test_mae = reg_model.evaluate(X_test_std, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mae, test_mae))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean absolute Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb52398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
