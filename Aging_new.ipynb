{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5fdd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from sklearn.metrics import confusion_matrix , classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(1234)\n",
    "import os\n",
    "import random\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bdd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8887140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(1234)\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f727c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11  \\\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3   \n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0   \n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5   \n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0   \n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c7fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ad269d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10   X11\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566   4.3\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566  10.0\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566  17.5\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566  31.0\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566  34.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8513aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0e8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.2</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.54</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1    X2   X3     X4     X5   X6   X7      X8   X9  X10\n",
       "0  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.2  566\n",
       "1  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  0.5  566\n",
       "2  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  1.0  566\n",
       "3  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  3.0  566\n",
       "4  17.54  5.67  7.8  0.003  68.98  0.0  0.0  99.993  7.0  566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a09e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data['X11']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3684fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.3\n",
       "1    10.0\n",
       "2    17.5\n",
       "3    31.0\n",
       "4    34.0\n",
       "Name: X11, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0131287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "17\n",
      "8\n",
      "18\n",
      "17\n",
      "9\n",
      "14\n",
      "55\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#We check the number of unique values in each column\n",
    "a=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "for i in a:\n",
    "    print(len(X[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89fee684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the boxplot for each variable\n",
    "# subplots(): plot subplots\n",
    "# figsize(): set the figure size\n",
    "fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# plot the boxplot using boxplot() from seaborn\n",
    "# z: let the variable z define the boxplot\n",
    "# x: data for which the boxplot is to be plotted\n",
    "# orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# ax: specifies the axes object to draw the plot o\n",
    "# set_xlabel(): set the x-axis label\n",
    "# fontsize: sets the font size of the x-axis label\n",
    "for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "    z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "    z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2deefbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code reduces the  above outliers seen. This is done by chaning the values in the box plot based on inter quantile range \n",
    "for i in X.columns:\n",
    "    q1=X[i].quantile(0.25)\n",
    "    q3=X[i].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    ub=q3 + 1.5*iqr\n",
    "    lb=q1 - 1.5*iqr\n",
    "    uc=X[i].quantile(0.99)\n",
    "    lc=X[i].quantile(0.01)\n",
    "    for ind1 in X[i].index:\n",
    "        if X.loc[ind1, i] >ub:            \n",
    "            X.loc[ind1, i] =uc\n",
    "        if X.loc[ind1, i] < lb:\n",
    "            X.loc[ind1, i] =lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f52c001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the boxplot for each variable\n",
    "# subplots(): plot subplots\n",
    "# figsize(): set the figure size\n",
    "fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "# plot the boxplot using boxplot() from seaborn\n",
    "# z: let the variable z define the boxplot\n",
    "# x: data for which the boxplot is to be plotted\n",
    "# orient: \"h\" specifies horizontal boxplot (for vertical boxplots use \"v\")\n",
    "# whis: proportion of the IQR past the low and high quartiles to extend the plot whiskers\n",
    "# ax: specifies the axes object to draw the plot o\n",
    "# set_xlabel(): set the x-axis label\n",
    "# fontsize: sets the font size of the x-axis label\n",
    "for variable, subplot in zip(X.columns, ax.flatten()):\n",
    "    z = sns.boxplot(x = X[variable], orient = \"h\",whis=1.5 , ax=subplot) # plot the boxplot\n",
    "    z.set_xlabel(variable, fontsize = 20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d6060de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X= scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c13b3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09ffa7",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6585c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7aba744e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f0573a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.562264</td>\n",
       "      <td>-0.624432</td>\n",
       "      <td>-0.246039</td>\n",
       "      <td>0.218947</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>-0.153706</td>\n",
       "      <td>0.063274</td>\n",
       "      <td>0.163968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.562359</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.245671</td>\n",
       "      <td>0.219044</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>-0.153784</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.163949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.562518</td>\n",
       "      <td>-0.624045</td>\n",
       "      <td>-0.245058</td>\n",
       "      <td>0.219204</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>-0.153914</td>\n",
       "      <td>0.063320</td>\n",
       "      <td>0.163917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.563154</td>\n",
       "      <td>-0.623079</td>\n",
       "      <td>-0.242607</td>\n",
       "      <td>0.219845</td>\n",
       "      <td>0.024222</td>\n",
       "      <td>-0.154435</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.163792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.564427</td>\n",
       "      <td>-0.621147</td>\n",
       "      <td>-0.237704</td>\n",
       "      <td>0.221127</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>-0.155475</td>\n",
       "      <td>0.063668</td>\n",
       "      <td>0.163540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.562264 -0.624432 -0.246039  0.218947  0.021905 -0.153706  0.063274   \n",
       "1 -0.562359 -0.624287 -0.245671  0.219044  0.022153 -0.153784  0.063291   \n",
       "2 -0.562518 -0.624045 -0.245058  0.219204  0.022567 -0.153914  0.063320   \n",
       "3 -0.563154 -0.623079 -0.242607  0.219845  0.024222 -0.154435  0.063436   \n",
       "4 -0.564427 -0.621147 -0.237704  0.221127  0.027533 -0.155475  0.063668   \n",
       "\n",
       "          7  \n",
       "0  0.163968  \n",
       "1  0.163949  \n",
       "2  0.163917  \n",
       "3  0.163792  \n",
       "4  0.163540  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df = pd.DataFrame(data = X_pca)\n",
    "PCA_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1e824",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa66efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "encoded = Dense(3, activation='relu')(input_layer)\n",
    "decoded = Dense(X.shape[1], activation='softmax')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "X1, X2, Y1, Y2 = train_test_split(X, X, test_size=0.3, random_state=101)\n",
    "\n",
    "autoencoder.fit(X1, Y1,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose = 30,\n",
    "                validation_data=(X2, Y2))\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_ae = encoder.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ffae21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7933368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "batch_size = 32\n",
    "input_dim = X_train[0].shape[0] #num of predictor variables \n",
    "learning_rate = 1e-5\n",
    "input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "#Input Layer\n",
    "encoder = Dense (2000, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "#Encoders first dense layer\n",
    "encoder = Dense (1000, activation=\"relu\",\n",
    "activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "#Encoders second dense layer\n",
    "encoder = Dense (500, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Code layer\n",
    "encoder = Dense (200, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoders first dense layer\n",
    "decoder = Dense(500, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoders second dense layer\n",
    "decoder = Dense(1000, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Decoders Third dense layer\n",
    "decoder = Dense(2000, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Output Layer\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\", activity_regularizer=regularizers.l1(learning_rate))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "774c8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 2s 41ms/step - loss: 0.1294 - accuracy: 0.1486\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0815 - accuracy: 0.1143\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0503 - accuracy: 0.2400\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0367 - accuracy: 0.3200\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0302 - accuracy: 0.3714\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0231 - accuracy: 0.5257\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0185 - accuracy: 0.4229\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0159 - accuracy: 0.4286\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0143 - accuracy: 0.5714\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0138 - accuracy: 0.5714\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0122 - accuracy: 0.6171\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0108 - accuracy: 0.6171\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0096 - accuracy: 0.6914\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0086 - accuracy: 0.6514\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0077 - accuracy: 0.7600\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0072 - accuracy: 0.7486\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0067 - accuracy: 0.7886\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0064 - accuracy: 0.7943\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0060 - accuracy: 0.8057\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0058 - accuracy: 0.8171\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0056 - accuracy: 0.8114\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0054 - accuracy: 0.8057\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0052 - accuracy: 0.7886\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0049 - accuracy: 0.7771\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0048 - accuracy: 0.7943\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0046 - accuracy: 0.7943\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0046 - accuracy: 0.7600\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0042 - accuracy: 0.7943\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0040 - accuracy: 0.7886\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0039 - accuracy: 0.7943\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0038 - accuracy: 0.7943\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0037 - accuracy: 0.7829\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0036 - accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0035 - accuracy: 0.8057\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0034 - accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0034 - accuracy: 0.7829\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0033 - accuracy: 0.8057\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0031 - accuracy: 0.8171\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0031 - accuracy: 0.8114\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0030 - accuracy: 0.7829\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0030 - accuracy: 0.8171\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0029 - accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0030 - accuracy: 0.8114\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0030 - accuracy: 0.8171\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0029 - accuracy: 0.7943\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0029 - accuracy: 0.8057\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0028 - accuracy: 0.8229\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0026 - accuracy: 0.8057\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0025 - accuracy: 0.7829\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0025 - accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0024 - accuracy: 0.8171\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0023 - accuracy: 0.7886\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0023 - accuracy: 0.8057\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0022 - accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0022 - accuracy: 0.8057\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0021 - accuracy: 0.8286\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 0.8114\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0021 - accuracy: 0.8229\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0021 - accuracy: 0.8057\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0020 - accuracy: 0.7943\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 0.8171\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 0.8114\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0020 - accuracy: 0.8057\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0019 - accuracy: 0.8114\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0019 - accuracy: 0.8171\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 0.8114\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0018 - accuracy: 0.8229\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 0.8171\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 0.8457\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0017 - accuracy: 0.8457\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0017 - accuracy: 0.8343\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 0.8171\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 0.8400\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8400\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 0.8343\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 0.8229\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0017 - accuracy: 0.8571\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 0.8286\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0017 - accuracy: 0.8057\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0017 - accuracy: 0.8171\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0017 - accuracy: 0.8286\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 0.8114\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 0.8229\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 0.8400\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8400\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0017 - accuracy: 0.8057\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8171\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 0.8114\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0015 - accuracy: 0.8171\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0015 - accuracy: 0.8457\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 0.8229\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0015 - accuracy: 0.8057\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0015 - accuracy: 0.8286\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0015 - accuracy: 0.8629\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 0.8171\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 0.8286\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0013 - accuracy: 0.8171\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 0.8114\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 0.8400\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0012 - accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0013 - accuracy: 0.8057\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 0.8571\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 0.8114\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0012 - accuracy: 0.8400\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 0.8286\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 0.8114\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 0.8114\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 0.8114\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 0.8114\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0010 - accuracy: 0.8057\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0010 - accuracy: 0.8057\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 0.8171\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.9418e-04 - accuracy: 0.8171\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.8128e-04 - accuracy: 0.8114\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.7138e-04 - accuracy: 0.8057\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.6165e-04 - accuracy: 0.8171\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.5557e-04 - accuracy: 0.8114\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.4539e-04 - accuracy: 0.8114\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.4197e-04 - accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 9.8139e-04 - accuracy: 0.8286\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.9006e-04 - accuracy: 0.8229\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0010 - accuracy: 0.8057\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0010 - accuracy: 0.8171\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 0.8400\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0010 - accuracy: 0.8400\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0010 - accuracy: 0.8114\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0010 - accuracy: 0.8343\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.6554e-04 - accuracy: 0.8057\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.4152e-04 - accuracy: 0.8114\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.3066e-04 - accuracy: 0.8171\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.9546e-04 - accuracy: 0.8171\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.9195e-04 - accuracy: 0.8286\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.7919e-04 - accuracy: 0.8114\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.8849e-04 - accuracy: 0.8229\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.8442e-04 - accuracy: 0.8114\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.7691e-04 - accuracy: 0.8171\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.7233e-04 - accuracy: 0.8343\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 8.7866e-04 - accuracy: 0.8171\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.7384e-04 - accuracy: 0.8114\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.0371e-04 - accuracy: 0.8114\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.2824e-04 - accuracy: 0.8114\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0012 - accuracy: 0.8457\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 0.8171\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0010 - accuracy: 0.8114\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0010 - accuracy: 0.8171\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0010 - accuracy: 0.8114\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0011 - accuracy: 0.8286\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 0.8057\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 0.8057\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3923e-04 - accuracy: 0.7943\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7818e-04 - accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.5771e-04 - accuracy: 0.8057\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.3107e-04 - accuracy: 0.7886\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.1205e-04 - accuracy: 0.8229\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.8821e-04 - accuracy: 0.8114\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.7764e-04 - accuracy: 0.8114\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.6217e-04 - accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.4961e-04 - accuracy: 0.8114\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.3213e-04 - accuracy: 0.8057\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.2070e-04 - accuracy: 0.8114\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.1230e-04 - accuracy: 0.8057\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.0932e-04 - accuracy: 0.8171\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.0046e-04 - accuracy: 0.8114\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.9115e-04 - accuracy: 0.8057\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8383e-04 - accuracy: 0.8057\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.7618e-04 - accuracy: 0.8057\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.6979e-04 - accuracy: 0.8229\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.6398e-04 - accuracy: 0.8114\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.5864e-04 - accuracy: 0.8114\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.5382e-04 - accuracy: 0.8057\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.4962e-04 - accuracy: 0.8171\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.4534e-04 - accuracy: 0.8057\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.4085e-04 - accuracy: 0.8057\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.3780e-04 - accuracy: 0.8114\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.3740e-04 - accuracy: 0.8114\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3772e-04 - accuracy: 0.8057\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.4026e-04 - accuracy: 0.8171\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.3628e-04 - accuracy: 0.8114\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.4217e-04 - accuracy: 0.8057\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.5381e-04 - accuracy: 0.8114\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.7501e-04 - accuracy: 0.8114\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.6507e-04 - accuracy: 0.8057\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.5842e-04 - accuracy: 0.8057\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.6582e-04 - accuracy: 0.7943\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.6154e-04 - accuracy: 0.8171\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.6656e-04 - accuracy: 0.8114\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.1946e-04 - accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.0730e-04 - accuracy: 0.8114\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.9592e-04 - accuracy: 0.8286\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.0972e-04 - accuracy: 0.8057\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.9420e-04 - accuracy: 0.8114\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.9600e-04 - accuracy: 0.8057\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.7218e-04 - accuracy: 0.8057\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.4097e-04 - accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "autoencoder_1 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_1.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_1 = autoencoder_1.fit(X_train, X_train,epochs=200,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5f9691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2_input = autoencoder_1.predict(X_train)\n",
    "autoencoder_2_input = np.concatenate((autoencoder_2_input , X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f35b31a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 35ms/step - loss: 0.0010 - accuracy: 0.8714\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 8.3606e-04 - accuracy: 0.8771\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 6.8580e-04 - accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 7.0076e-04 - accuracy: 0.8714\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 7.3781e-04 - accuracy: 0.8771\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 7.1291e-04 - accuracy: 0.8971\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 6.7314e-04 - accuracy: 0.8686\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 9.3461e-04 - accuracy: 0.8829\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 7.2502e-04 - accuracy: 0.8743\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 7.6358e-04 - accuracy: 0.8657\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 6.7484e-04 - accuracy: 0.8743\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 6.3380e-04 - accuracy: 0.8800\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 5.6834e-04 - accuracy: 0.8771\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 5.4623e-04 - accuracy: 0.8771\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 5.2202e-04 - accuracy: 0.8771\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 5.0437e-04 - accuracy: 0.8971\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.9338e-04 - accuracy: 0.8886\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.8482e-04 - accuracy: 0.8943\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.7836e-04 - accuracy: 0.8829\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.7676e-04 - accuracy: 0.8886\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 4.6878e-04 - accuracy: 0.8914\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 4.6742e-04 - accuracy: 0.8886\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.7090e-04 - accuracy: 0.8771\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.6710e-04 - accuracy: 0.8971\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.7421e-04 - accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.7099e-04 - accuracy: 0.8886\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.6298e-04 - accuracy: 0.8743\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.5614e-04 - accuracy: 0.8714\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.6553e-04 - accuracy: 0.8714\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 4.8937e-04 - accuracy: 0.8743\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 7.5624e-04 - accuracy: 0.8686\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0026 - accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0058 - accuracy: 0.7486\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.0063 - accuracy: 0.8143\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.0062 - accuracy: 0.8029\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0091 - accuracy: 0.7543\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0094 - accuracy: 0.8029\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0063 - accuracy: 0.7829\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0051 - accuracy: 0.8514\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0044 - accuracy: 0.8743\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0032 - accuracy: 0.8457\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0024 - accuracy: 0.8629\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0019 - accuracy: 0.8514\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 0.8714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0016 - accuracy: 0.8714\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0014 - accuracy: 0.8657\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.0013 - accuracy: 0.8886\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 0.8800\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0012 - accuracy: 0.8686\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0012 - accuracy: 0.8743\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0012 - accuracy: 0.8743\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0012 - accuracy: 0.8771\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.0012 - accuracy: 0.8914\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 0.8743\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 0.8743\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 0.8771\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0010 - accuracy: 0.8743\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 9.5327e-04 - accuracy: 0.8829\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 8.8128e-04 - accuracy: 0.8743\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 7.3884e-04 - accuracy: 0.8771\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 6.7369e-04 - accuracy: 0.8771\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 6.1302e-04 - accuracy: 0.8857\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.9813e-04 - accuracy: 0.8743\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.8739e-04 - accuracy: 0.8829\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.7717e-04 - accuracy: 0.8829\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.7096e-04 - accuracy: 0.8771\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 5.6339e-04 - accuracy: 0.8829\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.5831e-04 - accuracy: 0.8829\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 5.5295e-04 - accuracy: 0.8743\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.4845e-04 - accuracy: 0.8714\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.4366e-04 - accuracy: 0.8714\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 5.3919e-04 - accuracy: 0.8771\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 5.3528e-04 - accuracy: 0.8743\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 5.3073e-04 - accuracy: 0.8771\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.2697e-04 - accuracy: 0.8771\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 5.2276e-04 - accuracy: 0.8771\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 5.1889e-04 - accuracy: 0.8686\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 5.1672e-04 - accuracy: 0.8771\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 43ms/step - loss: 5.1322e-04 - accuracy: 0.8743\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.0897e-04 - accuracy: 0.8771\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.0624e-04 - accuracy: 0.8771\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.0230e-04 - accuracy: 0.8829\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 4.9833e-04 - accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 4.9492e-04 - accuracy: 0.8829\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.9154e-04 - accuracy: 0.8829\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.8954e-04 - accuracy: 0.8800\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.8519e-04 - accuracy: 0.8829\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.8218e-04 - accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.7997e-04 - accuracy: 0.8857\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.7896e-04 - accuracy: 0.8771\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.7631e-04 - accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.7525e-04 - accuracy: 0.8800\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 4.7132e-04 - accuracy: 0.8800\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.6820e-04 - accuracy: 0.8800\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.6553e-04 - accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.6256e-04 - accuracy: 0.8743\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 4.5998e-04 - accuracy: 0.8857\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.5809e-04 - accuracy: 0.8857\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.5655e-04 - accuracy: 0.8829\n"
     ]
    }
   ],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_2.compile(metrics=['accuracy'],loss='mean_squared_error',optimizer='adam')\n",
    "satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ca64cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)\n",
    "autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8d5fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 3s 29ms/step - loss: 0.0012 - accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 7.1759e-04 - accuracy: 0.8786\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 5.6472e-04 - accuracy: 0.8943\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.6410e-04 - accuracy: 0.9014\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 4.2448e-04 - accuracy: 0.9086\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.1554e-04 - accuracy: 0.9200\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.1043e-04 - accuracy: 0.9257\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.6981e-04 - accuracy: 0.9100\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 6.8940e-04 - accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.8914\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.0062 - accuracy: 0.8529\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0087 - accuracy: 0.8557\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.8457\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 0.8614\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0046 - accuracy: 0.8714\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0019 - accuracy: 0.8843\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.8829\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.8800\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.8857\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 0.8914\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0011 - accuracy: 0.8871\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 0.8957\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0010 - accuracy: 0.8929\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.8957\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 7.0771e-04 - accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 5.8739e-04 - accuracy: 0.8986\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 5.2980e-04 - accuracy: 0.8971\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 5.0564e-04 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.8281e-04 - accuracy: 0.8986\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 4.6975e-04 - accuracy: 0.9157\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.6031e-04 - accuracy: 0.9057\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.5398e-04 - accuracy: 0.9071\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 4.4525e-04 - accuracy: 0.9100\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 4.3844e-04 - accuracy: 0.9171\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 4.3161e-04 - accuracy: 0.9100\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 4.2495e-04 - accuracy: 0.9143\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 4.1815e-04 - accuracy: 0.9086\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 4.1215e-04 - accuracy: 0.9200\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 4.0820e-04 - accuracy: 0.9129\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 4.0238e-04 - accuracy: 0.9086\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 3.9347e-04 - accuracy: 0.9200\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 3.9203e-04 - accuracy: 0.9200\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 4.2194e-04 - accuracy: 0.9200\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 4.0420e-04 - accuracy: 0.9200\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 3.8111e-04 - accuracy: 0.9243\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 3.7499e-04 - accuracy: 0.9171\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 3.6954e-04 - accuracy: 0.9186\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 3.6335e-04 - accuracy: 0.9271\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 3.6197e-04 - accuracy: 0.9200\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 3.6240e-04 - accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "autoencoder_3 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_3.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75c24ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a4908f943eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_sae\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msatck_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bac56cb",
   "metadata": {},
   "source": [
    "# independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10ec40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=8)\n",
    "X_ica = ica.fit_transform(X)\n",
    "X_ica = pd.DataFrame(data = X_ica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4186bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041642</td>\n",
       "      <td>-0.010160</td>\n",
       "      <td>-0.026587</td>\n",
       "      <td>-0.055216</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>0.123657</td>\n",
       "      <td>-0.027799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041547</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>-0.026574</td>\n",
       "      <td>-0.055213</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.123680</td>\n",
       "      <td>-0.027806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041388</td>\n",
       "      <td>-0.010153</td>\n",
       "      <td>-0.026552</td>\n",
       "      <td>-0.055208</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.123717</td>\n",
       "      <td>-0.027819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040754</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>-0.026466</td>\n",
       "      <td>-0.055186</td>\n",
       "      <td>0.050093</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>-0.027868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039484</td>\n",
       "      <td>-0.010100</td>\n",
       "      <td>-0.026293</td>\n",
       "      <td>-0.055144</td>\n",
       "      <td>0.050154</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.124160</td>\n",
       "      <td>-0.027968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.041642 -0.010160 -0.026587 -0.055216  0.050050  0.027155  0.123657   \n",
       "1  0.041547 -0.010157 -0.026574 -0.055213  0.050054  0.027143  0.123680   \n",
       "2  0.041388 -0.010153 -0.026552 -0.055208  0.050062  0.027123  0.123717   \n",
       "3  0.040754 -0.010135 -0.026466 -0.055186  0.050093  0.027045  0.123864   \n",
       "4  0.039484 -0.010100 -0.026293 -0.055144  0.050154  0.026889  0.124160   \n",
       "\n",
       "          7  \n",
       "0 -0.027799  \n",
       "1 -0.027806  \n",
       "2 -0.027819  \n",
       "3 -0.027868  \n",
       "4 -0.027968  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c678c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
